<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Server | 织网]]></title>
  <link href="http://zheng-ji.github.com/blog/categories/server/atom.xml" rel="self"/>
  <link href="http://zheng-ji.github.com/"/>
  <updated>2016-09-28T08:45:51+08:00</updated>
  <id>http://zheng-ji.github.com/</id>
  <author>
    <name><![CDATA[zheng-ji]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Twemproxy 一个 Redis 代理]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/08/16/twemproxy/"/>
    <updated>2015-08-16T12:11:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/08/16/twemproxy</id>
    <content type="html"><![CDATA[<dl>
  <dt>为解决线上 Redis 服务直连出现链接数爆棚而做的调研， 对 Twitter 开源的 twemproxy 做一些记录。 我们之所以放弃官方的 RedisCLuster 是因为不太满意其性能</dt>
  <dd>
    <p><a href="#第一节">初窥原理</a>
* <a href="#第二节">安装与配置</a>
* <a href="#第三节">不支持的操作</a>
* <a href="#第四节">压力测试</a>
* <a href="#第五节">摘自极光博客的评论</a></p>
  </dd>
</dl>

<h3 id="第一节">初窥原理</h3>

<ul>
  <li>Twitter 出品的轻量级 Redis，memcached 代理，使用它可以减少缓存服务器的连接数，并且利用它来作分片。</li>
  <li>作是说最差情况下，性能损耗不会多于20%。背后是用了pipeline，redis是支持使用pipeline批处理的。</li>
  <li>twemproxy 与每个 redis 服务器都会建立一个连接，每个连接实现了两个 FIFO 的队列， 通过这两个队列实现对 redis 的 pipeline 访问，将多个客户端的访问合并到一个连接，这样既减少了redis服务器的连接数，又提高了访问性能。</li>
</ul>

<h3 id="第二节">安装与配置</h3>

<ul>
  <li>安装</li>
</ul>

<p><code>
apt-get install automake
apt-get install libtool
git clone git://github.com/twitter/twemproxy.git
cd twemproxy
autoreconf -fvi
./configure
make
sudo make install
</code>
默认的可执行文件在 /usr/local/sbin/nutcracker</p>

<ul>
  <li>配置文件 /etc/nutcracker/nutcracker.yml</li>
</ul>

<p><code>
alpha:
    listen: 127.0.0.1:8877
    hash: fnv1a_64
    distribution: ketama
    auto_eject_hosts: true
    redis: true
    server_retry_timeout: 30000
    server_failure_limit: 3
    servers:
        - 127.0.0.1:6379:1 master0  #后端的redis-server
        - 127.0.0.1:6380:1 master1
</code></p>

<p>当 redis 做缓存的使用的时候应该启用 auto_eject_hosts， 如果某个节点失败的时候将该节点删除，虽然丧失了数据的一致性，但作为缓存使用，保证了这个集群的高可用性。当redis做存储的使用时为了保持数据的一致性，应该禁用 auto_eject_hosts,也就是当某个节点失败之后并不删除该节点。</p>

<h3 id="第三节">不支持的操作</h3>

<p><code>
keys command: keys,migrate,move object,randomkey,rename,renamenx,
sort strings command: bitop,mset,msetnx
list command: blpop,brpop,brpoplpush
scripting command: script exists,script flush,script kill,script load
pub/sub command:(全部不支持)psubscribe,publish,punsubscribe,subscribe,unsubscribe
</code></p>

<h3 id="第四节">压测</h3>

<p>感谢 redis 提供的 redis-benchmark 工具，用它来做压测挺好的。</p>

<ul>
  <li>n 表示多少个连接</li>
  <li>r 表示多少个 key,</li>
  <li>t 代表命令</li>
</ul>

<p>```
zj@zheng-ji.info:~$ redis-benchmark -p 6700 -t smembers,hexists,get,hget,lrange,ltrim,zcard,setex,sadd -n 1000000 -r 100000000</p>

<p>====== GET ======
1000000 requests completed in 12.95 seconds
50 parallel clients
3 bytes payload
keep alive: 1</p>

<p>99.19% &lt;= 1 milliseconds
99.93% &lt;= 2 milliseconds
100.00% &lt;= 2 milliseconds
77220.08 requests per second</p>

<p>====== SADD ======
1000000 requests completed in 10.74 seconds
50 parallel clients
3 bytes payload
keep alive: 1</p>

<p>99.88% &lt;= 1 milliseconds
99.95% &lt;= 2 milliseconds
99.97% &lt;= 3 milliseconds
99.99% &lt;= 4 milliseconds
100.00% &lt;= 4 milliseconds
93144.56 requests per second
```</p>

<p>如作者所言, 性能几乎可以跟直连redis比拟，背后的数据也很均匀,使用twemproxy 观察连接数, 一直都保持在个位数左右。</p>

<h3 id="第五节">摘自极光博客的评论</h3>

<ul>
  <li>前端使用 Twemproxy 做代理，后端的 Redis 数据能基本上根据 key 来进行比较均衡的分布。</li>
  <li>后端一台 Redis 挂掉后，Twemproxy 能够自动摘除。恢复后，Twemproxy 能够自动识别、恢复并重新加入到 Redis 组中重新使用。</li>
  <li>Redis 挂掉后，后端数据是否丢失依据 Redis 本身的策略配置，与 Twemproxy 基本无关。</li>
  <li>如果要新增加一台 Redis，Twemproxy 需要重启才能生效；并且数据不会自动重新 Reblance，需要人工单独写脚本来实现。</li>
  <li>如同时部署多个 Twemproxy，配置文件一致（测试配置为distribution：ketama,modula），则可以从任意一个读取，都可以正确读取 key对应的值。</li>
  <li>多台 Twemproxy 配置一样，客户端分别连接多台 Twemproxy可以在一定条件下提高性能。根据 Server 数量，提高比例在 110-150%之间。</li>
  <li>如原来已经有 2 个节点 Redis，后续有增加 2 个 Redis，则数据分布计算与原来的 Redis 分布无关，现有数据如果需要分布均匀的话，需要人工单独处理。</li>
  <li>如果 Twemproxy 的后端节点数量发生变化，Twemproxy 相同算法的前提下，原来的数据必须重新处理分布，否则会存在找不到key值的情况。</li>
</ul>

<hr />

<p>参考链接</p>

<p><a href="http://blog.jpush.cn/redis-twemproxy-benchmark/">极光推送的博客</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[为服务端程序构建 Docker]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/04/05/yong-bao-docker/"/>
    <updated>2015-04-05T20:24:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/04/05/yong-bao-docker</id>
    <content type="html"><![CDATA[<p>Docker 的优点自从问世就一直被工业界热论。</p>

<p>平时工作中，所部署的大多数<code>Python</code>项目都会用上 <a href="http://wiki.zheng-ji.info/Python/virtualenv-py.html">virtualenv</a>, 
沙箱隔离带来的好处不言而喻。我也希望静态编译的服务，比如 <code>Golang</code> <code>C++</code> 的项目
同样能使用上沙箱环境。得益于<code>Docker</code>，我们仍然可以做到。</p>

<p>这个过程没有想象中的简单，需要一番折腾，我以最近写的 KafkServer 为例，叙述我是怎么构建的，需要读者具备一定的 Docker 基础. 或许这不是最好的方法。</p>

<h3 id="docker-">一览该 Docker 项目</h3>

<p><code>
zj@zheng-ji:~/workspace/gocode/src/kafconsumer/docker$ tree
.
├── Dockerfile
├── kafConsumer
│   ├── consumer
│   ├── etc
│   │   ├── config.yml
│   │   └── logger.xml
│   └── script
│       └── start.sh
└── kafConsumer.tar.gz
</code></p>

<p>以上的截图，是一个完整的 <code>Docker</code> 项目，包含了：</p>

<ul>
  <li><code>Dockerfile</code>,</li>
  <li><code>kafCounsumer</code>(服务端程序，里面附带的启动脚本，配置程序，以及二进制文件)，</li>
  <li>还有它被压缩而成的 <code>kafConsumer.tar.gz</code></li>
</ul>

<hr />

<h3 id="dockerfile-">Dockerfile 的内容</h3>

<p><code>
FROM ubuntu:14.04                                                         
MAINTAINER zheng-ji &lt;zheng-ji.info&gt;                                     
RUN echo Asia/Shanghai &gt; /etc/timezone                   
RUN sed -i "s/archive\.ubuntu/mirrors.163/" /etc/apt/sources.list          
RUN apt-get update                                                         
COPY kafConsumer.tar.gz /                                                  
RUN tar xvf kafConsumer.tar.gz                                         
VOLUME /data                   
WORKDIR /kafConsumer                                                   
ENTRYPOINT ["./script/start.sh"]
</code></p>

<p><code>Dockerfile</code> 可以理解为<code>makefile</code> 之类的文件，Docker 可以依照文件中的内容，构建镜像.</p>

<p><code>
sudo docker -t build Server/KafConsumer .
</code></p>

<p>这样就生成了<code>Tag</code> 为 <code>Server/KafConsumer</code> 的镜像，待会儿我们会使用它</p>

<p>以上 <code>Dockerfile</code> 的具体内容的意义是:</p>

<blockquote>

  <ul>
    <li>第一行：拉取ubuntu 14:04的镜像源</li>
    <li>第二行：维护者</li>
    <li>第三行：调整时区</li>
    <li>第四行：更新源地址</li>
    <li>第五行：更新源</li>
    <li>第六行：复制项目下的压缩包到虚拟机根目录</li>
    <li>第七行：解压</li>
    <li>第八行：项目中使用/data数据卷</li>
    <li>第九行：进入工作目录</li>
    <li>第十行：Docker的入口执行文件是start.sh</li>
  </ul>
</blockquote>

<hr />

<h3 id="section">入口文件的内容</h3>

<p><code>
#!/bin/bash
ulimit -a
if [ ! -d /data/ad ];  then
    mkdir /data/ad
fi
exec ./consumer -c=etc/config.yml
</code></p>

<p>这是一个shell的启动文件，因此一定要在开头写明 #!/bin/bash, 使用exec 执行程序</p>

<hr />

<h3 id="section-1">启动镜像</h3>

<p><code>
sudo docker run -i -t  -v /path/to/data:/data Server/kafConsumer
</code>
这样就执行了，-v 可以映射你的本地文件到虚拟机的某个数据卷，这样我们就能从外面看到程序产生的文件.</p>

<h3 id="section-2">如果你想关闭或者重启该服务的怎么办</h3>

<p>```
sudo docker ps -a</p>

<p>找到你的 Docker 容器</p>

<p>CONTAINER ID    IMAGE           COMMAND                CREATED        STATUS        PORTS    NAMES
5b39d0d5cb85    Server/kafkaconsumer:latest   “./script/start.sh”    3 hours ago    tender_bohr 
```</p>

<p>启动或者关闭</p>

<p><code>
sudo docker start tender_bohr
sudo docker stop tender_bohr
</code></p>

<hr />

<h3 id="daocloud--">Daocloud  加速</h3>

<p>功夫墙的原因，国外很多镜像被墙，因此构建镜像很慢，使用 Daocloud 服务可以加速,注册后就有该服务了</p>

<p><code>
cat /etc/default/docker
DOCKER_OPTS="$DOCKER_OPTS --registry-mirror=http://xxxxxx.m.daocloud.io"
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[rsyslog 接收远程日志]]></title>
    <link href="http://zheng-ji.github.com/blog/2014/07/27/rsyslog-jie-shou-yuan-cheng-ri-zhi/"/>
    <updated>2014-07-27T14:26:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2014/07/27/rsyslog-jie-shou-yuan-cheng-ri-zhi</id>
    <content type="html"><![CDATA[<p>Rsyslog 接收远程日志</p>

<p>需要开启运程模式, 以ubuntu为例子</p>

<p><code>
vim /etc/default/rsyslog
RSYSLOGD_OPTIONS="-c5 -r -x"
</code></p>

<p>编写模板,文档中说到要在<code>rsyslog.conf</code>里面编辑</p>

<p><code>
vim /etc/rsyslog.conf
$ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat
$template DynFile, "/data/log/%$year%%$month%%$day%/%$year%%$month%%$day%%$hour%.log"
$template dotalogformat, "%msg%\n"
</code></p>

<p>编写过滤规则, 修改 <code>/etc/rsysconf.d/your_business.conf</code></p>

<p>```
# 开通端口
$ModLoad imtcp
$InputTCPServerRun 1514</p>

<h1 id="section">过滤规则</h1>
<p>if $msg contains “xx” then ?DynFile;dotalogformat</p>

<h1 id="sysloglog-">为了不让它写入syslog.log 而直接写入目标模板</h1>
<p>:msg, contains, “xx” ~
```</p>

<p>重启服务</p>

<p><code>
sudo service rsyslog start
</code></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[折腾 Docker]]></title>
    <link href="http://zheng-ji.github.com/blog/2014/07/16/zhe-teng-docker/"/>
    <updated>2014-07-16T20:20:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2014/07/16/zhe-teng-docker</id>
    <content type="html"><![CDATA[<p>早在1年前就听过 <a href="http://docs.docker.com/">docker</a>这个 Golang 社区的明星产品 。</p>

<h3 id="section">简单地介绍</h3>

<p>Docker 提供了一个可以运行你的应用程序的容器。像一个可移植的容器引擎那样工作。它把应用程序及所有程序的依赖环境打包到一个虚拟容器中，这个虚拟容器可以运行在任何一种 Linux 服务器上。这大大地提高了程序运行的灵活性和可移植性，极大的降低运维成本。</p>

<h3 id="section-1">组成</h3>

<ul>
  <li>Docker 服务器守护程序（server daemon），用于管理所有的容器。</li>
  <li>Docker 命令行客户端，用于控制服务器守护程序。</li>
  <li>Docker 镜像：查找和浏览 docker 容器镜像。它也访问这里得到：<a href="https://index.docker.io/">链接</a></li>
</ul>

<h3 id="docker">有了虚拟机为什么还要docker?</h3>
<p>virtualbox 等虚拟机提供的是完整的操作系统环境, 迁移的时候太大了。它们包含了大量类似硬件驱动、虚拟处理器、网络接口等等并不需要的信息，也需要比较长时间的启动，同时也会消耗大量的内存、CPU 资源。</p>

<p>Docker 相比起来就非常轻量级了。运行起来就和一个常规程序差不多。这个容器不仅仅运行快，创建一个镜像和制作文件系统快照也很快,甚至比vagrant更节约资源</p>

<h3 id="section-2">初体验</h3>
<p>下载docker 并安装 ubuntu 12.04 这里如果没有指明 <code>ubuntu:12.04</code>, 会将所有ubuntu镜像都下载。由于被墙，速度惨不忍睹.</p>

<p><code>
zj@zheng-ji:~$ sudo apt-get install docker.io
zj@zheng-ji:~$ sudo docker pull ubuntu:12.04 
</code></p>

<p>查看已有的镜像</p>

<p><code>
zj@zheng-ji:~$ sudo docker images
</code></p>

<p>使用 bash 命令进入docker的指定镜像</p>

<p><code>
zj@zheng-ji:~$ sudo docker run -t -i -p 3000 ubuntu:12.04 /bin/bash
</code></p>

<p>这时候我就可以像一个新系统一样把玩了, 比如创建一个目录。</p>

<p><code>
zj@zheng-ji:~$ mkdir /home/zj/test
</code></p>

<p>好了，我想把这个现场保存下来做移植到别的地方直接使用。需要到 <a href="https://registry.hub.docker.com/u/">这里</a> 注册一个账户，然后再上传，类似在 github  上面一样的操作。</p>

<p>```
sudo docker ps </p>

<p>//因为我已经commit 过一次，所以名字变成我的别名 zhengji/helloworld
zj@zheng-ji:~$ docker ps
CONTAINER ID        IMAGE                       COMMAND             CREATED             STATUS              PORTS                     NAMES
8dad3aa4451f        zhengji/helloworld:latest   bin/bash            27 minutes ago      Up 27 minutes       0.0.0.0:49156-&gt;3000/tcp   high_galileo    <br />
```</p>

<p>可以看到要保存的镜像的 CONTAINER ID</p>

<p>这个时候提交</p>

<p>```
zj@zheng-ji:~$ sudo docker commit 8dad3aa4451f zhengji/helloworld -m “test”
61f9527f368395ee228af07062b3f1a26fa7143ba2721c4f9755ae93d588358e</p>

<p>zj@zheng-ji:~$ sudo docker push zhengji/helloworld
```</p>

<p>下次pull 下来就可以使用了</p>

<p><code>
sudo docker pull zhengji/helloworld
</code></p>

<hr />

<h3 id="section-3">可能遇到的坑</h3>

<ul>
  <li>需要编辑 /etc/default/docker.io 然后编辑里面的,使得其可以解决 DNS解析</li>
</ul>

<p><code>
DOCKER_OPTS = "-dns 8.8.8.8"
</code></p>

<ul>
  <li>设置 ufw 端口可转发</li>
</ul>

<p><code>
vim /etc/default/ufw
DEFAULT_FORWARD_POLICY = "ACCEPT"
</code></p>

<h3 id="section-4">参考链接</h3>

<ul>
  <li><a href="http://www.docker.org.cn/book/docker.html">docker 中文</a></li>
  <li><a href="http://www.docker.org.cn/book/docker.html">docker官网</a></li>
  <li><a href="http://segmentfault.com/a/1190000000366923">Docker入门教程</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[译]nginx pitfall]]></title>
    <link href="http://zheng-ji.github.com/blog/2014/05/13/nginx-pitfall/"/>
    <updated>2014-05-13T22:26:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2014/05/13/nginx-pitfall</id>
    <content type="html"><![CDATA[<p>今天看完<a href="http://wiki.nginx.org/Pitfalls">Nginx Pitfall</a>,热血用了一个下午翻译了的，以下是正文</p>

<h2 id="nginx-">Nginx 陷阱</h2>

<p>无论你是nginx的新用户还是老用户都会遇到nginx的一些陷阱，下面我们着重描述这些陷阱，以及如何避免犯错。这些问题多次出现在 #nginx channel on Freenode#上</p>

<h3 id="section">[是指南教我这么做的]</h3>

<p>不要轻易相信网上其他的配置指引，除非你知道这样做的真正意义，并且知道怎么清除它们。很多配置其实写的很糟糕，我们根据互联网上的错误配置收集到的陷阱，它们并非来自刻意搜索，而是来自网络上的疑惑问答，这些问题收到的共同回复是，他们因为看了一些错误配置指引所以不同意我们的方法。写此文的目的是为了阐述我们的观点，如果你也遇到如下问题，该文章正好为你准备。</p>

<h3 id="root-location">[Root 放置在Location块内]</h3>

<p>不好的配置</p>

<p><code>bash
server {
  server_name www.domain.com;
  location / {
    root /var/www/nginx-default/;
    [...]
  }
  location /foo {
    root /var/www/nginx-default/;
    [...]
  }
  location /bar {
    root /var/www/nginx-default/;
    [...]
  }
}
</code></p>

<p>该配置可以正常工作，把 root 放在 location块内可以完美的运行，但是当你开始添加location快，你就发现问题了。如果你给每个loaction 块添加 root，一旦有一个 location 块没有匹配到,那么他就失去了 root ,让我们来看看正确的配置</p>

<p><code>
server {
  server_name www.domain.com;
  root /var/www/nginx-default/;
  location / {
    [...]
  }
  location /foo {
    [...]
  }
  location /bar {
    [...]
  }
}
</code></p>

<h3 id="index-">[多条 index 指令]</h3>

<p>不好的配置</p>

<p><code>
http {
  index index.php index.htm index.html;
  server {
    server_name www.domain.com;
    location / {
      index index.php index.htm index.html;
      [...]
    }
  }
  server {
    server_name domain.com;
    location / {
      index index.php index.htm index.html;
      [...]
    }
    location /foo {
      index index.php;
      [...]
    }
  }
}
</code></p>

<p>为什么要重复多条不需要的 index 指令？事实上只需要用一次，它仅仅需要放置在 <code>http{}</code> 块内，后面的配置会继承它。</p>

<p>正确的配置</p>

<p><code>
http {
  index index.php index.htm index.html;
  server {
    server_name www.domain.com;
    location / {
      [...]
    }
  }
  server {
    server_name domain.com;
    location / {
      [...]
    }
    location /foo {
      [...]
    }
  }
</code></p>

<h3 id="if">[使用if]</h3>
<p>这里有小段篇幅是关于使用<code>if</code> 表达式，我们需要检查所谓的 “是否有害”，让我们看看那些错误的配置</p>

<p>不好的配置</p>

<p><code>
server {
  server_name domain.com *.domain.com;
  if ($host ~* ^www\.(.+)) {
    set $raw_domain $1;
    rewrite ^/(.*)$ $raw_domain/$1 permanent;
    [...]
  }
}
</code>
这里明显有问题，第一条 <code>if</code> 指令就引起我们的注意，为什么是不好的配置呢, 你是否阅读过 <a href="http://wiki.nginx.org/IfIsEvil">是否有害</a>。</p>

<p>使用if 指令，nginx 会强制检查所有到来的请求，检测每一条指令是否有危害，这是极度低效的。使用两个 server 配置可以避免上述问题。</p>

<p>正确的配置</p>

<p><code>
server {
  server_name www.domain.com;
  return 301 $scheme://domain.com$request_uri;
}
server {
  server_name domain.com;
  [...]
}
</code></p>

<p>这种方法不仅是配置易读，而且降低了 nginx 的处理负担。我们摆脱了<code>if</code>指令的陷阱，我们也使用了 <code>$scheme</code> 代替了 URI scheme 是 http 还是 https 的硬编码.</p>

<h3 id="section-1">[判断文件是否存在]</h3>

<p>使用 <code>if</code> 指令确保文件是否存在，是糟糕的实践，如果你有机会接触较新的 nginx 版本，查看下<code>try_files</code> 指令，该指令更适合做该事情。</p>

<p>不好的配置</p>

<p><code>
server {
  root /var/www/domain.com;
  location / {
    if (!-f $request_filename) {
      break;
    }
  }
}
</code></p>

<p>正确的配置</p>

<p><code>
server {
  root /var/www/domain.com;
  location / {
    try_files $uri $uri/ /index.html;
  }
}
</code></p>

<p>我们做的改变是，我们不使用<code>if</code>指令，而是使用 <code>try_files</code>,如果<code>$uri</code>不存在，尝试 <code>$uri/</code> 如果不存在，就使用默认的文件 <code>index.html</code></p>

<p>这个场景中，将会测试$uri是否存在，如果存在调用该服务，反之则会测试该目录是否存在，如果不存在就会调用 <code>index.html</code>，前提是<code>index.html</code>是存在的。这时候仅仅是简单的加载该页面。</p>

<h3 id="section-2">[包的前端控制器模式]</h3>

<p>“前端控制器模式”的设计很流行并广泛应用于 PHP 软件包，不乏很多比它更复杂的例子，使用 Drupal, Joomla 等，你只需要使用</p>

<p><code>
try_files $uri $uri/ /index.php?q=$uri&amp;$args;
</code></p>

<p>注意： - 参数名会依据你所使用的包不同而做相应的改变</p>

<ul>
  <li><code>q</code>用于Drupal, Joomla, WordPress</li>
  <li><code>page</code> 用于CMS Made Simple</li>
</ul>

<p>一些软件甚至不需要查询字符串，可以通过<code>REQUEST_URI</code>获取（比如WordPress就支持）</p>

<p><code>
try_files $uri $uri/ /index.php;
</code></p>

<p>当然，你的情况可能有所不一样，你可能需要更复杂的配置。对于简单的站点，该配置已经完美的支持，通常我们都是由浅入深地学习一样东西 。</p>

<p>如果你不关心目录是否存在，你可以决定跳过该目录检查,并且移 <code>$uri/</code></p>

<h3 id="php">[传递不受控制的请求给PHP]</h3>
<p>很多 PHP web 站点的 Nginx 配置要求，每一个URI需要附带<code>.php</code>给 PHP 解释器，注意到这里有一个关于PHP设置的严重安全隐患，因为它允许第三方执行任意代码。</p>

<p>比如</p>

<p><code>
location ~* \.php$ {
  fastcgi_pass backend;
  ...
}
</code></p>

<p>这里每一个关于.php的请求将会传给 <code>FastCGI</code> 后端，这是PHP默认配置，在不知道文件的具体路径下,试图通过该配置执行该文件。</p>

<p>举个例子，如果请求 <code>/forum/avatar/1232.jpg/file.php</code>不存在， PHP 解释器将会返回 <code>forum/avatar/1232.jpg</code>，如果该文件有内嵌php代码，就会相应地被执行了。</p>

<p>避免上述情况的配置选项是：</p>

<ul>
  <li>设置 php.ini 里的 <code>cgi.fix_pathinfo=0</code>，该配置使得 php 解释器仅仅执行具体制定的文件，停止执行不存在的文件。</li>
  <li>确保 nginx 指定具体的php可执行文件</li>
</ul>

<p><code>
location ~* (file_a|file_b|file_c)\.php$ {
  fastcgi_pass backend;
  ...
}
</code>
* 禁止执行用户上传目录中的php文件 </p>

<p><code>
location /uploaddir {
  location ~ \.php$ {return 403;}
  ...
}
</code></p>

<ul>
  <li>使用 <code>try_files</code>指令，过滤掉有问题的条件</li>
</ul>

<p><code>
location ~* \.php$ {
  try_files $uri =404;
  fastcgi_pass backend;
  ...
}
</code></p>

<ul>
  <li>使用嵌套块过滤有问题的条件</li>
</ul>

<p>```
location ~* .php$ {
  location ~ ..<em>/.</em>.php$ {return 404;}
  fastcgi_pass backend;
  …
}</p>

<p>```</p>

<h3 id="fastcgi-">[脚本文件名中的 FastCGI 路径]</h3>
<p>外界很多配置指引依靠绝对路径来获取你的信息，在PHP配置块内经常存在，当你从软件仓库中安装 nginx,他的配置文件中会有 “include fastcgi_params”,该文件在 nginx 文件夹 /etc/nginx 的目录下。</p>

<p>正确的配置</p>

<p><code>
fastcgi_param  SCRIPT_FILENAME    $document_root$fastcgi_script_name;
</code></p>

<p>不好的配置</p>

<p><code>
fastcgi_param  SCRIPT_FILENAME    /var/www/yoursite.com/$fastcgi_script_name;
</code></p>

<p><code>$document_root</code> 在哪里呢？他在<code>server</code>块中<code>root</code>指令，如果你的<code>root</code> 指令配置不存在， 请回头看看 <code>第一个陷阱</code>。</p>

<h3 id="section-3">[麻烦的重写]</h3>
<p>不要感到沮丧，你很容易被正则表达式迷糊住。事实上，我们可以努力让配置干净简洁不添加毫不相干的东西。</p>

<p>不好的配置</p>

<p><code>
rewrite ^/(.*)$ http://domain.com/$1 permanent;
</code></p>

<p>不好的配置</p>

<p><code>
rewrite ^ http://domain.com$request_uri? permanent;
</code></p>

<p>正确的配置</p>

<p><code>
return 301 http://domain.com$request_uri;
</code></p>

<p>反复看这几个例子，OK，第一个重写捕获斜线前完整的URI。通过使用内置的变量 <code>$request_uri</code> 我们可以有效地避免做任何捕获或匹配,并通过返回指令,我们可以完全避免对正则表达式的使用。</p>

<h3 id="http">[重写时丢失<code>http://</code>]</h3>
<p>很简单，重写都是相互关联的，除非你特意设置nginx。重写规则挺简单的，仅仅添加一条规则。</p>

<p>不好的配置</p>

<p><code>
 rewrite ^/blog(/.*)$ blog.domain.com$1 permanent;
</code></p>

<p>正确的配置</p>

<p><code>
rewrite ^/blog(/.*)$ http://blog.domain.com$1 permanent;
</code></p>

<p>上述看到的例子，我们仅仅是给该条规则添加了<code>http://</code>，便实现了重写，很简单，也很实用。</p>

<h3 id="section-4">[代理一切]</h3>

<p>不好的配置</p>

<p>```
server {
    server_name example.org;
    root /var/www/site;</p>

<pre><code>location / {
    include fastcgi_params;
    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
    fastcgi_pass unix:/tmp/phpcgi.socket;
} } ```
</code></pre>

<p>这个例子中，你转发请求给php,如果是 apache 服务器会这么干。但是 nginx 服务器不需要这样做，<code>try_files</code>指令会按顺序检测文件。这意味着nginx可以首先寻找需要测试的静态文件，如果找不到才返回用户指定的文件。通过这样的方式，php解释器不会执行任意php文件，除非你拥有该请求路径的php文件，而且能帮你节约资源，特别是当你直接通过php请求一个大小为1MB的图片1千次。</p>

<p>正确的配置</p>

<p>```
server {
    server_name example.org;
    root /var/www/site;</p>

<pre><code>location / {
    try_files $uri $uri/ @proxy;
}
 
location @proxy {
    include fastcgi.conf;
    fastcgi_pass unix:/tmp/php-fpm.sock;
} } ```
</code></pre>

<p>或者</p>

<p>```
server {
    server_name example.org;
    root /var/www/site;</p>

<pre><code>location / {
    try_files $uri $uri/ /index.php;
}
 
location ~ \.php$ {
    include fastcgi.conf;
    fastcgi_pass unix:/tmp/php-fpm.sock;
} } ```
</code></pre>

<p>如果被请求的 URI 存在就可以被 nginx 返回，如果不存在，那么是否存在一个具有index文件的目录里，同时，我们是否已经为该请求配置上了 index 指令。如果仍然不存在，重写规则将发送<code>index.php</code>到你的后端，只有当nginx前端不能处理你的请求，才会让后端服务参与进来。</p>

<p>想想有你的请求中有多少是静态资源，比如图片，css，javascript,我们可以通过上述方式的配置来节约这些资源。</p>

<h3 id="section-5">[配置改变，并没有生效]</h3>

<p>你的配置很完美，但是你依然捶胸顿足。问题出现在你的浏览器缓存上，当你加载一些东西，浏览器会保存下来，也会记住了它是如何请求服务的，如果你使用 <code>types{}</code>块，你会遇到如下问题。</p>

<p>修复</p>

<p>[选项1] 在火狐中按下 <code>Ctrl+Shift+Delet</code> ,检测缓存，并且清空。其他的浏览器自行搜索清空缓存的方法，每一次修改配置，记得清空缓存，除非你确认不需要这么做，这一步骤会帮你避免很多头痛。</p>

<p>在火狐中，你也可以选择一个更长久的解决方法，在URI搜索条内，输入<code>about:config</code>,然后搜索 <code>browser.cache.check_doc_frequency</code> ，设置其值为1，这样没加载一次包就会检测。</p>

<p>[选项2] 使用 <code>curl</code>
如果还行不通，而且你是在<code>vritualbox</code> 虚拟机里面运行 nginx,那么，可能是 <code>sendfile()</code> 惹得祸，你只需要注释掉 sendfile 指令，或者将其设置为 <code>off</code>,这个指令在<code>nginx.conf</code>里。</p>

<p><code>
sendfile off
</code></p>

<h3 id="http-1">[HTTP头部丢失]</h3>

<p>如果你没有显性设置 </p>

<p><code>
 underscores_in_headers on
</code></p>

<p>nginx 将会默认用下划线去掉http头部（这符合http标准），这么做是为了防止在映射CGI头信息时候有歧义。这个过程中破折号和下划线都被映射成了下划线。</p>
]]></content>
  </entry>
  
</feed>
