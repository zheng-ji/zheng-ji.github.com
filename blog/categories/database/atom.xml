<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: DataBase | 织网]]></title>
  <link href="http://zheng-ji.github.com/blog/categories/database/atom.xml" rel="self"/>
  <link href="http://zheng-ji.github.com/"/>
  <updated>2015-08-17T23:29:59+08:00</updated>
  <id>http://zheng-ji.github.com/</id>
  <author>
    <name><![CDATA[zheng-ji]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[my.cnf配置依据]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/07/12/my-dot-cnfpei-zhi-yi-ju/"/>
    <updated>2015-07-12T08:35:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/07/12/my-dot-cnfpei-zhi-yi-ju</id>
    <content type="html"><![CDATA[<p>阅读完<a href="http://book.douban.com/subject/6873681/">构建高性能服务器</a> 一书，书中对 <code>MySQL</code> 配置做了讲解，我用烂笔头记录一番，明白它们这么配置的真正意义，形成系统的认知。</p>

<ul>
  <li><a href="#第一节">通用配置</a></li>
  <li><a href="#第二节">innodb_pool_buffer 合理配置</a></li>
  <li><a href="#第三节">文件打开数的合理设置</a></li>
  <li><a href="#第四节">打开表优化设置</a></li>
  <li><a href="#第五节">临时表的设置</a></li>
  <li><a href="#第六节">查看索引命中率</a></li>
</ul>

<h3 id="第一节">通用配置</h3>

<p><code>
skip-name-resolve:
</code></p>

<p>禁止 MySQL 对外连接 DNS 解析 ,这一选项可以消除 MySQL 进行DNS解析时间，开启该选项，所有远程主机连接授权都要使用 IP。</p>

<p><code>
back_log=512
</code></p>

<p>指出在 MySQL 暂停响应之前，有多少个请求被存在堆栈中。</p>

<p><code>
key_buffer_size
</code></p>

<p>指定用于索引的缓冲区大小，增加它可得到更好的索引处理能力，对于内存 4G 左右，可设置为 256MB。</p>

<p><code>
max_allowed_packet=4M
</code>
设定在一次网络传输中的最大值。</p>

<p><code>
thread_stack=256k
</code>
设置每个线程的堆栈大小，可满足普通操作。</p>

<p><code>
table_cache=614k
</code>
高速缓冲区的大小，当mysql访问一个表示，缓冲区还有空间，那么这个表就会被放入缓冲区，一般看峰值时间状态值，open_tables与open_cache，用于判断是否需要增加table_cache，如果open_Table接近table_cache就要增加了。</p>

<p><code>
sort_buffer_size=6M
</code>
设定查询排序所用的缓冲区大小，是对每个链接而言，如果有100个连接，那么分配的总缓存是100*6=600M。
read_buffer_size,join_buffer_size 都是对单个链接而言。</p>

<p><code>
thread_cache_size=64
</code>
设置缓存中的链接线程的最大数量,4GB内存以上的我们会给64或者更大。</p>

<p><code>
query_cache_size=64M
</code></p>

<p>如果该值比较小反而会影响效率，可以考虑不用。如果太大，缓存区中碎片会很多。</p>

<p><code>
tmp_table_size
</code></p>

<p>设置内存临时表的最大值，如果超过改制，就会将临时表写入磁盘，范围是1kB-4GB。</p>

<p><code>
max_connection
</code></p>

<p>如果超过该值，会出现<code>too many connections</code>。</p>

<p><code>
max_connect_errors
</code>
设置每个主机中连接请求异常中断最大次数，如果超过，MySQL禁止host连接请求，直到MySQL重启。</p>

<p><code>
wait_timeout = 120
</code>
一个请求的最大链接时间。</p>

<p><code>
thread_concurrency=8
</code>
该参数为服务器逻辑CPU * 2。</p>

<p><code>
skip-networking
</code>
该选项可以关闭连接方式，如果需要远程连接，不要开启。</p>

<p><code>
innodb_flush_log_at_trx_commit = 1
</code>
设置为0就是等到 innodb_log_buffer_size 队列满了之后再统一存储，默认是1，是最安全的设置。</p>

<p><code>
innodb_thread_concurrency = 8
</code>
服务器几个CPU就设置多少。</p>

<p><code>
read_rnd_buffer_Size = 16M
</code></p>

<p>设置随机读的使用的缓冲区。</p>

<h3 id="第二节">innodb_buffer_pool 的合理设置</h3>

<p>不要武断的把innodb_buffer pool 配置为内存的50-80% 应具体而定。</p>

<p>```
show status like ‘innodb_buffer_pool_%’</p>

<p>关注的有
innodb_buffer_pool_pages_data;
innodb_buffer_pool_page_total;
innodb_buffer_pool_read_request;
innodb_buffer_pool_reads;
```</p>

<p>然后看</p>

<p><code>
读命中率 (innodb_buffer_pool_read_request - innodb_buffer_pool_reads) / innodb_buffer_pool_read_request;
写命中率 innodb_buffer_pool_pages_data /innodb_buffer_pool_page_total;
</code>
如果读写命中率都能在95%以上就很好了。</p>

<h3 id="第三节">文件打开数的合理设置依据</h3>

<p><code>
show global status like 'open_files'
show variables like 'open_file_limit';
</code>
比较合适的设置是 Open_files / open_files_limit * 100% &lt;= 75;</p>

<h3 id="第四节">打开表优化设置依据</h3>

<p><code>
show global status like 'open%tables';
show variable like 'table_cache';
</code>
比较合适</p>

<p><code>
open_tables / opende_tables * 100 &gt; 85%;
open_Tables / table_Cache* 100% &lt; 95%；
</code></p>

<h3 id="第五节">临时表的设置依据</h3>

<p>每次执行语句，关于已经被创造了的临时表的数量，可以这么设置:</p>

<p><code>
show gloabl status like 'created_tmp5';
Created_tmp_disk_table / Created_tmp_tables * 100% &lt;= 25 %
</code></p>

<h3 id="第六节">查看索引命中率</h3>

<p><code>
show global status like 'key_read%';
</code>
key_cache_miss_rate = key_Read / key_read_request * 100% 小于 1% 是很好的，
意味着1000个请求有一个直接读硬盘。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySQL Slave Relay log Corrupt 恢复]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/05/10/mysql-slave-relay-log-corrupt-chu-li-he-hui-fu/"/>
    <updated>2015-05-10T20:02:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/05/10/mysql-slave-relay-log-corrupt-chu-li-he-hui-fu</id>
    <content type="html"><![CDATA[<h3 id="section">现象</h3>
<p>周日早晨收到 <code>ganglia</code> 报警, 内容是：</p>

<p><code>
MySQL_Slave_SQL is 0.00
</code>
意味着从库同步有问题了。这时候进入从库看看状态</p>

<p><code>
show slave status\G;
</code></p>

<p>看到</p>

<p><code>
Slave_IO_State: Waiting for master to send event
   Master_Host: xxx.xxx.xxx
   Master_User: replication
   Master_Port: 3306
   Connect_Retry: 60
   Master_Log_File: mysql-bin.000028
   ad_Master_Log_Pos: 982714864
   Relay_Log_File: relay-bin.000143
   Relay_Master_Log_File: mysql-bin.000028
   Slave_IO_Running: Yes
   Slave_SQL_Running: No
   Replicate_Do_DB:
 Replicate_Ignore_DB:
 Replicate_Do_Table:
 Replicate_Ignore_Table:
 Replicate_Wild_Do_Table:
 Replicate_Wild_Ignore_Table:
 Last_Errno: 1594
 Last_Error: Relay log read failure: Could not parse relay log event entry. The possible reasons are: the master's binary log is corrupted (you can check this by running 'mysqlbinlog' on the binary log), the slave's relay log is corrupted (you can check this by running 'mysqlbinlog' on the relay log), a network problem, or a bug in the master's or slave's MySQL code. If you want to check the master's binary log or slave's relay log, you will be able to know their names by issuing 'SHOW SLAVE STATUS' on this slave.
 Skip_Counter: 3
 Exec_Master_Log_Pos: 974999870
 Relay_Log_Space: 399910514
 Until_Condition: None
</code></p>

<p>是因为从库的 relay log 损坏导致的从库停止执行同步, 后面从 MySQL 的错误日志发现是由几个没经过优化的大查询导致从库内存使用较大，mysqld_safe 被迫重启了。</p>

<h3 id="section-1">解决方法</h3>

<p>找到：</p>

<p><code>
Relay_Master_Log_File: mysql-bin.000028
Exec_Master_Log_Pos: 974999870
</code></p>

<p>执行</p>

<p><code>
mysql&gt; stop slave ;
mysql&gt; change master to master_log_file='mysql-bin.000028',master_log_pos=974999870;
mysql&gt; start slave;
</code></p>

<p>这样就重新追上了。以后还是要提高周围同事使用 MySQL 的优化意识啊。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[haproxy - MySQl 的负载均衡]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/02/03/haproxy-plus-mysql/"/>
    <updated>2015-02-03T23:17:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/02/03/haproxy-plus-mysql</id>
    <content type="html"><![CDATA[<p>服务器上每个PHP进程占用一个数据库链接，当有 n 台服务器, 每台服务器用用100 * m 个PHP 进程的时候，数据库的压力是有点小大。</p>

<p>为了解决这个问题, 可以有的选择是：</p>

<ul>
  <li>业内炒的比较火的有，奇虎<a href="https://github.com/Qihoo360/Atlas">Atlas</a>, 淘宝前架构师写的<a href="http://weibo.com/dbatools">OneProxy</a>, 官方的MySQL-Proxy;</li>
  <li>从连接层解决负载均衡的压力，Haproxy 所擅长的事情</li>
</ul>

<p>对于第一个选择，同事做过调研，使用起来不太放心。官方库就无人维护, 于是，最后选择了 Haproxy 来承担数据库的前端代理.链接数下降明显。</p>

<hr />

<h3 id="section">一些关键的配置</h3>

<p>参考<a href="http://www.sysads.co.uk/2014/08/install-haproxy-1-5-6-on-ubuntu-14-04/">连接</a>:</p>

<p>以下是配置内容</p>

<p>```
listen mysql-cluster
    bind 127.0.0.1:3306  # 连接本地3306 到后端的DB
    mode tcp
    option mysql-check user haproxy_check # haproxy_check 是该haproxy用户
    balance roundrobin
    server mysql-1 10.0.0.1:3306 check # 后端DB
    server mysql-2 10.0.0.2:3306 check # 后端DB</p>

<p>listen 0.0.0.0:8080 # 监控页面
    mode http
    stats enable
    stats uri /
    stats realm Strictly\ Private
    stats auth A_Username:YourPassword
    stats auth Another_User:passwd
```</p>

<p>值得注意的是，我们需要在DB 里面添加用户 haproxy_check,使得它有权限访问这个数据库。一开始我习惯用</p>

<p><code>
假设我的内网ip是 192.168.1.5
create user 'haproxy_check'@'192.168.1.5' identified by 'xxx';
flush privileges;
</code>
事实上这样连接 haproxy 会报：</p>

<p><code>
mysql -h127.0.0.1 -uusername -p
lost connection to mysql server at 'reading initial communication packet'
</code></p>

<p>后来老实按照 digitalocean 的文章修改成</p>

<p><code>
INSERT INTO mysql.user (Host,User) values ('192.168.1.5','haproxy_check');
flush privileges;
</code></p>

<p>测试就通过了.好奇怪，在我的理解中很不应该, 明天继续看看为什么会这么奇怪。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[搭建elasticsearch与kibana]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/01/31/da-jian-elasticsearchyu-kibana/"/>
    <updated>2015-01-31T12:52:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/01/31/da-jian-elasticsearchyu-kibana</id>
    <content type="html"><![CDATA[<p>ElasticSearch是一个基于Lucene构建的开源，分布式，RESTful搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速,
Kibana 是一个与之配套的 web 界面。</p>

<h3 id="section">安装所需的：</h3>

<ul>
  <li>需要openJDK</li>
  <li>下载并安装 <a href="http://www.elasticsearch.org/overview/elkdownloads/">elasticsearch-1.4.2.deb</a></li>
  <li>下载并安装 <a href="http://www.elasticsearch.org/overview/elkdownloads/">kibana-4.0.0-beta3.tar.gz</a></li>
</ul>

<h3 id="section-1">配置相关</h3>
<p>启动 elasticsearch 方式如下</p>

<p><code>
sudo service elasticsearch restart
</code></p>

<ul>
  <li>我是使用 <a href="http://wiki.zheng-ji.info/Sys/supervisor.html">supervisor</a> 启动 kibana, </li>
  <li>同时使用 <a href="http://wiki.zheng-ji.info/Sys/monit.html">monit</a> 监控elasticsearch </li>
</ul>

<p>在/etc/defaut/elasticsearch 配置数据文件目录的地址，log 地址，调整内存和堆栈大小，个人认为机器配置的50% 就可以了。</p>

<p>Nginx 配置，使得kibanan可以被外部访问，eleasticsearch 默认监听的是5601：</p>

<p><code>
server {
        listen 80;
        #auth_basic_user_file /home/ymserver/auth/kibana-user;
        error_log /home/ymserver/log/nginx/kibana.err.log;
        location / {
            proxy_pass http://127.0.0.1:5601$request_uri;
            proxy_set_header Host $http_host;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 
            proxy_set_header X-Forwarded-Proto $scheme;
        }
}
</code></p>

<h3 id="section-2">使用过程</h3>
<p>Python 有支持elasticsearch 的库 <a href="https://github.com/elasticsearch/elasticsearch-py">elasticsearch-py</a>，
用其导数据进入elasticsearch,需要指定好索引。</p>

<p>使用restful<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/">查询</a>， 
如下例子：其中’2014-12-18’是索引名，q后面是查询条件，_all表示全部索引</p>

<p><code>
curl -XGET 'http://localhost:9200/2014-12-18/_search/?q=name:861160022835011'
curl -XGET 'http://localhost:9200/_all/_search/?q=name:861160022835011'
curl -XGET localhost:9200/_search -d '
{
    "query": {
        "bool": {
            "must": [
            {
                "term": {
                    "field1": "X"
                }
            },
            {
                "term": {
                    "field3": "Z"
                }
            }
            ],
            "must_not": {
                "term": {
                    "field2": "Y"
                }
            }
        }
    }
}'
</code></p>

<h3 id="section-3">性能概述</h3>
<p>导入1个月的日志4.2G，31天的文件，每天一个索引，用了6个小时，elasticsearch用了 6.7G 的空间，在海量数据查询1s内响应。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Percona 小箱里的pt-archiver]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/01/21/percona-toolkitxiao-xiang-li-di-pt-archiver/"/>
    <updated>2015-01-21T23:27:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/01/21/percona-toolkitxiao-xiang-li-di-pt-archiver</id>
    <content type="html"><![CDATA[<p>在管理线上数据库，时常要做一些数据归档操作，在没有了解 <code>Percona toolkit</code> 之前，第一个想到的是在夜深人静的时候使用 <code>MySqlDump</code> 来完成这件事情。但它不是我们的优质选择，理由有：</p>

<ul>
  <li><code>MySqlDump</code> 只能备份在本机，不能直接做远端备份</li>
  <li>导出数据量太大的时候会锁表, 即使它的速度很快，但是在线上服务这是很危险的操作</li>
  <li>它仅仅只能导出，无法做到同时删除(可能不是太有必要)</li>
</ul>

<p>面对上述的场景，<code>Percona Toolkit</code> 让DBA 有了更好地选择，<a href="http://www.percona.com/doc/percona-toolkit/2.1/pt-archiver.html">pt-archiver</a> 应时而生。</p>

<h2 id="pt-archiver-">pt-archiver 介绍：</h2>

<p>根据官方文档的说法，几乎不会对线上的OTLP操作有影响：</p>

<blockquote>
  <p>The goal is a low-impact, forward-only job to nibble old data out of the table without impacting OLTP queries much</p>
</blockquote>

<p>它可以帮助我们将数据归档到文件, 另一个数据库，或者同一个数据库的另一个表, 亦或是用于合并两个表的内容。</p>

<h2 id="section">用法介绍：</h2>

<p><code>
pt-archiver [OPTION...] --source DSN --where WHERE
</code></p>

<p>归档的文件方便使用 load data infile 命令导入数据。另外你还可以用它来执行 delete 操作。这个工具默认的会删除源中的数据，使用的时候请注意。</p>

<p>假如我们将数据库里符合条件的记录归档到文件，并不做删除操作。</p>

<p><code>
pt-archiver --ask-pass --progress 100000 --no-delete --no-check-charset --source h=localhost,u=root,D=blog,t=comment--file /home/ubuntu/tmp/comment--where 'time &lt; "2013-12-31h"'
</code></p>

<p>注意的选项参数：</p>

<p><code>
--ask-pass        提示要求输密码
--progress num    执行num行在界面通知我们
--source h,D,t    数据源
--no-delete       加上这个参数并不会执行删除操作
--dry-run         仅仅将执行语句打印在终端，事实上并不执行。可以用于检测执行过程
--where           执行语句，需要用冒号包围起来
--limit           批量操作的数量，合理提高这个数值可以加快archive速度
</code></p>

<h3 id="section-1">小总结</h3>

<p>通过开启 mysql 的 <code>general log</code>, 可以发现pt-archiver 执行时，是分批commit 的事务，因此执行效率会慢，在8核16G 内存的生产环境机器备份 1kw 条记录, 耗时150 分钟。 但基本不对服务造成影响，而且可以不用深夜进行, 值得一用。</p>

<p>最近攒了好多好工具和经验，要好好整理搬上来和大家分享才是。</p>
]]></content>
  </entry>
  
</feed>
