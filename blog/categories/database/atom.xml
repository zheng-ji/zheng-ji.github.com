<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: DataBase | 织网]]></title>
  <link href="http://zheng-ji.github.com/blog/categories/database/atom.xml" rel="self"/>
  <link href="http://zheng-ji.github.com/"/>
  <updated>2015-01-21T23:54:35+08:00</updated>
  <id>http://zheng-ji.github.com/</id>
  <author>
    <name><![CDATA[zheng-ji]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Percona 小箱里的pt-archiver]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/01/21/percona-toolkitxiao-xiang-li-di-pt-archiver/"/>
    <updated>2015-01-21T23:27:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/01/21/percona-toolkitxiao-xiang-li-di-pt-archiver</id>
    <content type="html"><![CDATA[<p>在管理线上数据库，时常要做一些数据归档操作，在没有了解 <code>Percona toolkit</code> 之前，第一个想到的是在夜深人静的时候使用 <code>MySqlDump</code> 来完成这件事情。但它不是我们的优质选择，理由有：</p>

<ul>
  <li><code>MySqlDump</code> 只能备份在本机，不能直接做远端备份</li>
  <li>导出数据量太大的时候会锁表, 即使它的速度很快，但是在线上服务这是很危险的操作</li>
  <li>它仅仅只能导出，无法做到同时删除(可能不是太有必要)</li>
</ul>

<p>面对上述的场景，<code>Percona Toolkit</code> 让DBA 有了更好地选择，<a href="http://www.percona.com/doc/percona-toolkit/2.1/pt-archiver.html">pt-archiver</a> 应时而生。</p>

<h2 id="pt-archiver-">pt-archiver 介绍：</h2>

<p>根据官方文档的说法，几乎不会对线上的OTLP操作有影响：</p>

<blockquote>
  <p>The goal is a low-impact, forward-only job to nibble old data out of the table without impacting OLTP queries much</p>
</blockquote>

<p>它可以帮助我们将数据归档到文件, 另一个数据库，或者同一个数据库的另一个表, 亦或是用于合并两个表的内容。</p>

<h2 id="section">用法介绍：</h2>

<p><code>
pt-archiver [OPTION...] --source DSN --where WHERE
</code></p>

<p>归档的文件方便使用 load data infile 命令导入数据。另外你还可以用它来执行 delete 操作。这个工具默认的会删除源中的数据，使用的时候请注意。</p>

<p>假如我们将数据库里符合条件的记录归档到文件，并不做删除操作。</p>

<p><code>
pt-archiver --ask-pass --progress 100000 --no-delete --no-check-charset --source h=localhost,u=root,D=blog,t=comment--file /home/ubuntu/tmp/comment--where 'time &lt; "2013-12-31h"'
</code></p>

<p>注意的选项参数：</p>

<p><code>
--ask-pass        提示要求输密码
--progress num    执行num行在界面通知我们
--source h,D,t    数据源
--no-delete       加上这个参数并不会执行删除操作
--dry-run         仅仅将执行语句打印在终端，事实上并不执行。可以用于检测执行过程
--where           执行语句，需要用冒号包围起来
--limit           批量操作的数量，合理提高这个数值可以加快archive速度
</code></p>

<h3 id="section-1">小总结</h3>

<p>通过开启 mysql 的 <code>general log</code>, 可以发现pt-archiver 执行时，是分批commit 的事务，因此执行效率会慢，在8核16G 内存的生产环境机器备份 1kw 条记录, 耗时150 分钟。 但基本不对服务造成影响，而且可以不用深夜进行, 值得一用。</p>

<p>最近攒了好多好工具和经验，要好好整理搬上来和大家分享才是。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[唯一索引引发的思考]]></title>
    <link href="http://zheng-ji.github.com/blog/2014/10/23/mysql-unique-index/"/>
    <updated>2014-10-23T23:18:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2014/10/23/mysql-unique-index</id>
    <content type="html"><![CDATA[<p>最近需要改动线上一个有千万条记录的表，涉及到加字段操作，这个表有索引，按照经验，为了加速修改表结构,去掉索引。由于我删除的是Unique Index, 而服务一直在写,程序依赖数据库的唯一索引去重,导致瞬间有重复数据,唯一索引重新加上时会报 <code>Duplicated Key entry Error</code>,</p>

<h3 id="section">回放事件</h3>

<p>我们的数据表，之前是有 <code>UNIQUE INDEX(cuid, aid)</code>, 因为去掉索引，服务持续写入，导致有重复记录，所幸的是，这是一个统计表, 不影响功能，所以需要找出重复的记录</p>

<p><code>
select cuid,aid from (
    select cuid, aid,count(1) as num
    from register_chn 
    group by cuid,aid having num &gt; 1
) t;
</code></p>

<p>显示有8条记录,如果手动删除,是很慢且愚蠢的做法,还是用 SQL 执行,镇定之后执行</p>

<p><code>
delete from register_chn where (cuid,aid) in (
    select cuid,aid from (
        select cuid, aid,count(1) as num
        from register_chn
        group by cuid,aid having num &gt; 1
    ) t
);
</code>
影响了８条记录.然后瞬间加上索引.所幸是成功了, 事实上当时的合理操作应该是用事务。</p>

<p><code>
BEGIN;
delete from register_chn where (cuid,aid) in (
    select cuid,aid from (
        select cuid, aid,count(1) as num
        from register_chn
        group by cuid,aid having num &gt; 1
    ) t
);
alter table register_chn add unique index(cuid, aid);
COMMINT;
</code></p>

<h3 id="section-1">引发的思考</h3>

<p>后来想想, 上述方法虽然解决问题了, 但是有点碰运气成分。如果频繁快速地产生重复记录,也许就没那么好运了,事实上可以执行以下 SQL:</p>

<p><code>
alter ignore table register_chn add unique index(cuid, aid)；
</code></p>

<p>如果你以为很简单,那就错了。这个方法在 MySQL 5.0 上使用是没问题的，但是在5.6 之前是有bug的，亲自测试Percona 版本5.5, 的确会失败
官方的解决方法是：</p>

<p><code>
set session old_alter_table = on;
alter ignore table register_chn add unique index(cuid, aid);
</code></p>

<p>在有主备的情况,记得执行前设置一下</p>

<p><code>
set session sql_log_bin=off. 
</code>
以免备库报错。同样还需要在备库重复一下主库的操作, 这也算是一个不太完美的解决思路。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mysql的一些配置]]></title>
    <link href="http://zheng-ji.github.com/blog/2014/10/21/mysqlde-na-xie-dong-tai-bian-liang/"/>
    <updated>2014-10-21T23:18:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2014/10/21/mysqlde-na-xie-dong-tai-bian-liang</id>
    <content type="html"><![CDATA[<p>我想写一篇长期更新的文章，随着知识积累持续更新的文章，而最近遇到的在涉及的Mysql优化，便是一个可以琢磨的点，变量比较多，并且需要在每次采坑才来的深刻。</p>

<ul>
  <li>tmp_table_size
这个是临时表的大小，与之对应的有 <code>max_heap_size</code> 单位是Byte, <code>tmp_table_size</code> 的大小关乎临时表的大小, 如果设置太小，会导致一些数据直接写入磁盘，比较蛋疼, 看了官方文档，涉及到<code>Dynamic Variable=Yes</code>
那么这种配置便可以直接在终端用语句设置，并生效，不需要重启机器</li>
</ul>

<p><code>
set global tmp_table_size = 512 * 1024 *1024 
</code></p>

<ul>
  <li>max_connections
当<code>show processlist</code> 发现有好多链接的时候，客户端想登陆mysql却失败。可以执行, 看看是不是现有的链接数已经逼近</li>
</ul>

<p><code>
show global variable like '%max%'
set global max_connections 1000
</code>
* thread_concurrency</p>

<p>同一时间与性的线程设置，如果分配不当，会导致<code>mysql</code>不能充分使用多｀cpu｀, 出现同一时刻只有一个核在工作。
<code>thread_concurrency</code> 应设为<code>CPU</code> 核数的2倍. 比如有一个双核的CPU, 那么<code>thread_concurrency</code>的应该为4; 2个双核的cpu, <code>thread_concurrency</code>的值应为8.</p>

<ul>
  <li>max_allowed_packet
如果需要进行mysqldump这类操作，需要调大</li>
</ul>

<p><code>
set global max_allowed_packet = 2*1024*1024*10
</code></p>

<ul>
  <li>skip_slave_start
配置文件中建议加上skip-slave-start，以免在不需要时候slave线程自己开始执行了</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[redis热备]]></title>
    <link href="http://zheng-ji.github.com/blog/2014/10/04/redisre-bei/"/>
    <updated>2014-10-04T22:28:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2014/10/04/redisre-bei</id>
    <content type="html"><![CDATA[<p>一转眼到了 10 月份了, 依然很忙, 好多碰到的，解决了的, 没能解决的蛋疼问题, 那些一闪而过的被记载于 evernote里, 信誓旦旦说过要记载下来，终究也还是被时间欺骗。 </p>

<p>在过去的九月份，我们迁移了一批业务到云上。除了 mysql 需要热备处理，redis-server 同样也面临这种问题。相比起来，redis 的热备显得更为简单。</p>

<p>为了可以更好地阐述过程，我们定义了三个角色</p>

<ul>
  <li>A 服务器，原来拥有 redis 数据库的机器 </li>
  <li>B 服务器，未来取代 A 服务器的 redis 数据库服务器</li>
  <li>
    <p>C 服务器，B 服务器的 slave</p>
  </li>
  <li>我们在停止服务的5分钟，在 A 的命令行，执行</li>
</ul>

<p><code>
bgsave
</code></p>

<p>使得内存里的数据，完整地保存于 dumps.rdb</p>

<ul>
  <li>
    <p>配置好 B 服务器的redis server, 用上述的 dumps.rdb 取代该服务器的 dumps.rdb , 这里说的配置好，需要指定好 bind-address, 推荐使用内网 IP, 备份目录</p>
  </li>
  <li>
    <p>在 C 服务器的 redis 配置上 更改为:</p>
  </li>
</ul>

<p><code>
slaveof  IP地址 端口
slave-serve-stale-data no
slave-read-only yes # 只读
</code></p>

<p>这样就开始备份了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Percona Server 做主从]]></title>
    <link href="http://zheng-ji.github.com/blog/2014/09/07/percona-server-zuo-zhu-cong/"/>
    <updated>2014-09-07T15:31:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2014/09/07/percona-server-zuo-zhu-cong</id>
    <content type="html"><![CDATA[<p>数据库做主从，这个过程是需要很耐心的。</p>

<p>数据库做主从目的:</p>

<ul>
  <li>故障恢复， 柔性可用</li>
  <li>也可以做读写分离</li>
</ul>

<p>实验过程中 mysql 用的版本是 Percona Server ，</p>

<p><a href="http://www.percona.com/doc/percona-server/5.5/installation/apt_repo.html">安装过程</a></p>

<p>由于修改默认的数据目录，数据文件不再使用 <code>/var/lib/mysql</code>,数据文件夹被我安放位置是 <code>/data/mysql/data</code> 同时log 目录也放在这里 <code>/data/mysql/log</code> 
注意需要修改目录属主</p>

<p><code>
sudo chown mysql:mysql  -R /data/mysql
然后执行 sudo mysql_install_db 
</code></p>

<p>这时候会发生 <code>sudo service mysql stop</code> 失败，原因和方法见此 <a href="http://serverfault.com/questions/32692/cant-start-stop-mysql-service/420222#420222">神贴</a></p>

<p>好了开始进入正题了，备份数据的原理</p>

<ul>
  <li>在主库上把数据更改记录到二进制日志 (Binary Log) </li>
  <li>备库将主库的日志复制到自己的中继日志中</li>
  <li>备库读取中继日志的事件，将其重放到备库的数据之上</li>
</ul>

<p>从其他服务器克隆备库的方法：</p>

<ul>
  <li>使用冷备份：关闭主库，将数据复制到备库，重启主库后，会使用一个新的二进制日志文件，在备库执行 CHANGE MASTER TO 指向这个文件的起始处，缺陷在于关闭主库</li>
  <li>使用热备份，如果仅使用，mysqlhotcopy,或rsync来复制数据</li>
  <li>使用快照或备份：需要知道二进制日志坐标，就可以使用主库的快照和备份来初始化备库，只需要把备份或快照恢复到备库，然后使用 CHANGE MASTER TO 指定二进制日志的坐标.</li>
  <li>用<code>Percona Xtrabackup</code>  个人推荐  <a href="http://www.percona.com/doc/percona-xtrabackup/2.1/howtos/setting_up_replication.html">链接</a></li>
</ul>

<p>======= 实际的步骤如下 ====</p>

<ul>
  <li>备份主库的数据</li>
</ul>

<p><code>
innobackupex --user=root --password=xxx /home/zj/backup
</code>
在/home/zj/backup目录下就生成了2014-08-21_10-11-4` 目录</p>

<ul>
  <li>复制数据到从库，通过<code>scp</code>将上一步生成的目录放置在从库机器(~/tmp`)将原来的data目录备份, 在从库机器执行</li>
</ul>

<p><code>
mv /data/mysql/data /data/mysql/data_bak
mv ~/tmp/2014-08-21_10-11-46  /data/mysql/data
chown mysql:mysql -R /data/mysql/data
</code></p>

<ul>
  <li>配置主服务器</li>
</ul>

<p><code>
GRANT REPLICATION SLAVE ON *.*  TO 'repl'@'$slaveip' IDENTIFIED BY ''slavepass
</code></p>

<ul>
  <li>配置从数据库,并重启</li>
</ul>

<p><code>
server-id=2
</code></p>

<ul>
  <li>开始复制</li>
</ul>

<p>需要定位位置</p>

<p><code>
cat /data/mysql/data/xtrabackup_binlog_info
log-bin.000001     481
</code></p>

<ul>
  <li>在从库执行 </li>
</ul>

<p><code>
mysql&gt; CHANGE MASTER TO MASTER_HOST='$masterip',
       MASTER_USER='repl',
       MASTER_PASSWORD='$slavepass',
       MASTER_LOG_FILE='log-bin.000001',
       MASTER_LOG_POS=481;
mysql&gt; START SLAVE;
mysql&gt; SHOW SLAVE STATUS \G
</code></p>

<hr />

<p>系统学习的书籍，感谢杨先生推荐 : )
<a href="http://book.douban.com/subject/23008813/">高性能mysql</a></p>

]]></content>
  </entry>
  
</feed>
