<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: DataBase | 织网]]></title>
  <link href="http://zheng-ji.github.com/blog/categories/database/atom.xml" rel="self"/>
  <link href="http://zheng-ji.github.com/"/>
  <updated>2015-02-06T00:14:00+08:00</updated>
  <id>http://zheng-ji.github.com/</id>
  <author>
    <name><![CDATA[zheng-ji]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[haproxy - MySQl 的负载均衡]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/02/03/haproxy-plus-mysql/"/>
    <updated>2015-02-03T23:17:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/02/03/haproxy-plus-mysql</id>
    <content type="html"><![CDATA[<p>服务器上每个PHP进程占用一个数据库链接，当有 n 台服务器, 每台服务器用用100 * m 个PHP 进程的时候，数据库的压力是有点小大。</p>

<p>为了解决这个问题, 可以有的选择是：</p>

<ul>
  <li>业内炒的比较火的有，奇虎<a href="https://github.com/Qihoo360/Atlas">Atlas</a>, 淘宝前架构师写的<a href="http://weibo.com/dbatools">OneProxy</a>, 官方的MySQL-Proxy;</li>
  <li>从连接层解决负载均衡的压力，Haproxy 所擅长的事情</li>
</ul>

<p>对于第一个选择，同事做过调研，使用起来不太放心。官方库就无人维护, 于是，最后选择了 Haproxy 来承担数据库的前端代理.链接数下降明显。</p>

<hr />

<h3 id="section">一些关键的配置</h3>

<p>参考<a href="http://www.sysads.co.uk/2014/08/install-haproxy-1-5-6-on-ubuntu-14-04/">连接</a>:</p>

<p>以下是配置内容</p>

<p>```
listen mysql-cluster
    bind 127.0.0.1:3306  # 连接本地3306 到后端的DB
    mode tcp
    option mysql-check user haproxy_check # haproxy_check 是该haproxy用户
    balance roundrobin
    server mysql-1 10.0.0.1:3306 check # 后端DB
    server mysql-2 10.0.0.2:3306 check # 后端DB</p>

<p>listen 0.0.0.0:8080 # 监控页面
    mode http
    stats enable
    stats uri /
    stats realm Strictly\ Private
    stats auth A_Username:YourPassword
    stats auth Another_User:passwd
```</p>

<p>值得注意的是，我们需要在DB 里面添加用户 haproxy_check,使得它有权限访问这个数据库。一开始我习惯用</p>

<p><code>
假设我的内网ip是 192.168.1.5
create user 'haproxy_check'@'192.168.1.5' identified by 'xxx';
flush privileges;
</code>
事实上这样连接 haproxy 会报：</p>

<p><code>
mysql -h127.0.0.1 -uusername -p
lost connection to mysql server at 'reading initial communication packet'
</code></p>

<p>后来老实按照 digitalocean 的文章修改成</p>

<p><code>
INSERT INTO mysql.user (Host,User) values ('192.168.1.5','haproxy_check');
flush privileges;
</code></p>

<p>测试就通过了.好奇怪，在我的理解中很不应该, 明天继续看看为什么会这么奇怪。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[搭建elasticsearch与kibana]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/01/31/da-jian-elasticsearchyu-kibana/"/>
    <updated>2015-01-31T12:52:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/01/31/da-jian-elasticsearchyu-kibana</id>
    <content type="html"><![CDATA[<p>ElasticSearch是一个基于Lucene构建的开源，分布式，RESTful搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速,
Kibana 是一个与之配套的 web 界面。</p>

<h3 id="section">安装所需的：</h3>

<ul>
  <li>需要openJDK</li>
  <li>下载并安装 <a href="http://www.elasticsearch.org/overview/elkdownloads/">elasticsearch-1.4.2.deb</a></li>
  <li>下载并安装 <a href="http://www.elasticsearch.org/overview/elkdownloads/">kibana-4.0.0-beta3.tar.gz</a></li>
</ul>

<h3 id="section-1">配置相关</h3>
<p>启动 elasticsearch 方式如下</p>

<p><code>
sudo service elasticsearch restart
</code></p>

<ul>
  <li>我是使用 <a href="http://wiki.zheng-ji.info/Sys/supervisor.html">supervisor</a> 启动 kibana, </li>
  <li>同时使用 <a href="http://wiki.zheng-ji.info/Sys/monit.html">monit</a> 监控elasticsearch </li>
</ul>

<p>在/etc/defaut/elasticsearch 配置数据文件目录的地址，log 地址，调整内存和堆栈大小，个人认为机器配置的50% 就可以了。</p>

<p>Nginx 配置，使得kibanan可以被外部访问，eleasticsearch 默认监听的是5601：</p>

<p><code>
server {
        listen 80;
        #auth_basic_user_file /home/ymserver/auth/kibana-user;
        error_log /home/ymserver/log/nginx/kibana.err.log;
        location / {
            proxy_pass http://127.0.0.1:5601$request_uri;
            proxy_set_header Host $http_host;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 
            proxy_set_header X-Forwarded-Proto $scheme;
        }
}
</code></p>

<h3 id="section-2">使用过程</h3>
<p>Python 有支持elasticsearch 的库 <a href="https://github.com/elasticsearch/elasticsearch-py">elasticsearch-py</a>，
用其导数据进入elasticsearch,需要指定好索引。</p>

<p>使用restful<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/">查询</a>， 
如下例子：其中’2014-12-18’是索引名，q后面是查询条件，_all表示全部索引</p>

<p><code>
curl -XGET 'http://localhost:9200/2014-12-18/_search/?q=name:861160022835011'
curl -XGET 'http://localhost:9200/_all/_search/?q=name:861160022835011'
curl -XGET localhost:9200/_search -d '
{
    "query": {
        "bool": {
            "must": [
            {
                "term": {
                    "field1": "X"
                }
            },
            {
                "term": {
                    "field3": "Z"
                }
            }
            ],
            "must_not": {
                "term": {
                    "field2": "Y"
                }
            }
        }
    }
}'
</code></p>

<h3 id="section-3">性能概述</h3>
<p>导入1个月的日志4.2G，31天的文件，每天一个索引，用了6个小时，elasticsearch用了 6.7G 的空间，在海量数据查询1s内响应。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Percona 小箱里的pt-archiver]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/01/21/percona-toolkitxiao-xiang-li-di-pt-archiver/"/>
    <updated>2015-01-21T23:27:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/01/21/percona-toolkitxiao-xiang-li-di-pt-archiver</id>
    <content type="html"><![CDATA[<p>在管理线上数据库，时常要做一些数据归档操作，在没有了解 <code>Percona toolkit</code> 之前，第一个想到的是在夜深人静的时候使用 <code>MySqlDump</code> 来完成这件事情。但它不是我们的优质选择，理由有：</p>

<ul>
  <li><code>MySqlDump</code> 只能备份在本机，不能直接做远端备份</li>
  <li>导出数据量太大的时候会锁表, 即使它的速度很快，但是在线上服务这是很危险的操作</li>
  <li>它仅仅只能导出，无法做到同时删除(可能不是太有必要)</li>
</ul>

<p>面对上述的场景，<code>Percona Toolkit</code> 让DBA 有了更好地选择，<a href="http://www.percona.com/doc/percona-toolkit/2.1/pt-archiver.html">pt-archiver</a> 应时而生。</p>

<h2 id="pt-archiver-">pt-archiver 介绍：</h2>

<p>根据官方文档的说法，几乎不会对线上的OTLP操作有影响：</p>

<blockquote>
  <p>The goal is a low-impact, forward-only job to nibble old data out of the table without impacting OLTP queries much</p>
</blockquote>

<p>它可以帮助我们将数据归档到文件, 另一个数据库，或者同一个数据库的另一个表, 亦或是用于合并两个表的内容。</p>

<h2 id="section">用法介绍：</h2>

<p><code>
pt-archiver [OPTION...] --source DSN --where WHERE
</code></p>

<p>归档的文件方便使用 load data infile 命令导入数据。另外你还可以用它来执行 delete 操作。这个工具默认的会删除源中的数据，使用的时候请注意。</p>

<p>假如我们将数据库里符合条件的记录归档到文件，并不做删除操作。</p>

<p><code>
pt-archiver --ask-pass --progress 100000 --no-delete --no-check-charset --source h=localhost,u=root,D=blog,t=comment--file /home/ubuntu/tmp/comment--where 'time &lt; "2013-12-31h"'
</code></p>

<p>注意的选项参数：</p>

<p><code>
--ask-pass        提示要求输密码
--progress num    执行num行在界面通知我们
--source h,D,t    数据源
--no-delete       加上这个参数并不会执行删除操作
--dry-run         仅仅将执行语句打印在终端，事实上并不执行。可以用于检测执行过程
--where           执行语句，需要用冒号包围起来
--limit           批量操作的数量，合理提高这个数值可以加快archive速度
</code></p>

<h3 id="section-1">小总结</h3>

<p>通过开启 mysql 的 <code>general log</code>, 可以发现pt-archiver 执行时，是分批commit 的事务，因此执行效率会慢，在8核16G 内存的生产环境机器备份 1kw 条记录, 耗时150 分钟。 但基本不对服务造成影响，而且可以不用深夜进行, 值得一用。</p>

<p>最近攒了好多好工具和经验，要好好整理搬上来和大家分享才是。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[唯一索引引发的思考]]></title>
    <link href="http://zheng-ji.github.com/blog/2014/10/23/mysql-unique-index/"/>
    <updated>2014-10-23T23:18:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2014/10/23/mysql-unique-index</id>
    <content type="html"><![CDATA[<p>最近需要改动线上一个有千万条记录的表，涉及到加字段操作，这个表有索引，按照经验，为了加速修改表结构,去掉索引。由于我删除的是Unique Index, 而服务一直在写,程序依赖数据库的唯一索引去重,导致瞬间有重复数据,唯一索引重新加上时会报 <code>Duplicated Key entry Error</code>,</p>

<h3 id="section">回放事件</h3>

<p>我们的数据表，之前是有 <code>UNIQUE INDEX(cuid, aid)</code>, 因为去掉索引，服务持续写入，导致有重复记录，所幸的是，这是一个统计表, 不影响功能，所以需要找出重复的记录</p>

<p><code>
select cuid,aid from (
    select cuid, aid,count(1) as num
    from register_chn 
    group by cuid,aid having num &gt; 1
) t;
</code></p>

<p>显示有8条记录,如果手动删除,是很慢且愚蠢的做法,还是用 SQL 执行,镇定之后执行</p>

<p><code>
delete from register_chn where (cuid,aid) in (
    select cuid,aid from (
        select cuid, aid,count(1) as num
        from register_chn
        group by cuid,aid having num &gt; 1
    ) t
);
</code>
影响了８条记录.然后瞬间加上索引.所幸是成功了, 事实上当时的合理操作应该是用事务。</p>

<p><code>
BEGIN;
delete from register_chn where (cuid,aid) in (
    select cuid,aid from (
        select cuid, aid,count(1) as num
        from register_chn
        group by cuid,aid having num &gt; 1
    ) t
);
alter table register_chn add unique index(cuid, aid);
COMMINT;
</code></p>

<h3 id="section-1">引发的思考</h3>

<p>后来想想, 上述方法虽然解决问题了, 但是有点碰运气成分。如果频繁快速地产生重复记录,也许就没那么好运了,事实上可以执行以下 SQL:</p>

<p><code>
alter ignore table register_chn add unique index(cuid, aid)；
</code></p>

<p>如果你以为很简单,那就错了。这个方法在 MySQL 5.0 上使用是没问题的，但是在5.6 之前是有bug的，亲自测试Percona 版本5.5, 的确会失败
官方的解决方法是：</p>

<p><code>
set session old_alter_table = on;
alter ignore table register_chn add unique index(cuid, aid);
</code></p>

<p>在有主备的情况,记得执行前设置一下</p>

<p><code>
set session sql_log_bin=off. 
</code>
以免备库报错。同样还需要在备库重复一下主库的操作, 这也算是一个不太完美的解决思路。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mysql的一些配置]]></title>
    <link href="http://zheng-ji.github.com/blog/2014/10/21/mysqlde-na-xie-dong-tai-bian-liang/"/>
    <updated>2014-10-21T23:18:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2014/10/21/mysqlde-na-xie-dong-tai-bian-liang</id>
    <content type="html"><![CDATA[<p>我想写一篇长期更新的文章，随着知识积累持续更新的文章，而最近遇到的在涉及的Mysql优化，便是一个可以琢磨的点，变量比较多，并且需要在每次采坑才来的深刻。</p>

<ul>
  <li>tmp_table_size
这个是临时表的大小，与之对应的有 <code>max_heap_size</code> 单位是Byte, <code>tmp_table_size</code> 的大小关乎临时表的大小, 如果设置太小，会导致一些数据直接写入磁盘，比较蛋疼, 看了官方文档，涉及到<code>Dynamic Variable=Yes</code>
那么这种配置便可以直接在终端用语句设置，并生效，不需要重启机器</li>
</ul>

<p><code>
set global tmp_table_size = 512 * 1024 *1024 
</code></p>

<ul>
  <li>max_connections
当<code>show processlist</code> 发现有好多链接的时候，客户端想登陆mysql却失败。可以执行, 看看是不是现有的链接数已经逼近</li>
</ul>

<p><code>
show global variable like '%max%'
set global max_connections 1000
</code>
* thread_concurrency</p>

<p>同一时间与性的线程设置，如果分配不当，会导致<code>mysql</code>不能充分使用多｀cpu｀, 出现同一时刻只有一个核在工作。
<code>thread_concurrency</code> 应设为<code>CPU</code> 核数的2倍. 比如有一个双核的CPU, 那么<code>thread_concurrency</code>的应该为4; 2个双核的cpu, <code>thread_concurrency</code>的值应为8.</p>

<ul>
  <li>max_allowed_packet
如果需要进行mysqldump这类操作，需要调大</li>
</ul>

<p><code>
set global max_allowed_packet = 2*1024*1024*10
</code></p>

<ul>
  <li>skip_slave_start
配置文件中建议加上skip-slave-start，以免在不需要时候slave线程自己开始执行了</li>
</ul>
]]></content>
  </entry>
  
</feed>
