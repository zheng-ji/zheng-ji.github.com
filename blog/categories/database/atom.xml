<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: DataBase | 织网]]></title>
  <link href="http://zheng-ji.github.com/blog/categories/database/atom.xml" rel="self"/>
  <link href="http://zheng-ji.github.com/"/>
  <updated>2015-06-11T23:21:46+08:00</updated>
  <id>http://zheng-ji.github.com/</id>
  <author>
    <name><![CDATA[zheng-ji]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[MySQL Slave Relay log Corrupt 恢复]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/05/10/mysql-slave-relay-log-corrupt-chu-li-he-hui-fu/"/>
    <updated>2015-05-10T20:02:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/05/10/mysql-slave-relay-log-corrupt-chu-li-he-hui-fu</id>
    <content type="html"><![CDATA[<h3 id="section">现象</h3>
<p>周日早晨收到 <code>ganglia</code> 报警, 内容是：</p>

<p><code>
MySQL_Slave_SQL is 0.00
</code>
意味着从库同步有问题了。这时候进入从库看看状态</p>

<p><code>
show slave status\G;
</code></p>

<p>看到</p>

<p><code>
Slave_IO_State: Waiting for master to send event
   Master_Host: xxx.xxx.xxx
   Master_User: replication
   Master_Port: 3306
   Connect_Retry: 60
   Master_Log_File: mysql-bin.000028
   ad_Master_Log_Pos: 982714864
   Relay_Log_File: relay-bin.000143
   Relay_Master_Log_File: mysql-bin.000028
   Slave_IO_Running: Yes
   Slave_SQL_Running: No
   Replicate_Do_DB:
 Replicate_Ignore_DB:
 Replicate_Do_Table:
 Replicate_Ignore_Table:
 Replicate_Wild_Do_Table:
 Replicate_Wild_Ignore_Table:
 Last_Errno: 1594
 Last_Error: Relay log read failure: Could not parse relay log event entry. The possible reasons are: the master's binary log is corrupted (you can check this by running 'mysqlbinlog' on the binary log), the slave's relay log is corrupted (you can check this by running 'mysqlbinlog' on the relay log), a network problem, or a bug in the master's or slave's MySQL code. If you want to check the master's binary log or slave's relay log, you will be able to know their names by issuing 'SHOW SLAVE STATUS' on this slave.
 Skip_Counter: 3
 Exec_Master_Log_Pos: 974999870
 Relay_Log_Space: 399910514
 Until_Condition: None
</code></p>

<p>是因为从库的 relay log 损坏导致的从库停止执行同步, 后面从 MySQL 的错误日志发现是由几个没经过优化的大查询导致从库内存使用较大，mysqld_safe 被迫重启了。</p>

<h3 id="section-1">解决方法</h3>

<p>找到：</p>

<p><code>
Relay_Master_Log_File: mysql-bin.000028
Exec_Master_Log_Pos: 974999870
</code></p>

<p>执行</p>

<p><code>
mysql&gt; stop slave ;
mysql&gt; change master to master_log_file='mysql-bin.000028',master_log_pos=974999870;
mysql&gt; start slave;
</code></p>

<p>这样就重新追上了。以后还是要提高周围同事使用 MySQL 的优化意识啊。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[haproxy - MySQl 的负载均衡]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/02/03/haproxy-plus-mysql/"/>
    <updated>2015-02-03T23:17:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/02/03/haproxy-plus-mysql</id>
    <content type="html"><![CDATA[<p>服务器上每个PHP进程占用一个数据库链接，当有 n 台服务器, 每台服务器用用100 * m 个PHP 进程的时候，数据库的压力是有点小大。</p>

<p>为了解决这个问题, 可以有的选择是：</p>

<ul>
  <li>业内炒的比较火的有，奇虎<a href="https://github.com/Qihoo360/Atlas">Atlas</a>, 淘宝前架构师写的<a href="http://weibo.com/dbatools">OneProxy</a>, 官方的MySQL-Proxy;</li>
  <li>从连接层解决负载均衡的压力，Haproxy 所擅长的事情</li>
</ul>

<p>对于第一个选择，同事做过调研，使用起来不太放心。官方库就无人维护, 于是，最后选择了 Haproxy 来承担数据库的前端代理.链接数下降明显。</p>

<hr />

<h3 id="section">一些关键的配置</h3>

<p>参考<a href="http://www.sysads.co.uk/2014/08/install-haproxy-1-5-6-on-ubuntu-14-04/">连接</a>:</p>

<p>以下是配置内容</p>

<p>```
listen mysql-cluster
    bind 127.0.0.1:3306  # 连接本地3306 到后端的DB
    mode tcp
    option mysql-check user haproxy_check # haproxy_check 是该haproxy用户
    balance roundrobin
    server mysql-1 10.0.0.1:3306 check # 后端DB
    server mysql-2 10.0.0.2:3306 check # 后端DB</p>

<p>listen 0.0.0.0:8080 # 监控页面
    mode http
    stats enable
    stats uri /
    stats realm Strictly\ Private
    stats auth A_Username:YourPassword
    stats auth Another_User:passwd
```</p>

<p>值得注意的是，我们需要在DB 里面添加用户 haproxy_check,使得它有权限访问这个数据库。一开始我习惯用</p>

<p><code>
假设我的内网ip是 192.168.1.5
create user 'haproxy_check'@'192.168.1.5' identified by 'xxx';
flush privileges;
</code>
事实上这样连接 haproxy 会报：</p>

<p><code>
mysql -h127.0.0.1 -uusername -p
lost connection to mysql server at 'reading initial communication packet'
</code></p>

<p>后来老实按照 digitalocean 的文章修改成</p>

<p><code>
INSERT INTO mysql.user (Host,User) values ('192.168.1.5','haproxy_check');
flush privileges;
</code></p>

<p>测试就通过了.好奇怪，在我的理解中很不应该, 明天继续看看为什么会这么奇怪。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[搭建elasticsearch与kibana]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/01/31/da-jian-elasticsearchyu-kibana/"/>
    <updated>2015-01-31T12:52:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/01/31/da-jian-elasticsearchyu-kibana</id>
    <content type="html"><![CDATA[<p>ElasticSearch是一个基于Lucene构建的开源，分布式，RESTful搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速,
Kibana 是一个与之配套的 web 界面。</p>

<h3 id="section">安装所需的：</h3>

<ul>
  <li>需要openJDK</li>
  <li>下载并安装 <a href="http://www.elasticsearch.org/overview/elkdownloads/">elasticsearch-1.4.2.deb</a></li>
  <li>下载并安装 <a href="http://www.elasticsearch.org/overview/elkdownloads/">kibana-4.0.0-beta3.tar.gz</a></li>
</ul>

<h3 id="section-1">配置相关</h3>
<p>启动 elasticsearch 方式如下</p>

<p><code>
sudo service elasticsearch restart
</code></p>

<ul>
  <li>我是使用 <a href="http://wiki.zheng-ji.info/Sys/supervisor.html">supervisor</a> 启动 kibana, </li>
  <li>同时使用 <a href="http://wiki.zheng-ji.info/Sys/monit.html">monit</a> 监控elasticsearch </li>
</ul>

<p>在/etc/defaut/elasticsearch 配置数据文件目录的地址，log 地址，调整内存和堆栈大小，个人认为机器配置的50% 就可以了。</p>

<p>Nginx 配置，使得kibanan可以被外部访问，eleasticsearch 默认监听的是5601：</p>

<p><code>
server {
        listen 80;
        #auth_basic_user_file /home/ymserver/auth/kibana-user;
        error_log /home/ymserver/log/nginx/kibana.err.log;
        location / {
            proxy_pass http://127.0.0.1:5601$request_uri;
            proxy_set_header Host $http_host;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 
            proxy_set_header X-Forwarded-Proto $scheme;
        }
}
</code></p>

<h3 id="section-2">使用过程</h3>
<p>Python 有支持elasticsearch 的库 <a href="https://github.com/elasticsearch/elasticsearch-py">elasticsearch-py</a>，
用其导数据进入elasticsearch,需要指定好索引。</p>

<p>使用restful<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/">查询</a>， 
如下例子：其中’2014-12-18’是索引名，q后面是查询条件，_all表示全部索引</p>

<p><code>
curl -XGET 'http://localhost:9200/2014-12-18/_search/?q=name:861160022835011'
curl -XGET 'http://localhost:9200/_all/_search/?q=name:861160022835011'
curl -XGET localhost:9200/_search -d '
{
    "query": {
        "bool": {
            "must": [
            {
                "term": {
                    "field1": "X"
                }
            },
            {
                "term": {
                    "field3": "Z"
                }
            }
            ],
            "must_not": {
                "term": {
                    "field2": "Y"
                }
            }
        }
    }
}'
</code></p>

<h3 id="section-3">性能概述</h3>
<p>导入1个月的日志4.2G，31天的文件，每天一个索引，用了6个小时，elasticsearch用了 6.7G 的空间，在海量数据查询1s内响应。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Percona 小箱里的pt-archiver]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/01/21/percona-toolkitxiao-xiang-li-di-pt-archiver/"/>
    <updated>2015-01-21T23:27:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/01/21/percona-toolkitxiao-xiang-li-di-pt-archiver</id>
    <content type="html"><![CDATA[<p>在管理线上数据库，时常要做一些数据归档操作，在没有了解 <code>Percona toolkit</code> 之前，第一个想到的是在夜深人静的时候使用 <code>MySqlDump</code> 来完成这件事情。但它不是我们的优质选择，理由有：</p>

<ul>
  <li><code>MySqlDump</code> 只能备份在本机，不能直接做远端备份</li>
  <li>导出数据量太大的时候会锁表, 即使它的速度很快，但是在线上服务这是很危险的操作</li>
  <li>它仅仅只能导出，无法做到同时删除(可能不是太有必要)</li>
</ul>

<p>面对上述的场景，<code>Percona Toolkit</code> 让DBA 有了更好地选择，<a href="http://www.percona.com/doc/percona-toolkit/2.1/pt-archiver.html">pt-archiver</a> 应时而生。</p>

<h2 id="pt-archiver-">pt-archiver 介绍：</h2>

<p>根据官方文档的说法，几乎不会对线上的OTLP操作有影响：</p>

<blockquote>
  <p>The goal is a low-impact, forward-only job to nibble old data out of the table without impacting OLTP queries much</p>
</blockquote>

<p>它可以帮助我们将数据归档到文件, 另一个数据库，或者同一个数据库的另一个表, 亦或是用于合并两个表的内容。</p>

<h2 id="section">用法介绍：</h2>

<p><code>
pt-archiver [OPTION...] --source DSN --where WHERE
</code></p>

<p>归档的文件方便使用 load data infile 命令导入数据。另外你还可以用它来执行 delete 操作。这个工具默认的会删除源中的数据，使用的时候请注意。</p>

<p>假如我们将数据库里符合条件的记录归档到文件，并不做删除操作。</p>

<p><code>
pt-archiver --ask-pass --progress 100000 --no-delete --no-check-charset --source h=localhost,u=root,D=blog,t=comment--file /home/ubuntu/tmp/comment--where 'time &lt; "2013-12-31h"'
</code></p>

<p>注意的选项参数：</p>

<p><code>
--ask-pass        提示要求输密码
--progress num    执行num行在界面通知我们
--source h,D,t    数据源
--no-delete       加上这个参数并不会执行删除操作
--dry-run         仅仅将执行语句打印在终端，事实上并不执行。可以用于检测执行过程
--where           执行语句，需要用冒号包围起来
--limit           批量操作的数量，合理提高这个数值可以加快archive速度
</code></p>

<h3 id="section-1">小总结</h3>

<p>通过开启 mysql 的 <code>general log</code>, 可以发现pt-archiver 执行时，是分批commit 的事务，因此执行效率会慢，在8核16G 内存的生产环境机器备份 1kw 条记录, 耗时150 分钟。 但基本不对服务造成影响，而且可以不用深夜进行, 值得一用。</p>

<p>最近攒了好多好工具和经验，要好好整理搬上来和大家分享才是。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[唯一索引引发的思考]]></title>
    <link href="http://zheng-ji.github.com/blog/2014/10/23/mysql-unique-index/"/>
    <updated>2014-10-23T23:18:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2014/10/23/mysql-unique-index</id>
    <content type="html"><![CDATA[<p>最近需要改动线上一个有千万条记录的表，涉及到加字段操作，这个表有索引，按照经验，为了加速修改表结构,去掉索引。由于我删除的是Unique Index, 而服务一直在写,程序依赖数据库的唯一索引去重,导致瞬间有重复数据,唯一索引重新加上时会报 <code>Duplicated Key entry Error</code>,</p>

<h3 id="section">回放事件</h3>

<p>我们的数据表，之前是有 <code>UNIQUE INDEX(cuid, aid)</code>, 因为去掉索引，服务持续写入，导致有重复记录，所幸的是，这是一个统计表, 不影响功能，所以需要找出重复的记录</p>

<p><code>
select cuid,aid from (
    select cuid, aid,count(1) as num
    from register_chn 
    group by cuid,aid having num &gt; 1
) t;
</code></p>

<p>显示有8条记录,如果手动删除,是很慢且愚蠢的做法,还是用 SQL 执行,镇定之后执行</p>

<p><code>
delete from register_chn where (cuid,aid) in (
    select cuid,aid from (
        select cuid, aid,count(1) as num
        from register_chn
        group by cuid,aid having num &gt; 1
    ) t
);
</code>
影响了８条记录.然后瞬间加上索引.所幸是成功了, 事实上当时的合理操作应该是用事务。</p>

<p><code>
BEGIN;
delete from register_chn where (cuid,aid) in (
    select cuid,aid from (
        select cuid, aid,count(1) as num
        from register_chn
        group by cuid,aid having num &gt; 1
    ) t
);
alter table register_chn add unique index(cuid, aid);
COMMINT;
</code></p>

<h3 id="section-1">引发的思考</h3>

<p>后来想想, 上述方法虽然解决问题了, 但是有点碰运气成分。如果频繁快速地产生重复记录,也许就没那么好运了,事实上可以执行以下 SQL:</p>

<p><code>
alter ignore table register_chn add unique index(cuid, aid)；
</code></p>

<p>如果你以为很简单,那就错了。这个方法在 MySQL 5.0 上使用是没问题的，但是在5.6 之前是有bug的，亲自测试Percona 版本5.5, 的确会失败
官方的解决方法是：</p>

<p><code>
set session old_alter_table = on;
alter ignore table register_chn add unique index(cuid, aid);
</code></p>

<p>在有主备的情况,记得执行前设置一下</p>

<p><code>
set session sql_log_bin=off. 
</code>
以免备库报错。同样还需要在备库重复一下主库的操作, 这也算是一个不太完美的解决思路。</p>

]]></content>
  </entry>
  
</feed>
