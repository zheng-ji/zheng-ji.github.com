<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: System | 织网]]></title>
  <link href="http://zheng-ji.github.com/blog/categories/system/atom.xml" rel="self"/>
  <link href="http://zheng-ji.github.com/"/>
  <updated>2015-12-05T17:09:45+08:00</updated>
  <id>http://zheng-ji.github.com/</id>
  <author>
    <name><![CDATA[zheng-ji]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Gre 隧道与 Keepalived]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/12/05/gre-tuning-and-keepalived/"/>
    <updated>2015-12-05T10:29:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/12/05/gre-tuning-and-keepalived</id>
    <content type="html"><![CDATA[<p>这一篇文章是做了不少功课的。</p>

<ul>
  <li><a href="#第一节">什么是 Gre 隧道</a></li>
  <li><a href="#第二节">什么是 Vrrp </a></li>
  <li><a href="#第三节">KeepAlived 是什么</a></li>
  <li><a href="#第四节">用Keepalived 怎么玩</a></li>
  <li><a href="#第五节">附录</a></li>
</ul>

<h3 id="第一节">什么是 Gre 隧道 </h3>

<p>GRE 隧道是一种 IP-2-IP 的隧道，是通用路由封装协议，可以对某些网路层协议的数据报进行封装，使这些被封装的数据报能够在 IPv4/IPv6 网络中传输。Tunnel 是一个虚拟的点对点的连接，提供了一条通路使封装的数据报文能够在这个通路上传输，并且在一个Tunnel 的两端分别对数据报进行封装及解封装。Linux 上创建 GRE 隧道，需要 ip_gre 内核模块，它是Pv4 隧道的驱动程序。</p>

<p>假设我有2台服务器，想做这两台之间创建 GRE 隧道</p>

<ul>
  <li>$server_A_ip 表示服务器A的IP</li>
  <li>$server_B_ip 服务器B 的内网IP</li>
</ul>

<p>```
# 在 A 机器上执行
# 创建 GRE 协议的 虚拟网络设备, 指定本地和对端 IP
sudo ip link add gretap1 type gretap local $server_a_ip remote $server_b_ip 
sudo ip link set dev gretap1 up  # 启动该设备
sudo ip addr add dev gretap1 10.1.1.2/24 # 给该设备一个虚拟网络地址</p>

<h1 id="b-">在 B 机器上执行</h1>
<p># 创建 GRE 协议的 虚拟网络设备, 指定本地和对端 IP
sudo ip link add gretap1 type gretap local $server_b_ip remote $server_a_ip 
sudo ip link set dev gretap1 up  # 启动该设备
sudo ip addr add dev gretap1 10.1.1.3/24 # 给该设备一个虚拟网络地址
```</p>

<p>如果想停止或者删除上述网卡</p>

<p><code>
ip link set gretap1 down
ip tunnel del gretap1
</code></p>

<p>至此点到点得隧道建立。</p>

<h3 id="第二节">什么是 vrrp 协议 </h3>

<p>VRRP(Virtual Router Redundancy Protocol), 即虚拟路由冗余协议。是实现路由器高可用的容错协议。</p>

<p>即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个 master 和多个 backup， 但在外界看来就像一台一样，构成虚拟路由器，拥有一个虚拟IP（vip），占有这个IP 的 master 实际负责 ARP 相应和转发 IP 数据包， 组中的其它路由器作为备份的角色处于待命状态。 master 会发组播消息，当 backup 在超时时间内收不到 vrrp 包时就认为 master 宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master，保证路由器的高可用。</p>

<h3 id="第三节"> Keepalived 是什么 </h3>

<p>Keepalived 是一个基于 VRRP 协议来实现的服务高可用方案，可以利用其来避免IP单点故障。</p>

<ul>
  <li>一个经典的案例</li>
</ul>

<p>一个WEB服务至少会有2台服务器运行 Keepalived，一台为主服务器，一台为备份服务器, 但是对外表现为一个虚拟IP，主服务器会发送特定的消息给备份服务器，当备份服务器收不到这个消息的时候，即主服务器宕机的时候，备份服务器就会接管虚拟IP，继续提供服务，从而保证了高可用性。</p>

<h3 id="第四节">怎么玩 Keepalived</h3>

<ul>
  <li>安装</li>
</ul>

<p><code>
sudo apt-get install keepalived
</code></p>

<p>之前提到的，我们在 A, B 两台服务器建立起了 GRE 隧道了。 现在我们有一个虚拟的内网IP， 姑且叫做 $virtual_third_ip
接着在 A 服务器上</p>

<ul>
  <li>配置</li>
</ul>

<p>编辑服务器 A, B 的 <code>/etc/keepalived/keepalived.conf</code></p>

<p>```</p>

<p>global_defs {
    router_id LVS_DEVEL
}</p>

<p>vrrp_instance VI_1 {
    state MASTER
    interface gretap1 # 绑在建立起来的隧道上
    virtual_router_id 51
    # 优先级别,越高的设备会被弄成主设备, A,B 服务器要有所差别，其他都一样
    priority 100          advert_int 1      # 广播时间间隔
    authentication {  #  验证相关
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        $virtual_third_ip dev eth0
    }
}
```</p>

<p>我们将服务器  A 作为 Master, 服务器 B 当做 Backup, 当服务器 A 需要停机的时候，$virtual_third_ip 就会漂移到服务器 B 上面。 我们两台机器都有相同配置的 Nginx 服务，就可以保障机器出现故障的时候，Nginx 服务丝毫不受影响。</p>

<h3 id="第五节"> 附录 </h3>

<ul>
  <li><a href="http://linux.vbird.org/linux_server/0140networkcommand.php">鸟哥的网络知识</a></li>
  <li><a href="http://www.tldp.org/HOWTO/Adv-Routing-HOWTO/lartc.tunnel.gre.html">GRE tuneling</a></li>
  <li><a href="http://baike.baidu.com/link?url=N1-VGuzQC0PJ2bCnOzYn-XRTlN8eFGCvIJQlTI6KDL5Fx3EQxoRGTrxazb11jfZQqlfeA6q2Ka0VKRVEc0Kdu3GEyhqe1W_Ae2h0Tqu5NacIjOSaSnUVeOe-9QV5dB8q0Wv_uq8-vqdnQICt39UZFK">VRRP</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[给 Tengine 加上 lua 拓展]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/10/29/gei-tengine-jia-shang-lua-tuo-zhan/"/>
    <updated>2015-10-29T22:45:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/10/29/gei-tengine-jia-shang-lua-tuo-zhan</id>
    <content type="html"><![CDATA[<p>Tengine 能动态加载第三方模块，成为我们青睐的选择，我们可以编译动态链接文件，而不需要重新安装 Nginx, 这对在线增强 webservice 很有帮助. 
感谢 agentzh, <a href="https://github.com/openresty/lua-nginx-module">lua-nginx-module</a>, 可以让我们使用 lua 增强nginx的功能, 不言而喻，我们必须现有 Lua 的环境，才能运行 ngx_lua;</p>

<h2 id="nginxlua">编译 nginx_lua</h2>

<p>官方推荐使用LuaJit,虽然也可以使用Lua，但是即时编译(Just-In-Time Compiler)混合了动态编译和静态编译，一句一句编译源代码，但是会将翻译过的代码缓存起来以降低性能损耗。</p>

<ul>
  <li>下载安装</li>
</ul>

<p><code>
wget http://luajit.org/download/LuaJIT-2.0.4.tar.gz
tar zxvf LuaJIT-2.0.4.tar.gz
cd LuaJIT-2.0.4
make
make install
</code></p>

<ul>
  <li>设置环境变量</li>
</ul>

<p><code>
export LUAJIT_LIB=/usr/local/lib
export LUAJIT_INC=/usr/local/include/luajit-2.0
</code></p>

<ul>
  <li>然后编译ngx-lua-module.so</li>
</ul>

<p><code>
/usr/local/share/dso_tool/ --path=/Path/To/Lua-Nginx-module
</code></p>

<ul>
  <li>设置动态库</li>
</ul>

<p><code>
&gt; echo "/usr/local/lib" &gt; /etc/ld.so.conf.d/usr_local_lib.conf
&gt; ldconfig
</code></p>

<h3 id="tengine-">在 Tengine 中启用</h3>

<p><code>nginx.conf</code> 中先加载动态库</p>

<p><code>
dso {
    load ngx_load_module;
}
</code></p>

<p>在 nginx.conf 中添加</p>

<p><code>
lua_code_cache on/off;
</code></p>

<p>来开启是否将代码缓存，所以每次变更 “*.lua” 文件时，必须重启 nginx 才可生效.</p>

<h3 id="ngxluawaf">使用 ngx_lua_waf</h3>

<p>有了基础环境，我们要开始发挥 ngx lua 的优点了, 我用他安装了 waf (web application firework)
<a href="https://github.com/loveshell/ngx_lua_waf">ngx_lua_waf</a>，这是一个通过 ngx_lua 编写的 web 应用防火墙, 在使用过程中也发现了 ngx_lua_waf 一个bug，给他提了一个<a href="https://github.com/loveshell/ngx_lua_waf/pull/70">Pull Request</a>, 码农生涯第一个 PR.</p>

<hr />

<p>注：
静态编译的程序在执行前全部被翻译为机器码，而动态直译执行的则是一句一句边运行边翻译。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sysdig 值得拥有]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/09/10/sysdig-zhi-de-yong-you/"/>
    <updated>2015-09-10T23:10:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/09/10/sysdig-zhi-de-yong-you</id>
    <content type="html"><![CDATA[<p>定位服务器问题时,  我们需要各式各样的武器, 诸如 iftop, ifstat, netstat, tcpdump, iostat。dstat 等, 因此工具箱需要装满很多工具, 在面对问题的时候才能显得不费吹灰之力, 迅速定位问题并解决, 保障服务稳定运行。Sysdig 的横空出世, 对我们而言, 就是一把瑞士军刀, 灵活小巧, 武艺多端.</p>

<ul>
  <li><a href="#第一节">安装</a></li>
  <li><a href="#第二节">常用操作</a></li>
  <li><a href="#第三节">高效的实战</a></li>
</ul>

<h3 id="第一节">安装</h3>

<p><code>
curl -s https://s3.amazonaws.com/download.draios.com/DRAIOS-GPG-KEY.public | apt-key add -
curl -s -o /etc/apt/sources.list.d/draios.list http://download.draios.com/stable/deb/draios.list
apt-get update
apt-get -y install sysdig
</code></p>

<h3 id="第二节">常用操作</h3>

<p>sysdig 有很多 chisel, chisel 意为 铲子, 可以理解为定位某类问题的工具, sysdig 采用 Lua 编写的。</p>

<ul>
  <li>查看 chisel 列表</li>
</ul>

<p><code>
sysdig -cl  
</code></p>

<ul>
  <li>查看具体某个 chisel 的提示</li>
</ul>

<p><code>
sysdig -i spy_logs
</code></p>

<ul>
  <li>使用某个 chisel</li>
</ul>

<p><code>
sysdig -c spy_logs
</code></p>

<ul>
  <li>过滤器可以帮助我们从各种输出信息中, 筛选出我们需要的, 比如 
<code>proc.name=foo</code> , 
如果你记住不了太多过滤器也无妨,  我们可以借助如下命令查看过滤器</li>
</ul>

<p><code>
sysdig -l
</code></p>

<ul>
  <li>记录定位信息到文本, 以及从文本读取信息</li>
</ul>

<p><code>
sysdig -w tracefile.cap
sysdig -r tracefile.dump proc.name=sshd
</code></p>

<h3 id="第三节">高效的实战</h3>

<ul>
  <li>服务器上经常需要查看哪个服务带宽占用使用较高, 特别是被 DDOS 的时候。</li>
</ul>

<p><code>
sudo sysdig -c topprocs_net
</code></p>

<ul>
  <li>查看某个IP的通讯数据,并以ASCII 码输出</li>
</ul>

<p><code>
sudo sysdig -s2000 -A -c echo_fds fd.cip=127.0.0.1
</code></p>

<ul>
  <li>查看非请求 redis-server 的其他请求进程和句柄</li>
</ul>

<p><code>
sudo sysdig -p"%proc.name %fd.name" "evt.type=accept and proc.name!=redis-server"
</code></p>

<ul>
  <li>查看访问该服务器的所有 GET 请求数据</li>
</ul>

<p><code>
sudo sysdig -s 2000 -A -c echo_fds fd.port=80 and evt.buffer contains GET
</code></p>

<ul>
  <li>查看访问该服务器的 SQL 语句</li>
</ul>

<p><code>
sudo sysdig -s 2000 -A -c echo_fds evt.buffer contains SELECT
</code></p>

<ul>
  <li>查看磁盘读写最高的进程</li>
</ul>

<p><code>
sysdig -c topprocs_file
</code></p>

<ul>
  <li>查看延迟最大的系统调用</li>
</ul>

<p><code>
sysdig -c topscalls_time
</code></p>

<ul>
  <li>查看具体文件的操作细节</li>
</ul>

<p><code>
sysdig -A -c echo_fds "fd.filename=syslog"
</code></p>

<ul>
  <li>查看 IO 延迟大于 1ms 的文件</li>
</ul>

<p><code>
sudo sysdig -c fileslower 1
</code></p>

<ul>
  <li>监视某个文件是否被操作, 从安全出发想象空间很大哦</li>
</ul>

<p><code>
sudo sysdig evt.type=open and fd.name contains /etc
</code></p>

<hr />

<p><a href="http://www.sysdig.org/wiki/">Sysdig 官网</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ansible 使用经验]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/09/05/ansiblede-shi-yong-jing-yan/"/>
    <updated>2015-09-05T18:09:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/09/05/ansiblede-shi-yong-jing-yan</id>
    <content type="html"><![CDATA[<p>当你只有一两台服务器的情况下，可以直接登上服务器，手敲命令完成软件部署，代码发布等工作。但假如你有10台，100台的时候，这种方式不仅浪费大量时间，而且给人为犯错带来了可能。于是我们选择 Ansible 来做自动化批量操作。</p>

<p>之前有记录一些 Ansible 入门的使用,请看<a href="http://wiki.zheng-ji.info/Sys/ansible.html">这里</a>, 这半年的积累, 总结一些实用的经验, 记录了一把。</p>

<ul>
  <li><a href="#第一节">配置 ansible.cfg 文件</a></li>
  <li><a href="#第二节">使用 ansible role 来区分业务</a></li>
  <li><a href="#第三节">files 目录的路径定位</a></li>
  <li><a href="#第四节">使用 tags 区分不同操作</a></li>
  <li><a href="#第五节">规划 ansible roles 的 tasks 文件</a></li>
  <li><a href="#第六节">ansible-play-book 一些常用的选项</a></li>
</ul>

<h3 id="第一节">更好地配置文件</h3>

<p>我们会如下配置 /etc/ansible/host, 特意指明用户与 端口</p>

<p>```
[web-cluster]</p>
<node-1-ip> ansible_ssh_port=<your port=""> ansible_ssh_user=zj
<node-2-ip> ansible_ssh_port=<your port=""> ansible_ssh_user=zj
```

在 /etc/ansible/ansible.cfg 文件里
我们特意提及了 ansible-role 的配置，未来我们会使用这个东西

```
roles_path    = /home/zj/my-ansible/roles
```


<h3 id="第二节">使用 ansible role 来区分业务</h3>

打开 ansible 部署脚本的文件夹, 目录树如下


```
cd /home/zj/my-ansible/
haproxy
     - entry.yaml
roles
     - haproxy
        - files
        - handlers
        - vars
        - tasks
```

我用一个管理 haproxy 的例子来讲解这种方式。
在 roles 目录下创建 haproxy, 如上所示，需要有四个目录;

* files 目录下放置需要被传输到远端的文件;
* vars  目录下有一个 main.yml 文件,可以定义一些通用的配置变量，可以在 ansbile 脚本中使用;
* handlers 目录下有一个 main.yml, 可以定义一些通用的操作，比如重启服务等;
* tasks 目录下是我们编写 main.yml 脚本，执行业务逻辑的地方;

&gt; 那么 ansible role 的入口在哪呢？

在 ~/my-ansible/haproxy/entry.yml 中，指定了roles的角色，如此一来， 
ansible-playbook 就会去 /home/zj/my-ansible/roles/haproxy 准备执行 tasks/main.yml 

```
- hosts: web-cluster
  roles:
    - haproxy
```

<h3 id="第三节">files 目录的路径定位</h3>

摘取 ~/my-ansible/roles/haproxy/tasks/main.yml

```
- name: copy haproxy conf
  copy: src=haproxy.cfg dest=/etc/haproxy/haproxy.cfg owner=root group=root
  sudo: yes
```

这里的 src=haproxy.cfg 意味着 ~/my-ansible/roles/haproxy/files/haproxy.cfg

<h3 id="第四节">使用 tags 区分不同操作</h3>

```
- name: install ppa
  shell: add-apt-repository -y ppa:vbernat/haproxy-1.5
  sudo: yes
  tags:
    - install-haproxy
```

以下命令，是使用 tags 参数区分操作的例子

```
cd ~/my-ansible/haproxy
ansible-playbook entry.yml -v -K --tags "install-haproxy"
```

<h3 id="第五节">规划 ansible roles 的 tasks 目录</h3>

tasks 目录有一个主执行文件 main.yml, 因为业务操作步骤太多，导致 main.yml 文件很长，那么可读性就下降了。为此，我们使用了 include 语法。

cat ~/my-ansible/roles/haproxy/tasks/main.yml

```
- include: 'install-haproxy.yml'
```

include 上述文件，这样 main.yml 就显得简洁，我们可以将相关的操作写在对应的 yml 文件里

cat ~/my-ansible/roles/haproxy/tasks/install-haproxy.yml

```
- name: copy haproxy conf
  copy: src=haproxy.cfg dest=/etc/haproxy/haproxy.cfg owner=root group=root
  sudo: yes
  tags:
     - install-haproxy
```
tags 最好也与该 yml 文件名一致，清晰分明

<h3 id="第六节">ansible-play-book 一些常用的选项</h3>


* -K 需要 sudo 权限去客户机执行命令，会提示你输入密码
* -v 可以输出冗余的执行过程
* --check 可以测试脚本执行情况，但实际并未在远程机器执行
* --tags 提示 ansible-play-book 调用哪些 tags 命令

使用过ansible roles 之后，最大的体会是操作调理化，甚至编程化，合理的利用 handler, vars, 能更加优雅抽象。

----

上述的例子在 Github 有代码, 结合本文阅读可能更容易上手
[Link](https://github.com/zheng-ji/ToyCollection/tree/master/my-ansible) 


</your></node-2-ip></your></node-1-ip>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[记录错误登陆的 btmp 文件]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/07/24/ji-lu-cuo-wu-deng-lu-de-btmpwen-jian/"/>
    <updated>2015-07-24T23:06:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/07/24/ji-lu-cuo-wu-deng-lu-de-btmpwen-jian</id>
    <content type="html"><![CDATA[<p>今天查看了服务器时，发现 <code>/var/log/btmp</code> 日志文件较大。</p>

<p>此文件是记录错误登录的日志， 文件较大意味着有人使用密码字典登录ssh服务，
这个文件是需要用 <code>lastb</code> 命令才可读的。</p>

<p>查看尝试恶意登陆的前十个IP</p>

<p><code>
sudo lastb | awk '{ print $3}' | awk '{++S[$NF]} END {for(a in S) print a, S[a]}' | sort -rk2 |head
</code></p>

<p>如果有有必要封阻IP的话，可以执行：</p>

<p><code>
iptables -A INPUT -i eth0 -s *.*.*.0/24 -j DROP
</code></p>
]]></content>
  </entry>
  
</feed>
