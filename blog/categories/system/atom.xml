<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: System | 织网]]></title>
  <link href="http://zheng-ji.github.com/blog/categories/system/atom.xml" rel="self"/>
  <link href="http://zheng-ji.github.com/"/>
  <updated>2017-06-04T13:34:14+08:00</updated>
  <id>http://zheng-ji.github.com/</id>
  <author>
    <name><![CDATA[zheng-ji]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Squid 做正向代理]]></title>
    <link href="http://zheng-ji.github.com/blog/2017/02/22/zheng-xiang-yu-fan-xiang-dai-li/"/>
    <updated>2017-02-22T22:30:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2017/02/22/zheng-xiang-yu-fan-xiang-dai-li</id>
    <content type="html"><![CDATA[<h3 id="section">正向代理和反向代理</h3>

<ul>
  <li>正向代理</li>
</ul>

<p>正向代理 是一个位于客户端和原始服务器之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定原始服务器，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。</p>

<ul>
  <li>反向代理</li>
</ul>

<p>反向代理正好相反，对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容原本就是它自己的一样。</p>

<h3 id="section-1">正向代理软件</h3>

<p>Nginx 能做正向代理，遗憾的是它不能做 HTTPS 的正向代理。以下是一个例子。</p>

<ul>
  <li>不能有 hostname。 </li>
  <li>必须有 resolver, 即 DNS</li>
  <li>配置正向代理参数，均是由 Nginx 变量组成</li>
</ul>

<p><code>
server{
      resolver 8.8.8.8;
      resolver_timeout 30s; 
      listen 80;
      location / {
                proxy_pass http://$http_host$request_uri;
                proxy_set_header Host $http_host;
        }
}
</code></p>

<p>Squid 可正向代理 HTTP 以及 HTTPS</p>

<p><code>
sudo apt-get install squid
</code></p>

<p>编辑 <code>/etc/squid3/squid.conf</code>, 并重启</p>

<p>```
http_port 3128                 	#代理服务器的端口
#http_access deny !Safe_ports 	#注释掉此项
#http_access deny manager     	#注释掉此项</p>

<h1 id="section-2">添加下面两项，设置哪些网段可以访问本代理服务器</h1>
<p>acl our_networks src 172.16.1.0/24 
http_access allow our_networks
```</p>

<p><code>
sudo service squid3 restart
</code></p>

<p>Squid 的层次代理值得一提， 若我们需要定期地切换代理服务器的话, 启动一个 Squid 代理, 而这个代理会将请求转发到其他代理上面. 然后我们只需定时更新本地 Squid 代理的配置文件, 然后重启这个本地代理即可. 层次代理用到了 <code>cache_peer</code> 这个配置文件</p>

<p>```
cache_peer hostname type http_port icp_port option</p>

<p>e.g.
cache_peer xxx.proxy.com parent 9020 0 no-query default login=xxxxx:yyyy
```</p>

<ul>
  <li>hostname: 指被请求的同级子代理服务器或父代理服务器。可以用主机名或ip地址表示；</li>
  <li>type：指明 hostname 的类型，是同级子代理服务器还是父代理服务器，也即 parent 还是 sibling；</li>
  <li>http_port：hostname的监听端口；</li>
  <li>icp_port：hostname 上的ICP监听端口，对于不支持ICP协议的可指定7；</li>
  <li>options：可以包含一个或多个关键字。
    <ol>
      <li>proxy-only：指明从peer得到的数据在本地不进行缓存，缺省地，squid是要缓存这部分数据的；</li>
      <li>weight=n：用于有多个peer的情况，如果多于一个以上的peer拥有你请求的数据时，squid通过计算每个peer ICP 响应时间来 决定其weight的值，然后 squid 向其中拥有最大 weight 的peer发出ICP请求。</li>
      <li>no-query：不向该peer发送ICP请求。如果该peer不可用时，可以使用该选项；</li>
      <li>Default：有点象路由表中的缺省路由，该peer将被用作最后的尝试手段。当你只有一个父代理服务器并且其不支持ICP协议时，可以使用default和no-query选项让所有请求都发送到该父代理服务器；</li>
    </ol>
  </li>
  <li>login=user:password：当你的父代理服务器要求用户认证时可以使用该选项来进行认证</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[cgroup 限制计算资源]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/12/02/cgroupxian-zhi-ji-suan-zi-yuan/"/>
    <updated>2016-12-02T15:41:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/12/02/cgroupxian-zhi-ji-suan-zi-yuan</id>
    <content type="html"><![CDATA[<p>Cgroup 实现了对计算机资源使用上的隔离，它是 Docker 底层的基础技术。我们可以用它来限制程序使用的CPU、内存、磁盘。</p>

<h3 id="section">安装</h3>

<p>在 Ubuntu 14.04 下安装的方法：</p>

<p><code>
sudo apt-get install cgroup-bin
</code></p>

<p>安装完后执行
<code>mount -t cgroup</code> 会出现如下，可以看到它其实是一个文件系统</p>

<p><code>
cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,relatime,cpuset)
cgroup on /sys/fs/cgroup/cpu type cgroup (rw,relatime,cpu)
...
cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,relatime,hugetlb)
</code></p>

<p>如果没有看到以上的目录，这时候需要手动 mount 了</p>

<p><code>
cd /sys/fs
mkdir cgroup
mount -t tmpfs cgroup_root ./cgroup
mkdir cgroup/cpuset
mount -t cgroup -ocpuset cpuset ./cgroup/cpuset/
mkdir cgroup/cpu
mount -t cgroup -ocpu cpu ./cgroup/cpu/
mkdir cgroup/memory
mount -t cgroup -omemory memory ./cgroup/memory/
</code></p>

<h3 id="section-1">实践</h3>

<p>我们来感性认识下 cgroup 吧，编写一个耗费 CPU 的程序，姑且叫暴走程序(baozou)</p>

<p><code>py
count = 0
while True:
    count = count + 1 - 1
</code></p>

<p>运行该程序，top -p 之，100% CPU使用率</p>

<p><code>
  PID      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                       
16515      20   0    2336    728    544 R  100.0  0.0   1:27.23 baozou
</code></p>

<p>我想限制暴走程序 CPU 使用该如何做? 我们手动创建一个 cgroup 目录来针对它。</p>

<p><code>sh
cd /sys/fs/cgroup/cpu
mkdir calm      // 名字可自定义
ls /calm        // 该目录下自动生产与 CPU 有关的文件
cgroup.clone_children  cpu.cfs_period_us  cpu.shares  notify_on_release
cgroup.procs           cpu.cfs_quota_us   cpu.stat    tasks
</code></p>

<p>接着写入限制规则</p>

<p>```
// 默认是100000，20000意味着限制它的cpu为20%
echo 20000 &gt; /sys/fs/cgroup/cpu/calm/cpu.cfs_quota_us, </p>

<p>// 写入程序的 PID 16515
echo 16515 &gt; /sys/fs/cgroup/cpu/calm/tasks
```</p>

<p>于是 CPU 就降到 20% 。</p>

<p><code>
  PID       PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                       
16515       20   0    2336    728    544 R  20.0  0.0   1:27.23 baozou
</code></p>

<p>除了这种需要指定 PID 来限制资源的方法，也可通过指定规则来执行，更显得方便，效果和上述一致。</p>

<p><code>
sudo cgexec -g cpu:calm ./baozou
</code></p>

<p>可以看看这个限制规则做了什么?</p>

<p><code>
$ sudo cgget calm
calm:
cpu.shares: 1024
cpu.cfs_quota_us: 20000
cpu.stat: nr_periods 6943
    nr_throttled 6941
    throttled_time 563080015831
cpu.cfs_period_us: 100000
</code></p>

<p>上述的例子中，我们手动创建了 <code>calm</code>， 其实也能通过命令来做到的</p>

<p>```
// 创建cgroup 文件目录
sudo cgcreate -g cpu:/calm -g memory:/calm</p>

<p>// 设置限制的参数
sudo cgset -r cpu.shares=200 calm</p>

<p>// 限制了内存
sudo cgset -r memory.limit_in_bytes=64k calm</p>

<p>// 可以删除
sudo cgdelete cpu/calm memory:/calm
```</p>

<hr />

<p>参考链接：</p>

<ul>
  <li><a href="http://coolshell.cn/articles/17049.html">Docker基础技术: Linux CGroup</a></li>
  <li><a href="http://www.jianshu.com/p/dc3140699e79">cgroup实践</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[共享内存与信号量]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/09/25/gong-xiang-nei-cun-yu-xin-hao-liang/"/>
    <updated>2016-09-25T23:37:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/09/25/gong-xiang-nei-cun-yu-xin-hao-liang</id>
    <content type="html"><![CDATA[<p>今天和朋友聊天，他多次提到了共享内存，惭愧的是我没怎么用上，只是从 APUE 等神书阅读到此类名词。这个周末，我来搞懂它们。</p>

<h3 id="section">共享内存</h3>

<p>它是 Linux 最底层的通信机制，被称为最快的通信机制。多个进程共享同一个内存区域实现进程间通信。一个进程创建一个共享内存区域，并将数据存放到共享内存中，而后多个进程对其进行访问。</p>

<p>借鉴网友的例子，我做了注释和修改，一个进程写共享内存 (shmwrite.c)，一个进程读共享内存(shmread.c)。</p>

<p>共享内存并未提供同步机制，在第一个进程结束对共享内存的写操作之前，并无自动机制阻止第二个进程开始对它进行读取。上述代码中，我通过自己维护了一个变量 isWritten 来控制同步行为。</p>

<p>还好，伟大的计算机先驱们提供了信号量来帮我们解决同步的问题。</p>

<h3 id="section-1">信号量</h3>
<p>为了防止出现因多个程序同时访问一个共享资源带来的问题，Linux 使用 信号量协调进程对共享资源的访问的。
信号量只能进行两种操作等待和发送信号，即 P(sv) 和 V(sv).</p>

<ul>
  <li>P(sv)：当sv的值大于零，就减1；当它的值为零，就挂起该进程的执行。</li>
  <li>V(sv)：当有其他进程因等待sv而被挂起，就让它恢复运行，当没有进程因等待sv而挂起，就给它加1.</li>
</ul>

<p>比如：两个进程共享信号量 sv，其中一个进程执行了 P(sv) 操作，它将得到信号量，进入临界区，将 sv 减1。此时sv=0,第二个进程将被阻止进入临界区，它会被挂起以等待第一个进程离开临界区域,并执行 V(sv) 释放信号量，这时第二个进程就可以恢复执行。</p>

<h3 id="mmap--shmget">mmap 还是 shmget</h3>

<p>这两个东西某种程度上很类似。</p>

<p>内存映射，将用户空间的一段内存区域映射到内核空间,用户对这段内存区域的修改可以直接反映到内核空间，同样，内核空间对这段区域的修改也直接反映用户空间。两者之间需要大量数据传输等操作的话效率是非常高的.</p>

<p>mmap 并不是完全为了用于共享内存而设计的。它提供了不同于一般对普通文件的访问方式，进程可以像读写内存一样对普通文件的操作。而 Posix 或系统V的共享内存 IPC 则纯粹用于共享目的.</p>

<p>mmap 使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以像访问普通内存一样对文件进行访问，不必再调用 read()，write() 等操作。mmap 并不分配空间, 只是将文件映射到调用进程的地址空间里 然后你就可以用 memcpy 等操作写文件。</p>

<hr />

<p>附上代码：</p>

<ul>
  <li>共享数据结构: <a href="https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmdata.h">shmdata.h</a></li>
  <li>读共享内存：<a href="https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmread.c">shmread.c</a></li>
  <li>写共享内存：<a href="https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmwrite.c">shmwrite.c</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[环境变量的那些事]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/07/16/bash-jia-zai-shun-xu/"/>
    <updated>2016-07-16T11:35:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/07/16/bash-jia-zai-shun-xu</id>
    <content type="html"><![CDATA[<ul>
  <li><a href="#第一节">四种模式下的环境变量加载</a></li>
  <li><a href="#第二节">跨机器SSH 传递环境变量</a></li>
</ul>

<h3 id="第一节">四种模式下的环境变量加载</h3>

<p>名词解析</p>

<ol>
  <li>login shell: 指用户以非图形化界面 ssh登陆到机器上时获得的第一个 shell。 </li>
  <li>interactive: 交互式，有输入提示符，它的标准输入输出和错误输出都会显示在控制台上。</li>
</ol>

<ul>
  <li>interactive + login shell</li>
</ul>

<p>比如登陆机器后的第一个 shell 就是这种场景。它首先加载 /etc/profile，然后再依次去加载下列三个配置文件之一，一旦找到其中一个便不再接着寻找</p>

<p><code>
~/.bash_profile
~/.bash_login
~/.profile
</code></p>

<p>设计如此多的配置是为了兼容 bourne shell 和 C shell，尽量杜绝使用 .bash_login，如果已创建，需要创建 .bash_profile 覆盖</p>

<ul>
  <li>noninteractive + login shell</li>
</ul>

<p>bash -l script.sh 就是这种场景。<code>-l</code> 参数是将shell作为一个login shell启动，配置文件的加载与第一种完全一样。</p>

<ul>
  <li>interactive + non-login shell</li>
</ul>

<p>在一个已有shell中运行bash，此时会打开一个交互式的shell，因为不再需要登陆，所以不是login shell。启动 shell 时会去查找并加载</p>

<p><code>
/etc/bash.bashrc
~/.bashrc 
</code></p>

<ul>
  <li>non-interactive + non-login shell</li>
</ul>

<p>比如执行脚本 bash script.sh 或者 ssh user@remote command。这两种都是创建一个shell，执行完脚本之后便退出，不再需要与用户交互。它会去寻找环境变量BASH_ENV，将变量的值作为文件名进行查找，如果找到便加载它。</p>

<p>从网上看到一个清晰的图</p>

<p><code>
+----------------+--------+-----------+---------------+
|                | login  |interactive|non-interactive|
|                |        |non-login  |non-login      |
+----------------+--------+-----------+---------------+
|/etc/profile    |   A    |           |               |
+----------------+--------+-----------+---------------+
|/etc/bash.bashrc|        |    A      |               |
+----------------+--------+-----------+---------------+
|~/.bashrc       |        |    B      |               |
+----------------+--------+-----------+---------------+
|~/.bash_profile |   B1   |           |               |
+----------------+--------+-----------+---------------+
|~/.bash_login   |   B2   |           |               |
+----------------+--------+-----------+---------------+
|~/.profile      |   B3   |           |               |
+----------------+--------+-----------+---------------+
|BASH_ENV        |        |           |       A       |
+----------------+--------+-----------+---------------+
</code>
—-</p>

<h3 id="第二节">跨机器传递环境变量</h3>

<p>假设要传递的变量叫做 $VARNAME</p>

<p>客户端机器的 <code>/etc/ssh_config</code> 添加 </p>

<p><code>
SendEnv VARNAME
</code></p>

<p>服务端机器的 <code>/etc/sshd_config</code> 添加</p>

<p><code>
AcceptEnv VARNAME
</code></p>

<p>客户端机器的 $VARNAME 就可以通过 ssh 传递到服务端机器，继续使用.</p>

<hr />

<h3 id="section">参考</h3>

<p><a href="http://feihu.me/blog/2014/env-problem-when-ssh-executing-command-on-remote/">ssh连接远程主机执行脚本的环境变量问题</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ansible Dynamic Inventory]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/04/24/ansible-dynamic-inventory/"/>
    <updated>2016-04-24T20:53:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/04/24/ansible-dynamic-inventory</id>
    <content type="html"><![CDATA[<p>Ansible 在使用的过程中，如果机器数量比较固定，且变更不多的情况下，可在 /etc/ansible/hosts 文件里面配置固定的组合机器IP， 并给他起组的别名，执行 Ansible 脚本便可以通过别名找到相应的机器。</p>

<p><code>
[webservers]
111.222.333.444 ansible_ssh_port=888
</code></p>

<p>假如你有很多台机器，且机器经常变更导致IP时常变换，你还想把IP逐个写入 /etc/ansible/hosts 就不现实了。你也许会问，若不把 IP 写进 /etc/ansible/hosts，那不是没法用 Ansible 指挥这些机器？
感谢 Ansible Dynamic Inventory， 如果我们能通过编程等手段获取变更机器的IP，我们还是有办法实现的。</p>

<h3 id="dynamic-inventory-">Dynamic Inventory 的原理</h3>

<ul>
  <li>通过编程的方式,也就是动态获取机器的 json 信息;</li>
  <li>Ansible 通过解析这串 json 字符串;</li>
</ul>

<p><code>
ansible -i yourprogram.py -m raw  -a 'cd /home'
</code></p>

<p>Ansible Dynamic Inventory 对程序返回的 json 的转义是这样的：</p>

<p><code>
{"devtest-asg": {"hosts": ["172.31.21.164"], "vars": {"ansible_ssh_port": 12306}}}
</code></p>

<p>翻译一下就是  /etc/ansible/hosts 中的:</p>

<p><code>
[devtest-asg]
172.31.21.164 ansible_ssh_port=12306
</code></p>

<h3 id="section">一个实战的例子</h3>

<p>官方文档对 Inventory 仅作概念性描述，阅读完后仍是一头雾水，不知如何下手。 让我们用一个例子来豁然开朗吧。 我们使用 AWS 的 AutoScaling Group，以下简称 ASG，ASG 会在某种自定义的条件下会自动开启和关闭机器，这给我们在辨别IP，定位机器的时候造成困扰。因此我们需要 Ansible Dynamic Inventory</p>

<p>我们使用 AWS 的 boto 库来获取 ASG 的实例信息.以下程序(get_host.py)中要实现的方法就是列出返回机器信息的 json 串。</p>

<p>```python
#!/usr/bin/env python
# -<em>- coding: utf-8 -</em>-
import json
import boto
import boto.ec2
import boto.ec2.autoscale</p>

<p>AWS_REGION = ‘BBB’
AWS_ACCESS_KEY = ‘xxxx’
AWS_SECRET_KEY = ‘yyy’</p>

<p>result = {}
def getData():
    conn_as = boto.ec2.autoscale.connect_to_region(
            ‘cn-north-1’,
            aws_access_key_id=AWS_ACCESS_KEY,
            aws_secret_access_key=AWS_SECRET_KEY)
    group = conn_as.get_all_groups(names=[‘devtest-asg’])[0]
    conn_ec2 = boto.ec2.connect_to_region(
            AWS_REGION,
            aws_access_key_id=AWS_ACCESS_KEY,
            aws_secret_access_key=AWS_SECRET_KEY)</p>

<pre><code>instance_ids = [i.instance_id for i in group.instances]
reservations = conn_ec2.get_all_instances(instance_ids)
instances = [i for r in reservations for i in r.instances]

result['devtest-asg'] = {}
result['devtest-asg']['hosts'] = []
for r in reservations:
    for i in r.instances:
        result['devtest-asg']['hosts'].append('%s' % i.private_ip_address)
        result['devtest-asg']['vars'] = {'ansible_ssh_port': 36000}
</code></pre>

<p>def getlists():
    getData()
    print json.dumps(result)</p>

<p>getlists()
```</p>

<p>执行以下命令就可以愉快地使用 Ansible 了，其中 devtest-asg 是 ASG 的别名：</p>

<p><code>
ansible -i get_host.py  devtest-asg -m raw -a 'ls /'
</code></p>
]]></content>
  </entry>
  
</feed>
