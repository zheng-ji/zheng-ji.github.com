<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: System | 织网]]></title>
  <link href="http://zheng-ji.github.com/blog/categories/system/atom.xml" rel="self"/>
  <link href="http://zheng-ji.github.com/"/>
  <updated>2016-06-03T23:49:00+08:00</updated>
  <id>http://zheng-ji.github.com/</id>
  <author>
    <name><![CDATA[zheng-ji]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Ansible Dynamic Inventory]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/04/24/ansible-dynamic-inventory/"/>
    <updated>2016-04-24T20:53:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/04/24/ansible-dynamic-inventory</id>
    <content type="html"><![CDATA[<p>Ansible 在使用的过程中，如果机器数量比较固定，且变更不多的情况下，可在 /etc/ansible/hosts 文件里面配置固定的组合机器IP， 并给他起组的别名，执行 Ansible 脚本便可以通过别名找到相应的机器。</p>

<p><code>
[webservers]
111.222.333.444 ansible_ssh_port=888
</code></p>

<p>假如你有很多台机器，且机器经常变更导致IP时常变换，你还想把IP逐个写入 /etc/ansible/hosts 就不现实了。你也许会问，若不把 IP 写进 /etc/ansible/hosts，那不是没法用 Ansible 指挥这些机器？
感谢 Ansible Dynamic Inventory， 如果我们能通过编程等手段获取变更机器的IP，我们还是有办法实现的。</p>

<h3 id="dynamic-inventory-">Dynamic Inventory 的原理</h3>

<ul>
  <li>通过编程的方式,也就是动态获取机器的 json 信息;</li>
  <li>Ansible 通过解析这串 json 字符串;</li>
</ul>

<p><code>
ansible -i yourprogram.py -m raw  -a 'cd /home'
</code></p>

<p>Ansible Dynamic Inventory 对程序返回的 json 的转义是这样的：</p>

<p><code>
{"devtest-asg": {"hosts": ["172.31.21.164"], "vars": {"ansible_ssh_port": 12306}}}
</code></p>

<p>翻译一下就是  /etc/ansible/hosts 中的:</p>

<p><code>
[devtest-asg]
172.31.21.164 ansible_ssh_port=12306
</code></p>

<h3 id="section">一个实战的例子</h3>

<p>官方文档对 Inventory 仅作概念性描述，阅读完后仍是一头雾水，不知如何下手。 让我们用一个例子来豁然开朗吧。 我们使用 AWS 的 AutoScaling Group，以下简称 ASG，ASG 会在某种自定义的条件下会自动开启和关闭机器，这给我们在辨别IP，定位机器的时候造成困扰。因此我们需要 Ansible Dynamic Inventory</p>

<p>我们使用 AWS 的 boto 库来获取 ASG 的实例信息.以下程序(get_host.py)中要实现的方法就是列出返回机器信息的 json 串。</p>

<p>```python
#!/usr/bin/env python
# -<em>- coding: utf-8 -</em>-
import json
import boto
import boto.ec2
import boto.ec2.autoscale</p>

<p>AWS_REGION = ‘BBB’
AWS_ACCESS_KEY = ‘xxxx’
AWS_SECRET_KEY = ‘yyy’</p>

<p>result = {}
def getData():
    conn_as = boto.ec2.autoscale.connect_to_region(
            ‘cn-north-1’,
            aws_access_key_id=AWS_ACCESS_KEY,
            aws_secret_access_key=AWS_SECRET_KEY)
    group = conn_as.get_all_groups(names=[‘devtest-asg’])[0]
    conn_ec2 = boto.ec2.connect_to_region(
            AWS_REGION,
            aws_access_key_id=AWS_ACCESS_KEY,
            aws_secret_access_key=AWS_SECRET_KEY)</p>

<pre><code>instance_ids = [i.instance_id for i in group.instances]
reservations = conn_ec2.get_all_instances(instance_ids)
instances = [i for r in reservations for i in r.instances]

result['devtest-asg'] = {}
result['devtest-asg']['hosts'] = []
for r in reservations:
    for i in r.instances:
        result['devtest-asg']['hosts'].append('%s' % i.private_ip_address)
        result['devtest-asg']['vars'] = {'ansible_ssh_port': 36000}
</code></pre>

<p>def getlists():
    getData()
    print json.dumps(result)</p>

<p>getlists()
```</p>

<p>执行以下命令就可以愉快地使用 Ansible 了，其中 devtest-asg 是 ASG 的别名：</p>

<p><code>
ansible -i get_host.py  devtest-asg -m raw -a 'ls /'
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Flume 实时收集 Nginx 日志]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/04/23/flume-shi-shi-shou-ji-nginx-ri-zhi/"/>
    <updated>2016-04-23T09:13:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/04/23/flume-shi-shi-shou-ji-nginx-ri-zhi</id>
    <content type="html"><![CDATA[<p>在分布式系统中，各个机器都有程序运行的本地日志，有时为了分析需求，不得不这些分散的日志汇总需求，相信很多人会选择 Rsync，Scp 之类，
但它们的实时性不强，而且也会带来名字冲突的问题。扩展性差强人意，一点也不优雅。</p>

<p>现实中，我们就碰到了这样的需求：实时汇总线上多台服务器的 Nginx 日志。Flume 立功了。</p>

<h1 id="flume-">Flume 简介</h1>

<p><a href="https://flume.apache.org/"><strong>F</strong>lume</a> 是一个分布式，可靠高效的日志收集系统，它允许用户自定义数据传输模型，因此可扩展性也强。也有较强的容错和恢复机制.
以下是几个重要的概念</p>

<ul>
  <li>Event：Event 是 Flume 数据传输的基本单元。flume 以事件的形式将数据从源头传送到最终的目的。</li>
  <li>Agent：Agent包含 Sources, Channels, Sinks 和其他组件，它利用这些组件将events从一个节点传输到另一个节点或最终目的。</li>
  <li>Source：Source负责接收events，并将events批量的放到一个或多个Channels。</li>
  <li>Channel：Channel位于 Source 和 Sink 之间，用于缓存进来的events，当Sink成功的将events发送到下一跳的channel或最终目的，events从Channel移除。</li>
  <li>Sink：Sink 负责将 events 传输到下一跳或最终目的，成功完成后将events从channel移除。</li>
</ul>

<p><img src="/images/2016/04/flume.jpg"></p>

<ul>
  <li>Source 就有 Syslog Source, Kafka Source,HTTP Source, Exec Source Avro Source 等。</li>
  <li>Sink 有 Kafka Sink, Avro Sink, File Roll Sink, HDFS Sink 等。</li>
  <li>Channel 有 Memory Channel,File Channel 等</li>
</ul>

<p>它提供了一个骨架，以及多种 Source, Sink, Channel, 让你设计合适的数据模型。事实上也可以多个 Flume 联动完成，就像地铁的车厢一样。</p>

<h1 id="section">定义数据流模型</h1>

<p>回到我们开头的场景,我们要将多台服务器的 Nginx 日志进行汇总分析，</p>

<p>分成两个 flume 来实现</p>

<ul>
  <li>Flume1 数据流是 Exec Source -&gt; Memory Channel -&gt; Avro Sink,部署在业务机器上</li>
  <li>Flume2 数据流是 Avro Source -&gt; Memory Channel -&gt; FileRoll Sink</li>
</ul>

<p><img src="/images/2016/04/flume1toflume2.jpg"></p>

<h1 id="section-1">需要的准备</h1>

<p>你需要安装</p>

<ul>
  <li>下载 <a href="https://flume.apache.org/download.html">Flume</a></li>
  <li>安装 JavaSDk,并在下载解压之后的 conf/flume-env.sh，配置</li>
</ul>

<p><code>sh
# 我用的是oracle-java-8
export JAVA_HOME=/usr/lib/jvm/java-8-oracle/jre/
</code></p>

<ul>
  <li>思考你的数据流动模型，编写配置，如上文所说的Flume1, tail2avro.conf  ：</li>
</ul>

<p>```
agent.sources = s1
agent.channels = c1
agent.sinks = k1</p>

<p>agent.sources.s1.type=exec
agent.sources.s1.command=tail -F <your file="" path="">
agent.sources.s1.channels=c1</your></p>

<p>agent.channels.c1.type=memory
agent.channels.c1.capacity=10000
agent.channels.c1.transactionCapacity=10000</p>

<p>agent.sinks.k1.type = avro
agent.sinks.k1.hostname = <your target="" address="">
agent.sinks.k1.port = <your target="" port="">
agent.sinks.k1.channel=c1
```</your></your></p>

<p>Flume2 中的 avro2file.conf </p>

<p>```
agent.sources = s1
agent.channels = c1
agent.sinks = k1</p>

<p>agent.sources.s1.type = avro
agent.sources.s1.bind = <your address="">
agent.sources.s1.port = <your port="">
agent.sources.s1.channels = c1</your></your></p>

<p>agent.sinks.k1.type = file_roll
agent.sinks.k1.sink.directory = /data/log/ngxlog
# 滚动间隔
agent.sinks.k1.sink.rollInterval = 86400
agent.sinks.k1.channel = c1</p>

<p>agent.channels.c1.type = memory
# 队列里 Event 的容量
agent.channels.c1.capacity = 10000
agent.channels.c1.transactionCapacity = 10000
agent.channels.c1.keep-alive = 60
```</p>

<ul>
  <li>启动运行</li>
</ul>

<p>```
# 启动flume1
bin/flume-ng agent -n agent -c conf -f conf/tail2avro.conf \
-Dflume.root.logger=WARN</p>

<h1 id="flume2">启动flume2</h1>
<p>in/flume-ng agent -n agent -c conf -f conf/avro2file.conf \
-Dflume.root.logger=INFO
```</p>

<h2 id="section-2">参考</h2>

<ul>
  <li><a href="https://flume.apache.org/FlumeUserGuide.html">FlumeUserGuide</a> 官方的 FlumeUserGuide</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ 实时监控 nginx qps 的拓展]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/01/07/shi-shi-jian-kong-nginx-qps-de-tuo-zhan/"/>
    <updated>2016-01-07T12:59:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/01/07/shi-shi-jian-kong-nginx-qps-de-tuo-zhan</id>
    <content type="html"><![CDATA[<p>用下班时间写了一个 ngx lua 的拓展, <a href="https://github.com/zheng-ji/ngx_lua_reqstatus">GitHub</a>。可以:</p>

<ul>
  <li>[x] 实时监控域名的 qps</li>
  <li>[x] 实时监控域名的 5xx 个数</li>
  <li>[x] 实时监控域名的 响应时长</li>
  <li>[x] 并附带 Ganglia 监控插件</li>
</ul>

<h2 id="section">使用</h2>

<ul>
  <li>配置 <code>nginx.conf</code></li>
</ul>

<p>```
http {
    …
    …</p>

<pre><code>lua_shared_dict statics_dict    1M; # 初始化变量
lua_package_path "/etc/nginx/ngx_lua_reqstatus/?.lua";  #路径
log_by_lua_file "/etc/nginx/ngx_lua_reqstatus/hook.lua"; # 添加此句

server {
    listen 80;
    server_name  justforfun.com; 

    location /{
        ...
    }
}
# 监控服务
server {
    listen 127.0.0.1:6080;
    location /{
        access_by_lua_file "/etc/nginx/ngx_lua_reqstatus/status.lua";
    }
} } ```
</code></pre>

<ul>
  <li>效果</li>
</ul>

<p><code>
curl localhost:6080/?domain=justforfun.com
</code></p>

<ul>
  <li>输出</li>
</ul>

<p><code>
Server Name:    justforfun.com
Seconds SinceLast:   1.4399998188019 secs
Request Count:      1
Average Req Time:   0 secs
Requests Per Secs:  0.69444453182781
5xx num:    0
</code></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx 日志利器 GoAccess]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/12/10/fen-xi-nginxri-zhi-de-li-qi-goaccess/"/>
    <updated>2015-12-10T23:28:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/12/10/fen-xi-nginxri-zhi-de-li-qi-goaccess</id>
    <content type="html"><![CDATA[<p>我们经常需要从 Nginx 日志分析得出很多有价值的东西，分析的方法是各种 shell, awk, python, 现在 <a href="https://github.com/allinurl/goaccess">GoAccess</a> 给你另外一种选择, 值得拥有。</p>

<ul>
  <li>安装
用以下的方式安装，才能得到新版的 GoAccess, 功能更健全</li>
</ul>

<p><code>
$ echo "deb http://deb.goaccess.io $(lsb_release -cs) main"|sudo tee -a /etc/apt/sources.list
$ wget -O - http://deb.goaccess.io/gnugpg.key | sudo apt-key add -
$ sudo apt-get update
$ sudo apt-get install goaccess
</code></p>

<ul>
  <li>推荐配置</li>
</ul>

<p>安装完成之后，会生成一份 <code>/etc/goaccess.conf</code> 稍作编辑，这就是默认的配置，免去了后续每次都要定义格式</p>

<p><code>
time-format %T   # 只有这种方式才能解决 0.0us 的显示问题
date-format %d/%b/%Y
log-format %h %^[%d:%t %^] "%r" %s %b "%R" "%u" %T
</code></p>

<ul>
  <li>使用</li>
</ul>

<p>输出报表，报表中，我们可以看到最常访问的 IP, 接口，以及每个接口使用带宽，平均响应时长，状态码等，对业务分析有较好的便利性</p>

<p>```
终端显示
goaccess -f access.log </p>

<p>输出报表，报表中，我们可以看到top ip, 接口，以及接口使用带宽，平均响应时长，状态码等
goaccess -f access.log &gt; report.html</p>

<p>具体某段时间的输出
sed -n ‘/5\/Dec\/2015/,/10\/Dec\/2010/ p’ access.log | goaccess -a</p>

<p>处理已经压缩的日志
zcat access.log.*.gz | goaccess
```</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gre 隧道与 Keepalived]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/12/05/gre-tuning-and-keepalived/"/>
    <updated>2015-12-05T10:29:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/12/05/gre-tuning-and-keepalived</id>
    <content type="html"><![CDATA[<p>这一篇文章是做了不少功课的。</p>

<ul>
  <li><a href="#第一节">什么是 Gre 隧道</a></li>
  <li><a href="#第二节">什么是 Vrrp </a></li>
  <li><a href="#第三节">KeepAlived 是什么</a></li>
  <li><a href="#第四节">用Keepalived 怎么玩</a></li>
  <li><a href="#第五节">附录</a></li>
</ul>

<h3 id="第一节">什么是 Gre 隧道 </h3>

<p>GRE 隧道是一种 IP-2-IP 的隧道，是通用路由封装协议，可以对某些网路层协议的数据报进行封装，使这些被封装的数据报能够在 IPv4/IPv6 网络中传输。Tunnel 是一个虚拟的点对点的连接，提供了一条通路使封装的数据报文能够在这个通路上传输，并且在一个Tunnel 的两端分别对数据报进行封装及解封装。Linux 上创建 GRE 隧道，需要 ip_gre 内核模块，它是Pv4 隧道的驱动程序。</p>

<p>假设我有2台服务器，想做这两台之间创建 GRE 隧道</p>

<ul>
  <li>$server_A_ip 表示服务器A的IP</li>
  <li>$server_B_ip 服务器B 的内网IP</li>
</ul>

<p>```
# 在 A 机器上执行
# 创建 GRE 协议的 虚拟网络设备, 指定本地和对端 IP
sudo ip link add gretap1 type gretap local $server_a_ip remote $server_b_ip 
sudo ip link set dev gretap1 up  # 启动该设备
sudo ip addr add dev gretap1 10.1.1.2/24 # 给该设备一个虚拟网络地址</p>

<h1 id="b-">在 B 机器上执行</h1>
<p># 创建 GRE 协议的 虚拟网络设备, 指定本地和对端 IP
sudo ip link add gretap1 type gretap local $server_b_ip remote $server_a_ip 
sudo ip link set dev gretap1 up  # 启动该设备
sudo ip addr add dev gretap1 10.1.1.3/24 # 给该设备一个虚拟网络地址
```</p>

<p>如果想停止或者删除上述网卡</p>

<p><code>
ip link set gretap1 down
ip tunnel del gretap1
</code></p>

<p>至此点到点得隧道建立。</p>

<h3 id="第二节">什么是 vrrp 协议 </h3>

<p>VRRP(Virtual Router Redundancy Protocol), 即虚拟路由冗余协议。是实现路由器高可用的容错协议。</p>

<p>即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个 master 和多个 backup， 但在外界看来就像一台一样，构成虚拟路由器，拥有一个虚拟IP（vip），占有这个IP 的 master 实际负责 ARP 相应和转发 IP 数据包， 组中的其它路由器作为备份的角色处于待命状态。 master 会发组播消息，当 backup 在超时时间内收不到 vrrp 包时就认为 master 宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master，保证路由器的高可用。</p>

<h3 id="第三节"> Keepalived 是什么 </h3>

<p>Keepalived 是一个基于 VRRP 协议来实现的服务高可用方案，可以利用其来避免IP单点故障。</p>

<ul>
  <li>一个经典的案例</li>
</ul>

<p>一个WEB服务至少会有2台服务器运行 Keepalived，一台为主服务器，一台为备份服务器, 但是对外表现为一个虚拟IP，主服务器会发送特定的消息给备份服务器，当备份服务器收不到这个消息的时候，即主服务器宕机的时候，备份服务器就会接管虚拟IP，继续提供服务，从而保证了高可用性。</p>

<h3 id="第四节">怎么玩 Keepalived</h3>

<ul>
  <li>安装</li>
</ul>

<p><code>
sudo apt-get install keepalived
</code></p>

<p>之前提到的，我们在 A, B 两台服务器建立起了 GRE 隧道了。 现在我们有一个虚拟的内网IP， 姑且叫做 $virtual_third_ip
接着在 A 服务器上</p>

<ul>
  <li>配置</li>
</ul>

<p>编辑服务器 A, B 的 <code>/etc/keepalived/keepalived.conf</code></p>

<p>```</p>

<p>global_defs {
    router_id LVS_DEVEL
}</p>

<p>vrrp_instance VI_1 {
    state MASTER
    interface gretap1 # 绑在建立起来的隧道上
    virtual_router_id 51
    # 优先级别,越高的设备会被弄成主设备, A,B 服务器要有所差别，其他都一样
    priority 100          advert_int 1      # 广播时间间隔
    authentication {  #  验证相关
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        $virtual_third_ip dev eth0
    }
}
```</p>

<p>我们将服务器  A 作为 Master, 服务器 B 当做 Backup, 当服务器 A 需要停机的时候，$virtual_third_ip 就会漂移到服务器 B 上面。 我们两台机器都有相同配置的 Nginx 服务，就可以保障机器出现故障的时候，Nginx 服务丝毫不受影响。</p>

<h3 id="第五节"> 附录 </h3>

<ul>
  <li><a href="http://linux.vbird.org/linux_server/0140networkcommand.php">鸟哥的网络知识</a></li>
  <li><a href="http://www.tldp.org/HOWTO/Adv-Routing-HOWTO/lartc.tunnel.gre.html">GRE tuneling</a></li>
  <li><a href="http://baike.baidu.com/link?url=N1-VGuzQC0PJ2bCnOzYn-XRTlN8eFGCvIJQlTI6KDL5Fx3EQxoRGTrxazb11jfZQqlfeA6q2Ka0VKRVEc0Kdu3GEyhqe1W_Ae2h0Tqu5NacIjOSaSnUVeOe-9QV5dB8q0Wv_uq8-vqdnQICt39UZFK">VRRP</a></li>
</ul>
]]></content>
  </entry>
  
</feed>
