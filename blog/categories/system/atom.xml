<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: System | 织网]]></title>
  <link href="http://zheng-ji.github.com/blog/categories/system/atom.xml" rel="self"/>
  <link href="http://zheng-ji.github.com/"/>
  <updated>2016-09-21T21:00:41+08:00</updated>
  <id>http://zheng-ji.github.com/</id>
  <author>
    <name><![CDATA[zheng-ji]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[环境变量的那些事]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/07/16/bash-jia-zai-shun-xu/"/>
    <updated>2016-07-16T11:35:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/07/16/bash-jia-zai-shun-xu</id>
    <content type="html"><![CDATA[<ul>
  <li><a href="#第一节">四种模式下的环境变量加载</a></li>
  <li><a href="#第二节">跨机器SSH 传递环境变量</a></li>
</ul>

<h3 id="第一节">四种模式下的环境变量加载</h3>

<p>名词解析</p>

<ol>
  <li>login shell: 指用户以非图形化界面 ssh登陆到机器上时获得的第一个 shell。 </li>
  <li>interactive: 交互式，有输入提示符，它的标准输入输出和错误输出都会显示在控制台上。</li>
</ol>

<ul>
  <li>interactive + login shell</li>
</ul>

<p>比如登陆机器后的第一个 shell 就是这种场景。它首先加载 /etc/profile，然后再依次去加载下列三个配置文件之一，一旦找到其中一个便不再接着寻找</p>

<p><code>
~/.bash_profile
~/.bash_login
~/.profile
</code></p>

<p>设计如此多的配置是为了兼容 bourne shell 和 C shell，尽量杜绝使用 .bash_login，如果已创建，需要创建 .bash_profile 覆盖</p>

<ul>
  <li>noninteractive + login shell</li>
</ul>

<p>bash -l script.sh 就是这种场景。<code>-l</code> 参数是将shell作为一个login shell启动，配置文件的加载与第一种完全一样。</p>

<ul>
  <li>interactive + non-login shell</li>
</ul>

<p>在一个已有shell中运行bash，此时会打开一个交互式的shell，因为不再需要登陆，所以不是login shell。启动 shell 时会去查找并加载</p>

<p><code>
/etc/bash.bashrc
~/.bashrc 
</code></p>

<ul>
  <li>non-interactive + non-login shell</li>
</ul>

<p>比如执行脚本 bash script.sh 或者 ssh user@remote command。这两种都是创建一个shell，执行完脚本之后便退出，不再需要与用户交互。它会去寻找环境变量BASH_ENV，将变量的值作为文件名进行查找，如果找到便加载它。</p>

<p>从网上看到一个清晰的图</p>

<p><code>
+----------------+--------+-----------+---------------+
|                | login  |interactive|non-interactive|
|                |        |non-login  |non-login      |
+----------------+--------+-----------+---------------+
|/etc/profile    |   A    |           |               |
+----------------+--------+-----------+---------------+
|/etc/bash.bashrc|        |    A      |               |
+----------------+--------+-----------+---------------+
|~/.bashrc       |        |    B      |               |
+----------------+--------+-----------+---------------+
|~/.bash_profile |   B1   |           |               |
+----------------+--------+-----------+---------------+
|~/.bash_login   |   B2   |           |               |
+----------------+--------+-----------+---------------+
|~/.profile      |   B3   |           |               |
+----------------+--------+-----------+---------------+
|BASH_ENV        |        |           |       A       |
+----------------+--------+-----------+---------------+
</code>
—-</p>

<h3 id="第二节">跨机器传递环境变量</h3>

<p>假设要传递的变量叫做 $VARNAME</p>

<p>客户端机器的 <code>/etc/ssh_config</code> 添加 </p>

<p><code>
SendEnv VARNAME
</code></p>

<p>服务端机器的 <code>/etc/sshd_config</code> 添加</p>

<p><code>
AcceptEnv VARNAME
</code></p>

<p>客户端机器的 $VARNAME 就可以通过 ssh 传递到服务端机器，继续使用.</p>

<hr />

<h3 id="section">参考</h3>

<p><a href="http://feihu.me/blog/2014/env-problem-when-ssh-executing-command-on-remote/">ssh连接远程主机执行脚本的环境变量问题</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ansible Dynamic Inventory]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/04/24/ansible-dynamic-inventory/"/>
    <updated>2016-04-24T20:53:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/04/24/ansible-dynamic-inventory</id>
    <content type="html"><![CDATA[<p>Ansible 在使用的过程中，如果机器数量比较固定，且变更不多的情况下，可在 /etc/ansible/hosts 文件里面配置固定的组合机器IP， 并给他起组的别名，执行 Ansible 脚本便可以通过别名找到相应的机器。</p>

<p><code>
[webservers]
111.222.333.444 ansible_ssh_port=888
</code></p>

<p>假如你有很多台机器，且机器经常变更导致IP时常变换，你还想把IP逐个写入 /etc/ansible/hosts 就不现实了。你也许会问，若不把 IP 写进 /etc/ansible/hosts，那不是没法用 Ansible 指挥这些机器？
感谢 Ansible Dynamic Inventory， 如果我们能通过编程等手段获取变更机器的IP，我们还是有办法实现的。</p>

<h3 id="dynamic-inventory-">Dynamic Inventory 的原理</h3>

<ul>
  <li>通过编程的方式,也就是动态获取机器的 json 信息;</li>
  <li>Ansible 通过解析这串 json 字符串;</li>
</ul>

<p><code>
ansible -i yourprogram.py -m raw  -a 'cd /home'
</code></p>

<p>Ansible Dynamic Inventory 对程序返回的 json 的转义是这样的：</p>

<p><code>
{"devtest-asg": {"hosts": ["172.31.21.164"], "vars": {"ansible_ssh_port": 12306}}}
</code></p>

<p>翻译一下就是  /etc/ansible/hosts 中的:</p>

<p><code>
[devtest-asg]
172.31.21.164 ansible_ssh_port=12306
</code></p>

<h3 id="section">一个实战的例子</h3>

<p>官方文档对 Inventory 仅作概念性描述，阅读完后仍是一头雾水，不知如何下手。 让我们用一个例子来豁然开朗吧。 我们使用 AWS 的 AutoScaling Group，以下简称 ASG，ASG 会在某种自定义的条件下会自动开启和关闭机器，这给我们在辨别IP，定位机器的时候造成困扰。因此我们需要 Ansible Dynamic Inventory</p>

<p>我们使用 AWS 的 boto 库来获取 ASG 的实例信息.以下程序(get_host.py)中要实现的方法就是列出返回机器信息的 json 串。</p>

<p>```python
#!/usr/bin/env python
# -<em>- coding: utf-8 -</em>-
import json
import boto
import boto.ec2
import boto.ec2.autoscale</p>

<p>AWS_REGION = ‘BBB’
AWS_ACCESS_KEY = ‘xxxx’
AWS_SECRET_KEY = ‘yyy’</p>

<p>result = {}
def getData():
    conn_as = boto.ec2.autoscale.connect_to_region(
            ‘cn-north-1’,
            aws_access_key_id=AWS_ACCESS_KEY,
            aws_secret_access_key=AWS_SECRET_KEY)
    group = conn_as.get_all_groups(names=[‘devtest-asg’])[0]
    conn_ec2 = boto.ec2.connect_to_region(
            AWS_REGION,
            aws_access_key_id=AWS_ACCESS_KEY,
            aws_secret_access_key=AWS_SECRET_KEY)</p>

<pre><code>instance_ids = [i.instance_id for i in group.instances]
reservations = conn_ec2.get_all_instances(instance_ids)
instances = [i for r in reservations for i in r.instances]

result['devtest-asg'] = {}
result['devtest-asg']['hosts'] = []
for r in reservations:
    for i in r.instances:
        result['devtest-asg']['hosts'].append('%s' % i.private_ip_address)
        result['devtest-asg']['vars'] = {'ansible_ssh_port': 36000}
</code></pre>

<p>def getlists():
    getData()
    print json.dumps(result)</p>

<p>getlists()
```</p>

<p>执行以下命令就可以愉快地使用 Ansible 了，其中 devtest-asg 是 ASG 的别名：</p>

<p><code>
ansible -i get_host.py  devtest-asg -m raw -a 'ls /'
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Flume 实时收集 Nginx 日志]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/04/23/flume-shi-shi-shou-ji-nginx-ri-zhi/"/>
    <updated>2016-04-23T09:13:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/04/23/flume-shi-shi-shou-ji-nginx-ri-zhi</id>
    <content type="html"><![CDATA[<p>在分布式系统中，各个机器都有程序运行的本地日志，有时为了分析需求，不得不这些分散的日志汇总需求，相信很多人会选择 Rsync，Scp 之类，
但它们的实时性不强，而且也会带来名字冲突的问题。扩展性差强人意，一点也不优雅。</p>

<p>现实中，我们就碰到了这样的需求：实时汇总线上多台服务器的 Nginx 日志。Flume 立功了。</p>

<h1 id="flume-">Flume 简介</h1>

<p><a href="https://flume.apache.org/"><strong>F</strong>lume</a> 是一个分布式，可靠高效的日志收集系统，它允许用户自定义数据传输模型，因此可扩展性也强。也有较强的容错和恢复机制.
以下是几个重要的概念</p>

<ul>
  <li>Event：Event 是 Flume 数据传输的基本单元。flume 以事件的形式将数据从源头传送到最终的目的。</li>
  <li>Agent：Agent包含 Sources, Channels, Sinks 和其他组件，它利用这些组件将events从一个节点传输到另一个节点或最终目的。</li>
  <li>Source：Source负责接收events，并将events批量的放到一个或多个Channels。</li>
  <li>Channel：Channel位于 Source 和 Sink 之间，用于缓存进来的events，当Sink成功的将events发送到下一跳的channel或最终目的，events从Channel移除。</li>
  <li>Sink：Sink 负责将 events 传输到下一跳或最终目的，成功完成后将events从channel移除。</li>
</ul>

<p><img src="/images/2016/04/flume.jpg"></p>

<ul>
  <li>Source 就有 Syslog Source, Kafka Source,HTTP Source, Exec Source Avro Source 等。</li>
  <li>Sink 有 Kafka Sink, Avro Sink, File Roll Sink, HDFS Sink 等。</li>
  <li>Channel 有 Memory Channel,File Channel 等</li>
</ul>

<p>它提供了一个骨架，以及多种 Source, Sink, Channel, 让你设计合适的数据模型。事实上也可以多个 Flume 联动完成，就像地铁的车厢一样。</p>

<h1 id="section">定义数据流模型</h1>

<p>回到我们开头的场景,我们要将多台服务器的 Nginx 日志进行汇总分析，</p>

<p>分成两个 flume 来实现</p>

<ul>
  <li>Flume1 数据流是 Exec Source -&gt; Memory Channel -&gt; Avro Sink,部署在业务机器上</li>
  <li>Flume2 数据流是 Avro Source -&gt; Memory Channel -&gt; FileRoll Sink</li>
</ul>

<p><img src="/images/2016/04/flume1toflume2.jpg"></p>

<h1 id="section-1">需要的准备</h1>

<p>你需要安装</p>

<ul>
  <li>下载 <a href="https://flume.apache.org/download.html">Flume</a></li>
  <li>安装 JavaSDk,并在下载解压之后的 conf/flume-env.sh，配置</li>
</ul>

<p><code>sh
# 我用的是oracle-java-8
export JAVA_HOME=/usr/lib/jvm/java-8-oracle/jre/
</code></p>

<ul>
  <li>思考你的数据流动模型，编写配置，如上文所说的Flume1, tail2avro.conf  ：</li>
</ul>

<p>```
agent.sources = s1
agent.channels = c1
agent.sinks = k1</p>

<p>agent.sources.s1.type=exec
agent.sources.s1.command=tail -F <your file="" path="">
agent.sources.s1.channels=c1</your></p>

<p>agent.channels.c1.type=memory
agent.channels.c1.capacity=10000
agent.channels.c1.transactionCapacity=10000</p>

<p>agent.sinks.k1.type = avro
agent.sinks.k1.hostname = <your target="" address="">
agent.sinks.k1.port = <your target="" port="">
agent.sinks.k1.channel=c1
```</your></your></p>

<p>Flume2 中的 avro2file.conf </p>

<p>```
agent.sources = s1
agent.channels = c1
agent.sinks = k1</p>

<p>agent.sources.s1.type = avro
agent.sources.s1.bind = <your address="">
agent.sources.s1.port = <your port="">
agent.sources.s1.channels = c1</your></your></p>

<p>agent.sinks.k1.type = file_roll
agent.sinks.k1.sink.directory = /data/log/ngxlog
# 滚动间隔
agent.sinks.k1.sink.rollInterval = 86400
agent.sinks.k1.channel = c1</p>

<p>agent.channels.c1.type = memory
# 队列里 Event 的容量
agent.channels.c1.capacity = 10000
agent.channels.c1.transactionCapacity = 10000
agent.channels.c1.keep-alive = 60
```</p>

<ul>
  <li>启动运行</li>
</ul>

<p>```
# 启动flume1
bin/flume-ng agent -n agent -c conf -f conf/tail2avro.conf \
-Dflume.root.logger=WARN</p>

<h1 id="flume2">启动flume2</h1>
<p>in/flume-ng agent -n agent -c conf -f conf/avro2file.conf \
-Dflume.root.logger=INFO
```</p>

<h2 id="section-2">参考</h2>

<ul>
  <li><a href="https://flume.apache.org/FlumeUserGuide.html">FlumeUserGuide</a> 官方的 FlumeUserGuide</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 该选择哪种持久化配置]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/03/10/gai-xuan-ze-na-chong-redischi-jiu-hua-pei-zhi/"/>
    <updated>2016-03-10T23:32:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/03/10/gai-xuan-ze-na-chong-redischi-jiu-hua-pei-zhi</id>
    <content type="html"><![CDATA[<p>这个标题或许会让你想起<a href="https://movie.douban.com/subject/1291843/">《黑客帝国》</a>里经典的台词，你要选择蓝色药丸，还是红色药丸？</p>

<p>Redis 是我们重度使用的一个开源软件，对它的持久化配置做一番相对深入的总结，是值得的。目前它有两种主流的持久化存储方式 SnapShot 以及 AOF 。</p>

<ul>
  <li><a href="#第一节">什么是 Snapshot</a></li>
  <li><a href="#第二节">什么是 AOF </a></li>
  <li><a href="#第三节">选择哪种药丸</a></li>
</ul>

<h3 id="第一节">什么是 Snapshot</h3>

<p>Snapshot 将内存中数据以结构化的方式序列化到 rdb 文件中，是默认的持久化方式，便于解析引擎快速解析和内存实施。快照得由间隔时间，变更次数同时符合才会触发， 该过程中并不阻塞客户端请求，copy-on-write 方式也意味着极端情况下可能会导致实际数据2倍内存的使用量。它首先将数据写入临时文件，结束后，将临时文件重名为 dump.rdb。可以使用 <code>redis-check-dump</code> 用来检测完整性</p>

<p>只有快照结束后才会将旧的文件替换成新的，因此任何时候 RDB 文件都是完整的。如果在触发 snapshot 之前，server 失效。会导致上一个时间点之后的数据未能序列化到 rdb 文件，安全性上稍弱。 </p>

<p>我们可手动执行 save 或 bgsave 命令让 redis 执行快照。两个命令的区别在于:</p>

<ul>
  <li>save 是由主进程进行快照操作，会阻塞其它请求;</li>
  <li>bgsave 会通过 fork 子进程进行快照操作;</li>
</ul>

<p>RDB 文件默认是经过压缩的二进制文件，占用的空间会小于内存中的数据，更加利于传输。设置如下，可以关闭快照功能</p>

<p><code>
save ""
</code></p>

<h4 id="section">相关配置</h4>

<p><code>
# snapshot触发的时机，save &lt;seconds&gt; &lt;changes&gt;， 比如600秒有2个操作
save 600 2
# 当snapshot 时出现错误无法继续时，是否阻塞客户端变更操作 
stop-writes-on-bgsave-error yes 
# 是否启用rdb文件压缩，默认为 yes cpu消耗，快速传输  
rdbcompression yes  
# rdb文件名称  
dbfilename dump.rdb  
</code></p>

<h3 id="第二节">什么是 AOF</h3>

<p>Append-only file，将 <code>操作 + 数据</code> 以格式化指令的方式追加到操作日志文件的尾部，在 append 操作返回后， 已经写入到文件或者即将写入，才进行实际的数据变更，日志文件保存了历史的操作过程；当 server 需要数据恢复时，可以直接回放此日志文件，即可还原所有的操作过程。 如果你期望数据更少的丢失，那么可以采用 AOF 模式。可以用 redis-check-aof 检测文件是否完整。</p>

<p>AOF 就是日志会记录变更操(例如：set/del等)，会导致AOF文件非常的庞大，意味着server失效后，数据恢复的过程将会很长；事实上，一条数据经过多次变更，将会产生多条AOF记录，其实只要保存当前的状态，历史的操作记录是可以抛弃的， 由此催生了 AOF ReWrite。</p>

<h4 id="aof-rewrite">什么是 AOF Rewrite</h4>

<p>其实是压缩 AOF 文件的过程，Redis 采取了类似 Snapshot 的方式：基于 <code>copy-on-write</code>，全量遍历内存中数据，然后逐个序列到 aof 文件中。因此 AOF Rewrite 能够正确反应当前内存数据的状态， Rewrite 过程中，新的变更操作将仍然被写入到原 AOF 文件中，同时这些新的变更操作也会被收集起来， 并不阻塞客户端请求。</p>

<h4 id="section-1">相关配置</h4>

<p>```
##只有在yes下，aof重写/文件同步等特性才会生效<br />
appendonly no  </p>

<h2 id="aof">指定aof文件名称</h2>
<p>appendfilename appendonly.aof  </p>

<h2 id="aofalways-everysec-noeverysec">指定aof操作中文件同步策略，有三个合法值：always everysec no，默认为everysec</h2>
<p>appendfsync everysec  </p>

<h2 id="aof-rewriteappendfsync-no-yes-no">在aof-rewrite期间，appendfsync 是否暂缓文件同步，no 表示不暂缓，yes 表示暂缓，默认为no</h2>
<p>no-appendfsync-on-rewrite no  </p>

<h2 id="aofrewrite-aofrewrite64mb512mb">aof文件rewrite触发的最小文件尺寸 只有大于此aof文件大于此尺寸是才会触发rewrite，默认64mb，建议512mb</h2>
<p>auto-aof-rewrite-min-size 64mb  </p>

<h2 id="rewriterewriteaof">相对于上一次rewrite，本次rewrite触发时aof文件应该增长的百分比</h2>
<p>auto-aof-rewrite-percentage 100<br />
```</p>

<h4 id="appendfsync-">appendfsync 方式：</h4>

<ul>
  <li>always：每一条 aof 记录都立即同步到文件，这是最安全的方式，但是更多的磁盘操作和阻塞延迟，IO 开支较大。</li>
  <li>everysec：每秒同步一次，性能和安全也是redis推荐的方式。如果服务器故障，有可能导致最近一秒内aof记录丢失。</li>
  <li>no：redis并不直接调用文件同步，而是交给操作系统来处理，操作系统可以根据buffer填充情况等择机触发同步；性能较好，在物理服务器故障时，数据丢失量会因OS配置有关。</li>
</ul>

<h3 id="第三节">选择哪种药丸</h3>

<ul>
  <li>AOF更安全，可将数据及时同步到文件中，但需要较多的磁盘IO，AOF文件尺寸较大，文件内容恢复相对较慢， 也更完整。</li>
  <li>Snapshot，安全性较差，它是正常时期数据备份及 master-slave 数据同步的最佳手段，文件尺寸较小，恢复数度较快。</li>
</ul>

<h4 id="section-2">主从架构的环境下的选择</h4>

<ul>
  <li>通常 master 使用AOF，slave 使用 Snapshot，master 需要确保数据完整性，slave 提供只读服务.</li>
  <li>如果你的网络稳定性差， 物理环境糟糕情况下，那么 master， slave均采取 AOF，这个在 master， slave角色切换时，可以减少时间成本；</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ 实时监控 nginx qps 的拓展]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/01/07/shi-shi-jian-kong-nginx-qps-de-tuo-zhan/"/>
    <updated>2016-01-07T12:59:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/01/07/shi-shi-jian-kong-nginx-qps-de-tuo-zhan</id>
    <content type="html"><![CDATA[<p>用下班时间写了一个 ngx lua 的拓展, <a href="https://github.com/zheng-ji/ngx_lua_reqstatus">GitHub</a>。可以:</p>

<ul>
  <li>[x] 实时监控域名的 qps</li>
  <li>[x] 实时监控域名的 5xx 个数</li>
  <li>[x] 实时监控域名的 响应时长</li>
  <li>[x] 并附带 Ganglia 监控插件</li>
</ul>

<h2 id="section">使用</h2>

<ul>
  <li>配置 <code>nginx.conf</code></li>
</ul>

<p>```
http {
    …
    …</p>

<pre><code>lua_shared_dict statics_dict    1M; # 初始化变量
lua_package_path "/etc/nginx/ngx_lua_reqstatus/?.lua";  #路径
log_by_lua_file "/etc/nginx/ngx_lua_reqstatus/hook.lua"; # 添加此句

server {
    listen 80;
    server_name  justforfun.com; 

    location /{
        ...
    }
}
# 监控服务
server {
    listen 127.0.0.1:6080;
    location /{
        access_by_lua_file "/etc/nginx/ngx_lua_reqstatus/status.lua";
    }
} } ```
</code></pre>

<ul>
  <li>效果</li>
</ul>

<p><code>
curl localhost:6080/?domain=justforfun.com
</code></p>

<ul>
  <li>输出</li>
</ul>

<p><code>
Server Name:    justforfun.com
Seconds SinceLast:   1.4399998188019 secs
Request Count:      1
Average Req Time:   0 secs
Requests Per Secs:  0.69444453182781
5xx num:    0
</code></p>

]]></content>
  </entry>
  
</feed>
