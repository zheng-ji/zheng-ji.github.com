<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Programe | 织网]]></title>
  <link href="http://zheng-ji.github.com/blog/categories/programe/atom.xml" rel="self"/>
  <link href="http://zheng-ji.github.com/"/>
  <updated>2017-06-04T13:34:14+08:00</updated>
  <id>http://zheng-ji.github.com/</id>
  <author>
    <name><![CDATA[zheng-ji]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[MIT 6.824 MapReduce]]></title>
    <link href="http://zheng-ji.github.com/blog/2017/06/04/mit-6-dot-824-mapreduce/"/>
    <updated>2017-06-04T13:27:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2017/06/04/mit-6-dot-824-mapreduce</id>
    <content type="html"><![CDATA[<p>学习完成 MIT 6.824 <a href="http://nil.csail.mit.edu/6.824/2017/labs/lab-1.html">Lab1 MapReduce</a>，做下笔记</p>

<h3 id="mapreduce-">MapReduce 的思路</h3>

<ul>
  <li>把数据分成 M 份，每一份叫做 Mi</li>
  <li>启动一个 master 对象，由它来控制如何分配调控</li>
  <li>master 挑出一个 worker，对 Mi 执行 map 操作，返回一个 KV 数组</li>
  <li>然后把 KV 数组分成 nReduce 份存在本地，等待 Reduce 操作。当 map 全部完成后，每个 Mi 产生 nReduce 份结果，每一个叫做 Ri。文件名：mrtmp-JobName-Mi-Ri 其中Mi Ri 分别表示数字，因此这一步会产生 M * nReduce 份文件。</li>
  <li>从每个 Mi 中选择一份 Ri。然后根据 Key 排序，把相同 Key 的 Value 合在一起，生成 Key /list(value)</li>
  <li>开始 Reduce，输入list(value)，最后会生成 R 份文件 mrtmp.JobName-res-Ri</li>
  <li>最后 Merge 成一个文件。</li>
</ul>

<h3 id="section">作业步骤</h3>

<ul>
  <li>Part1 完成 doMap 和 doReduce。doMap 完成3，4两个步骤. doReduce 完成5，6两个步骤。</li>
  <li>Part2 实现 main/wc.go 在Part1的基础上完成函数调用而已。</li>
  <li>Part3 把 map 和 reduce 的操作变成异步。用到了RPC，用channel 来实现并发控制。</li>
</ul>

<h3 id="section-1">代码笔记</h3>

<p><a href="https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce">源码</a></p>

<ul>
  <li>common.go <a href="https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/common.go#L11">11-32行</a>：可变参数打印日志，这个方法与C语言常用的类似</li>
  <li>common_reduce.go <a href="https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/common_reduce.go#L75">Line75</a>：sort.strings 对字符串切片排序</li>
  <li>commo_rpc.go <a href="https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/common_rpc.go#L59">Line59</a>：rpc调用方法</li>
  <li>master.go <a href="https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master.go#L95">Line95-99</a>：当mr.newCond.Broadcast()被调用，此处就被唤醒，否则一直阻塞,mr.wait()所在的逻辑分支才会被唤醒，否则继续阻塞</li>
  <li>master.go <a href="https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master.go#L15">Line15-16</a>：匿名参数，表示 Master 具有sync.Mutex的接口, 因而 Master 也能调用sync.Mutex的函数. 所以当调用 master.Lock()的时候也不足为奇</li>
  <li>master_rpc.go <a href="https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master_rpc.go#L14">Line14</a>,<a href="https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master_rpc.go#L37">Line37</a>：chanel 被close的时候，case &lt;- shutdown 也就被触发了 </li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[双端链表]]></title>
    <link href="http://zheng-ji.github.com/blog/2017/05/29/shuang-duan-lian-biao/"/>
    <updated>2017-05-29T23:19:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2017/05/29/shuang-duan-lian-biao</id>
    <content type="html"><![CDATA[<p>Nginx, Redis 项目中，均使用上了双链表。</p>

<ul>
  <li>
    <p>列表类型的键进行操作(RPUSH, LPOP)时，程序底层操作用的是双端链表。 <a href="https://github.com/antirez/redis/blob/unstable/src/adlist.c">源码</a></p>
  </li>
  <li>
    <p>Nginx 典型应用是在连接池中。Nginx 会处理大量的 socket 连接，为提高并发处理链接的能力，引入了连接池，其实现这个连接池用到了双链表。<a href="https://github.com/nginx/nginx/blob/master/src/core/ngx_queue.c">源码</a>.</p>
  </li>
</ul>

<p>对于双端链表，教科书上曾有提及，但如今映像并不深刻，再度理解并实践一次。</p>

<h3 id="section">结构定义与初始化</h3>

<p>```
typedef struct Node {
    int num;
    struct Node * next; //前继指针
    struct Node * pre;  //后继指针
} Node;</p>

<p>typedef struct dlist {
    Node * head; //双链表的指向头结点的元素
    Node * tail; //双链表指向尾部节点的元素，方便从后检索
} dlist;
```</p>

<p>初始化的双链表，<code>head</code>,<code>tail</code> 均为空。</p>

<h3 id="section-1">插入操作</h3>

<p>插入操作，是按照递增的顺序插入，涉及到双链表的更改，因此传参是指向链表的指针，分三种情况</p>

<ul>
  <li>空链表插入头元素，head 与 tail 节点均要修改</li>
  <li>在链表尾部插入节点，要变动 tail 指针</li>
  <li>中间插入节点</li>
</ul>

<p><img src="/images/2017/05/dlist-insert.png"></p>

<p>```
static int insertDlist(dlist <em>*list, int num) {
    Node * head = (</em>list) -&gt; head;
    Node * tail = (*list) -&gt; tail;</p>

<pre><code>if (list == NULL) return -1;

Node * node = initNode(num);
if (node == NULL) return -1;

// empty dlist
if ((*list) -&gt; head == NULL &amp;&amp; (*list) -&gt; tail == NULL) {
    (*list)-&gt; head = node;
    (*list)-&gt; tail = node;
    return 0;
}

while (head -&gt; next &amp;&amp; head -&gt; num &lt; num) {
    head = head -&gt; next;
}

// at the end
if (head-&gt;next == NULL) {
    head -&gt; next = node;
    node -&gt; pre = head;
    tail -&gt; pre = node;
    return 0;
} else {
    // in the middle
    node-&gt; next = head -&gt; next;
    head -&gt; next -&gt; pre = node;
    node -&gt; pre = head;
    head -&gt; next = node;
    return 0;
} }
</code></pre>

<p>```</p>

<h3 id="section-2">删除操作</h3>

<p>删除操作，要涉及到双链表的更改，因此传参是指向链表的指针，分三种情况</p>

<ul>
  <li>删除头结点，</li>
  <li>删除尾节点</li>
  <li>删除中间节点</li>
</ul>

<p><img src="/images/2017/05/dlist-delete.png"></p>

<p>```
static int deleteDlist(dlist ** list, int location) {
    Node * head = (*list) -&gt; head;
    Node * now = NULL;
    Node * last = NULL;</p>

<pre><code>if (head == NULL)
    return -1;
if (location &lt;= 0 || location &gt; numOfDlist(*list))
    return -1;

if (location == 1) {
    now = head;
    (*list) -&gt; head = now -&gt;next;
    head -&gt; next -&gt;pre = NULL;
    if (now) {
        free(now);
        now = NULL;
    }
    return 0;
}
int num = 0;
while (head &amp;&amp; num++ &lt; location) {
    head = head -&gt; next;
}

if (head -&gt; next == NULL) {
    now = (*list) -&gt; tail;
    head -&gt; pre -&gt; next = NULL;
    now -&gt; pre = head-&gt;pre;
    if (head) {
        free(head);
        head = NULL;
    }
} else {
    now = head -&gt; next;
    last = head -&gt; pre;
    now -&gt;pre = head -&gt; pre;
    last -&gt; next = head -&gt;next;
    if (head) {
        free(head);
        head = NULL;
    }
}
return 0; } ```
</code></pre>

<p>本文所述是 C 语言实现的，<a href="https://github.com/zheng-ji/ToyCollection/blob/master/Dlist/mydlist.c">源码</a>
在 Go 语言之中, <code>container/list</code> 包实现了双链表，直接引入就可以使用了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[记一次使用 redis 协议诡异的bug]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/09/28/ji-yi-ci-redis-server-bug/"/>
    <updated>2016-09-28T08:21:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/09/28/ji-yi-ci-redis-server-bug</id>
    <content type="html"><![CDATA[<p>记录昨天定位一个诡异 bug 的过程，我耗费了不少精力，你若有兴趣，请带着一点耐心看完它。</p>

<ul>
  <li><a href="#第一节">问题背景</a></li>
  <li><a href="#第二节">重新问题 </a></li>
  <li><a href="#第三节">试着解决问题</a></li>
  <li><a href="#第四节">一点总结</a></li>
</ul>

<h3 id="第一节">问题背景</h3>

<p>我们使用 <a href="https://github.com/youmi/go-redis-server">go-redis-server</a> 开发具有 redis 协议的服务。 按照文档，我们实现了如下接口，其背后访问的是 AWS 的 Dynamodb，我们的服务也开发了监控接口，以供我们这些程序狗知道它发生了什么。</p>

<p><code>
func (handler *RedisHandler) Get(key string) (result string, err error)
func (handler *RedisHandler) Set(key string, val string) (err error)
func (handler *RedisHandler) Del(key string) (count int, err error)
</code></p>

<p>这样，我们就能通过 redis 客户端来执行 Get，Set，Del 操作。</p>

<p>我在批量写入几千条数据时，通过监控接口，我看到服务突然卡住的样子，没有 Get，Set的统计信息了。但我能肯定的是客户端一直有数据在往服务写入，或者读写。
同时从 AWS 监控得到的反馈是 Dynamodb 使用超过预设值，我调高了读写预设值，重启服务，就恢复可用（重启大法好）。
程序试运行十多天，只发生过一次异常，之后再无重现。
这个事情没有搞清楚，就成为我一个心结。</p>

<h3 id="第二节">重现问题</h3>

<p>我们来看看代码</p>

<p>```
func (handler *RedisHandler) 
Set(key string, val string) (err error) {
	…</p>

<pre><code>m, err := JSONToMap(val)
_, err = table.PutItem(m)
if err != nil {
	log.Log.Errorf("PutItem failed, 
	table: %s, primary key: %s, value: %+v, 
	err: %s", 
	tableName, primaryVal, m, err.Error())
	return
}
return } ```
</code></pre>

<p>Set接口，简单的将数据写入 Dynamodb，Dynamodb 如果异常就返回错误，然后通过redis协议返回给客户端。</p>

<p>我很大程度确定那时候是因为 AWS Dynamodb 的异常导致这个错误的。除非这个巧合太牛逼了，难道 go-redis-server 接口不支持返回错误不成吗？这个猜想很快就被我们用实验否定了。</p>

<p>我想重新触发 AWS Dynamodb 返回写容量超标的错误，测试了一阵子，并不容易重现。有点沮丧，这个时候我回忆起 aws-go-sdk 的特点，如果给Dynamodb 字段 赋予空值，是会有异常返回的，
类似如下：</p>

<p><code>
ValidationException: One or more parameter values were invalid:
An AttributeValue may not contain an empty string
	status code: 400
</code></p>

<p>空值的测试明显容易制造。我在本地也开启服务，端口是1234，用 pyredis 作为客户端做测试。
测试脚本</p>

<p>```
import redis
import json
import random
r = redis.Redis(host=’localhost’,port=1234,db=0)</p>

<p>table_name = ‘test’
primary_key = ‘a’</p>

<p>i = 0
while True:
    if i &gt; 2:
        break
    data = {
        ‘a’: str(random.random()),
        ‘b’: ‘’,
    }
    key = ‘{0}:{1}:{2}’.format(table_name, primary_key, data[primary_key])
    value = json.dumps(data)
    r.set(key, value)
    i = i + 1
```</p>

<p>发现测试程序卡在终端，一动不动，strace 测试程序</p>

<p><code>
$ sudo strace -p 22404
Process 22404 attached
recvfrom(3,
</code></p>

<p>感觉像是在等待服务器返回，但是等不到回报的样子。</p>

<h3 id="第三节">试着解决问题</h3>

<p>难道 go-redis-server 这个框架有猫腻，我就开始了一下午的看源码之旅。不得不说源码写的真好。回头看我们出错的代码片段，我试着修改 err 信息，修改成自己定义的错误字符串。</p>

<p>```
func (handler *RedisHandler) Set(key string, val string) (err error) {
	…</p>

<pre><code>m, err := JSONToMap(val)
_, err = table.PutItem(m)
if err != nil {
	err = errors.New("I am a Custom Error")
	return
}
return } ```
</code></pre>

<p>再次执行测试脚本，这一次。2条测试数据很快就执行结束，并无阻塞。
好像看到了一丝曙光：error 内容的不一样，导致不一样的结果。类型一样，那么我能怀疑的就是格式，或者长度了。</p>

<p>```
AWS 错误信息的格式：
ValidationException: One or more parameter values were invalid:
An AttributeValue may not contain an empty string
	status code: 400</p>

<p>我自定义错误信息的格式：
I am a Custom Error
```</p>

<p>我特意加长了自定义错误的长度，结果也是能顺利执行不阻塞客户端。但是我给自定义错误字符串加入了换行符，果然客户端再次测试会出现阻塞。当出现错误的时候，源码中是调用了 ErrorReply.WriteTo 这个函数，特别的。返回错误的协议格式是</p>

<blockquote>
  <p>第一个字节将是“-”,并以CR + LF 结尾</p>
</blockquote>

<p>配合源码，以下是 go-redis-server 最核心的逻辑调度代码。</p>

<p><code>
for {
	request, err := parseRequest(conn)
	if err != nil {
		return err
	}
		request.Host = clientAddr
		request.ClientChan = clientChan
		reply, err := srv.Apply(request)
		if err != nil {
			return err
		}
		if _, err = reply.WriteTo(conn); err != nil {
			return err
		}
	}
	return nil
}
func (er *ErrorReply) WriteTo(w io.Writer) (int64, error) {
	n, err := w.Write([]byte("-" + er.code + " " + er.message + "\r\n"))
	return int64(n), err
}
</code></p>

<p>从 <a href="http://redis.cn/topics/protocol.html">Redis协议官方文档</a>，可以确定客户端与服务器端之间传输的每个 Redis 命令或者数据都以 <code>\r\n</code> 结尾。 我们的错误信息中间杀出了 <code>\n</code>，导致协议错乱，redis 客户端不能理解协议，就阻塞了。</p>

<h3 id="第四节">一点总结</h3>

<ul>
  <li>
    <p>以后我们使用 go-redis-server 的服务时候，要记得检查返回的字符串或者错误信息有没有包含换行符，如果有，最好做一次过滤替换。</p>
  </li>
  <li>
    <p>出现这个bug,我和同事都觉得不可思议，非常神奇。在没有其他直观线索的条件下，阅读使用的库的源码，并在源码加上一些输出验证语言加以辅助，收到了效果，的确需要一些耐心。但我觉得是值得的。</p>
  </li>
  <li>
    <p>李笑来说有效阅读就是精度，这次阅读代码过程中我还有意外的收获，我发现了 reflect 的妙用，以及函数注册在框架可以那么用，读完觉得很满足的样子，值得再记录一番。</p>
  </li>
</ul>

<hr />

<p>附链接：</p>

<ul>
  <li><a href="http://redis.cn/topics/protocol.html">Redis官方协议</a></li>
  <li><a href="https://github.com/youmi/go-redis-server">go-redis-server</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CuckooFilter，BloomFilter的优化]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/08/01/cuckoofilter/"/>
    <updated>2016-08-01T19:48:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/08/01/cuckoofilter</id>
    <content type="html"><![CDATA[<p>面对海量数据，我们需要一个索引数据结构，用来帮助查询，快速判断数据记录是否存在，这类数据结构叫过滤器，常用的选择是 <code>Bloom Filter</code>. 而 <code>Cuckoo Filter</code> 是它的优化变种。借此也用 Golang 实践了这个<a href="https://github.com/zheng-ji/goCuckoo">算法</a>。</p>

<p><img src="https://cloud.githubusercontent.com/assets/1414745/17084380/8c3a4896-51ee-11e6-869e-b087226cc5ce.jpg" alt="goCuckoo" /></p>

<p><code>Bloom Filter</code> 的位图模式有两个问题：</p>

<ul>
  <li>误报，它能判断元素一定不存在，但只能判断可能存在，因为存在其它元素被映射到部分相同位上，导致该位置1，那么一个不存在的元素可能会被误报成存在；</li>
  <li>漏报，如果删除了某个元素，导致该映射位被置0，那么本来存在的元素会被漏报成不存在。 </li>
</ul>

<p><code>Cuckoo Filter</code>，可以确保该元素存在的必然性，又可以在不违背此前提下删除任意元素，仅仅比 <code>Bloom Filter</code> 牺牲了微量空间效率。 它的的数据模型: </p>

<ul>
  <li>每个元素对应两个哈希算法，在哈希碰撞时会启用备用哈希算法。</li>
  <li>每一个桶是有4路的，每个槽对应一个指纹。</li>
</ul>

<p><img src="https://cloud.githubusercontent.com/assets/1414745/17103421/c97635e0-52b0-11e6-83ac-1b1fdbb5d31c.png" alt="model" /></p>

<h2 id="feature">Feature</h2>

<ul>
  <li>支持删除操作</li>
  <li>支持快速查找，支持 O(1) 查找速度</li>
  <li>高效的空间利用，四路槽的表，可以有95% 的空间利用率</li>
  <li>可替代布隆过滤器</li>
</ul>

<h2 id="installation">Installation</h2>

<p><code>
go get github.com/zheng-ji/goCuckoo
</code></p>

<h2 id="example">Example</h2>

<p>```go
import (
	“fmt”
	“github.com/zheng-ji/goCuckoo”
)</p>

<p>func main() {
    // speicify capacity 
	filter := cuckoo.NewCuckooFilter(10000)</p>

<pre><code>filter.Insert([]byte("zheng-ji"))
filter.Insert([]byte("stupid"))
filter.Insert([]byte("coder"))

if filter.Find([]byte("stupid")) {
	fmt.Println("exist")
} else {
	fmt.Println("Not exist")
}

filter.Del([]byte("stupid"))
filter.Println(filter.Size()) } ```
</code></pre>

<h2 id="section">参考</h2>

<ul>
  <li><a href="http://www.cs.cmu.edu/~binfan/papers/conext14_cuckoofilter.pdf">CMU Paper</a></li>
  <li><a href="http://www.cs.cmu.edu/~binfan/papers/conext14_cuckoofilter.pptx">CMU PPT</a></li>
  <li><a href="http://coolshell.cn/articles/17225.html">CoolShell Article</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Celery的Crontab实践]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/07/23/celeryde-crontabshi-jian/"/>
    <updated>2016-07-23T20:19:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/07/23/celeryde-crontabshi-jian</id>
    <content type="html"><![CDATA[<p>有时候我们需要处理耗时的操作，同时又要保持较快的响应速度，就需要借助异步队列的帮助。Celery 作为异步队列服务，想必是很多人和我一样的选择。用法在官方文档也详细介绍，不再赘述。</p>

<p>这次想记录的是用 Celery 来实现定时任务。这里也有一点点坑。</p>

<p>以下是 <code>main.py</code> 的内容</p>

<p>```py
from celery import Celery
from lib import distribute
from celery.schedules import crontab</p>

<p>app = distribute.app
app.conf.update(
    CELERYBEAT_SCHEDULE = {
        ‘every-minute’: {
            ‘task’: ‘test_cron’,
            ‘schedule’: crontab(minute=”*”),
            ‘args’: (16, 13),
        }
    },
    CELERY_INCLUDE=(“apps.tasks”,)
)
if <strong>name</strong> == ‘<strong>main</strong>’:
    app.start()
```</p>

<p>实际工作单元,我放在 apps 目录下的 <code>tasks.py</code> 文件中</p>

<p><code>py
from lib.distribute import app
@app.task(name="test_cron")
def mul(x, y):
    return x * y
</code></p>

<p>上述是一个简单的 Crontab 应用，它仅需要以下命令就能执行,
其中  <code>--beat</code> 表示 crontab 的应用</p>

<p><code>
python main.py worker --beat -l info
</code></p>

<p>起初我想把异步队列和定时任务放在一起,就加上了一句 CELERY_QUEUES 的配置</p>

<p><code>py
app.conf.update(
    // 添加的部分
    CELERY_QUEUES=(
        Queue(
          'test', Exchange('test_exchange'),
           routing_key='test_queue'
        ),
    ),
    CELERYBEAT_SCHEDULE = {
        'every-minute': {
            'task': 'test_cron',
            'schedule': crontab(minute="*"),
            'args': (16, 13),
        }
    },
    CELERY_INCLUDE=("apps.tasks",)
)
</code></p>

<p>同样用上述命令开启worker，发现这个时候 Crontab 不能工作了，后来看到官方的文档：</p>

<blockquote>
  <p>celery beat and celery worker as separate services instead. </p>
</blockquote>

<p>也就是说 Celery 的 Beat 需要和其他异步worker 分开，单独执行。</p>

<p>相关代码<a href="https://github.com/zheng-ji/ToyCollection/tree/master/celery_proj">链接</a></p>
]]></content>
  </entry>
  
</feed>
