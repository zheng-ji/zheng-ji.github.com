<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[织网]]></title>
  <link href="http://zheng-ji.github.com/atom.xml" rel="self"/>
  <link href="http://zheng-ji.github.com/"/>
  <updated>2017-02-25T17:48:53+08:00</updated>
  <id>http://zheng-ji.github.com/</id>
  <author>
    <name><![CDATA[zheng-ji]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[zookeeper 笔记]]></title>
    <link href="http://zheng-ji.github.com/blog/2017/02/25/zookeeper-bi-ji/"/>
    <updated>2017-02-25T17:30:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2017/02/25/zookeeper-bi-ji</id>
    <content type="html"><![CDATA[<p>ZooKeeper 是一个开源的分布式协调服务，是分布式数据一致性的解决方案。</p>

<h3 id="section">集群角色</h3>

<p>在 ZooKeeper 中，有三种角色： Leader，Follower，Observer</p>

<p>一个 ZooKeeper 集群同时只会有一个Leader，其他都是 Follower 或 Observer。
Leader 服务器为客户端提供读和写服务，Follower 和 Observer 都能提供读服务，不能提供写服务。区别在于，Observer 不参与 Leader 选举过程，也不参与写操作的过半写成功策略，因此 Observer 可以在不影响写性能的情况下提升集群的读性能。</p>

<h3 id="section-1">会话</h3>

<p>客户端和 ZooKeeper 服务器会与服务器建立一个 TCP 连接，通过这个连接，客户端能够通过心跳检测和服务器保持有效的会话，也能够向 ZooKeeper 服务器发送请求并接受响应，同时还能通过该连接接收来自服务器的 Watch 事件通知。</p>

<h3 id="section-2">数据节点</h3>

<p>ZooKeeper 中的数据节点是指数据模型中的数据单元，称为 ZNode。ZooKeeper将所有数据存储在内存中，数据模型是一棵树（ZNode Tree），由斜杠进行分割的路径，就是一个ZNode。每个ZNode上都会保存自己的数据内容，同时会保存一系列属性信息。每个ZNode不仅本身可以写数据，还可以有下一级文件或目录。</p>

<p>在ZooKeeper中，ZNode可以分为持久节点和临时节点两类。持久节点是指一旦这个 ZNode 被创建了，除非主动进行 ZNode 的移除操作，否则这个 ZNode 将一直保存在 ZooKeeper上。临时节点的生命周期跟客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。</p>

<p>ZooKeeper 允许用户为每个节点添加一个特殊的属性：SEQUENTIAL。一旦节点被标记上这个属性，那么在这个节点被创建的时候，ZooKeeper就会自动在其节点后面追加上一个整型数字，这个整型数字是一个由父节点维护的自增数字。</p>

<h3 id="section-3">版本</h3>

<p>ZooKeeper 的每个 ZNode 上都会存储数据，对于每个ZNode，ZooKeeper都会为其维护一个叫作Stat的数据结构，Stat中记录了这个ZNode的三个数据版本，分别是 version（当前ZNode的版本, cversion（当前ZNode子节点的版本）和 aversion（当前ZNode的ACL版本）。</p>

<h3 id="section-4">事务</h3>

<p>在 ZooKeeper 中，能改变 ZooKeeper 服务器状态的操作称为事务操作。包括数据节点创建与删除、数据内容更新和客户端会话创建与失效等操作。对应每一个事务请求，ZooKeeper都会为其分配一个全局唯一的事务ID，用ZXID表示，通常是一个64位的数字。每一个ZXID对应一次更新操作，从这些ZXID中可以间接地识别出ZooKeeper处理这些事务操作请求的全局顺序。</p>

<h3 id="watcher">Watcher</h3>

<p>ZooKeeper 允许用户在指定节点上注册一些 Watcher，并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到感兴趣的客户端上去。该机制是 ZooKeeper 实现分布式协调服务的重要特性。</p>

<h3 id="acl">ACL</h3>

<p>ZooKeeper 采用 Access Control Lists 策略来进行权限控制。ZooKeeper 定义了如下5种权限。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class=""><span class="line">CREATE: 创建子节点的权限。
</span><span class="line">READ: 获取节点数据和子节点列表的权限。
</span><span class="line">WRITE：更新节点数据的权限。
</span><span class="line">DELETE: 删除子节点的权限。
</span><span class="line">ADMIN: 设置节点ACL的权限。
</span><span class="line">注意：CREATE 和 DELETE 都是针对子节点的权限控制。</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="zab-">ZAB 原子广播协议</h3>

<p>ZooKeeper Atomic Broadcast（ZAB，ZooKeeper原子广播协议）的协议作为其数据一致性的核心算法。</p>

<p>所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为Leader服务器，而剩下的其他服务器则成为 Follower 服务器。Leader 服务器负责将一个客户端事务请求转换成一个事务 Proposal（提案）并将该 Proposal分发给集群中所有的 Follower 服务器。之后 Leader 服务器需要等待所有 Follower 服务器的反馈，一旦超过半数的 Follower 服务器进行了正确的反馈后，Leader 就会再次向所有的 Follower 服务器分发 Commit 消息，要求对刚才的 Proposal 进行提交。</p>

<h3 id="section-5">应用场景</h3>

<ul>
  <li>数据发布与订阅-配置中心</li>
</ul>

<p>发布者将数据发布到 ZooKeeper 节点上，供订阅者进行数据订阅，进而达到动态获取数据的目的，实现配置信息的集中式管理和动态更新。全局配置信息就可以发布到 ZooKeeper 上，让客户端（集群的机器）去订阅该消息。</p>

<p>客户端想服务端注册自己需要关注的节点，一旦该节点的数据发生变更，那么服务端就会向相应的客户端发送 Watcher 事件通知，客户端接收到这个消息通知后，需要主动到服务端获取最新的数据（推拉结合）。</p>

<ul>
  <li>
    <p>命名服务，即生成全局唯一的ID。</p>
  </li>
  <li>
    <p>分布式协调通知</p>
  </li>
</ul>

<p>ZooKeeper 中特有 Watcher 注册与异步通知机制，实现对数据变更的实时处理。不同的客户端都对ZK上同一个ZNode 进行注册，监听 ZNode 的变化（包括ZNode本身内容及子节点的），如果 ZNode 发生了变化，那么所有订阅的客户端都能够接收到相应的 Watcher 通知，并做出相应的处理，是一种通用的分布式系统机器间的通信方式。</p>

<ul>
  <li>心跳检测</li>
</ul>

<p>基于 ZK 临时节点的特性，可以让不同的进程都在 ZK 的一个指定节点下创建临时子节点，不同的进程直接可以根据这个临时子节点来判断对应的进程是否存活。通过这种方式，检测和被检测系统直接并不需要直接相关联，而是通过 ZK 上的某个节点进行关联，大大减少了系统耦合。</p>

<ul>
  <li>分布式锁</li>
</ul>

<p>分布式锁是控制分布式系统之间同步访问共享资源的一种方式。分布式锁又分为排他锁和共享锁两种。 排他锁又称为写锁或独占锁，共享锁又称为读锁。</p>

<p>把 ZooKeeper 上一个 ZNode 看作是一个锁，获得锁就通过创建ZNode的方式来实现。所有客户端都去/x_lock节点下创建临时子节点/x_lock/lock。ZooKeeper会保证在所有客户端中，最终只有一个客户端能够创建成功，那么就可以认为该客户端获得了锁。同时，所有没有获取到锁的客户端就需要到/x_lock节点上注册一个子节点变更的 Watcher 监听，以便实时监听到 lock 节点的变更情况。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Squid 做正向代理]]></title>
    <link href="http://zheng-ji.github.com/blog/2017/02/22/zheng-xiang-yu-fan-xiang-dai-li/"/>
    <updated>2017-02-22T22:30:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2017/02/22/zheng-xiang-yu-fan-xiang-dai-li</id>
    <content type="html"><![CDATA[<h3 id="section">正向代理和反向代理</h3>

<ul>
  <li>正向代理</li>
</ul>

<p>正向代理 是一个位于客户端和原始服务器之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定原始服务器，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。</p>

<ul>
  <li>反向代理</li>
</ul>

<p>反向代理正好相反，对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容原本就是它自己的一样。</p>

<h3 id="section-1">正向代理软件</h3>

<p>Nginx 能做正向代理，遗憾的是它不能做 HTTPS 的正向代理。以下是一个例子。</p>

<ul>
  <li>不能有 hostname。 </li>
  <li>必须有 resolver, 即 DNS</li>
  <li>配置正向代理参数，均是由 Nginx 变量组成</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class=""><span class="line">server{
</span><span class="line">      resolver 8.8.8.8;
</span><span class="line">      resolver_timeout 30s; 
</span><span class="line">      listen 80;
</span><span class="line">      location / {
</span><span class="line">                proxy_pass http://$http_host$request_uri;
</span><span class="line">                proxy_set_header Host $http_host;
</span><span class="line">        }
</span><span class="line">}</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Squid 可正向代理 HTTP 以及 HTTPS</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo apt-get install squid</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>编辑 <code>/etc/squid3/squid.conf</code>, 并重启</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class=""><span class="line">http_port 3128                 	#代理服务器的端口
</span><span class="line">#http_access deny !Safe_ports 	#注释掉此项
</span><span class="line">#http_access deny manager     	#注释掉此项
</span><span class="line">
</span><span class="line">#添加下面两项，设置哪些网段可以访问本代理服务器
</span><span class="line">acl our_networks src 172.16.1.0/24 
</span><span class="line">http_access allow our_networks</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo service squid3 restart</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Squid 的层次代理值得一提， 若我们需要定期地切换代理服务器的话, 启动一个 Squid 代理, 而这个代理会将请求转发到其他代理上面. 然后我们只需定时更新本地 Squid 代理的配置文件, 然后重启这个本地代理即可. 层次代理用到了 <code>cache_peer</code> 这个配置文件</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class=""><span class="line">cache_peer hostname type http_port icp_port option
</span><span class="line">
</span><span class="line">e.g.
</span><span class="line">cache_peer xxx.proxy.com parent 9020 0 no-query default login=xxxxx:yyyy</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>hostname: 指被请求的同级子代理服务器或父代理服务器。可以用主机名或ip地址表示；</li>
  <li>type：指明 hostname 的类型，是同级子代理服务器还是父代理服务器，也即 parent 还是 sibling；</li>
  <li>http_port：hostname的监听端口；</li>
  <li>icp_port：hostname 上的ICP监听端口，对于不支持ICP协议的可指定7；</li>
  <li>options：可以包含一个或多个关键字。
    <ol>
      <li>proxy-only：指明从peer得到的数据在本地不进行缓存，缺省地，squid是要缓存这部分数据的；</li>
      <li>weight=n：用于有多个peer的情况，如果多于一个以上的peer拥有你请求的数据时，squid通过计算每个peer ICP 响应时间来 决定其weight的值，然后 squid 向其中拥有最大 weight 的peer发出ICP请求。</li>
      <li>no-query：不向该peer发送ICP请求。如果该peer不可用时，可以使用该选项；</li>
      <li>Default：有点象路由表中的缺省路由，该peer将被用作最后的尝试手段。当你只有一个父代理服务器并且其不支持ICP协议时，可以使用default和no-query选项让所有请求都发送到该父代理服务器；</li>
    </ol>
  </li>
  <li>login=user:password：当你的父代理服务器要求用户认证时可以使用该选项来进行认证</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[cgroup 限制计算资源]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/12/02/cgroupxian-zhi-ji-suan-zi-yuan/"/>
    <updated>2016-12-02T15:41:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/12/02/cgroupxian-zhi-ji-suan-zi-yuan</id>
    <content type="html"><![CDATA[<p>Cgroup 实现了对计算机资源使用上的隔离，它是 Docker 底层的基础技术。我们可以用它来限制程序使用的CPU、内存、磁盘。</p>

<h3 id="section">安装</h3>

<p>在 Ubuntu 14.04 下安装的方法：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo apt-get install cgroup-bin</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>安装完后执行
<code>mount -t cgroup</code> 会出现如下，可以看到它其实是一个文件系统</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class=""><span class="line">cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,relatime,cpuset)
</span><span class="line">cgroup on /sys/fs/cgroup/cpu type cgroup (rw,relatime,cpu)
</span><span class="line">...
</span><span class="line">cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,relatime,hugetlb)</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>如果没有看到以上的目录，这时候需要手动 mount 了</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class=""><span class="line">cd /sys/fs
</span><span class="line">mkdir cgroup
</span><span class="line">mount -t tmpfs cgroup_root ./cgroup
</span><span class="line">mkdir cgroup/cpuset
</span><span class="line">mount -t cgroup -ocpuset cpuset ./cgroup/cpuset/
</span><span class="line">mkdir cgroup/cpu
</span><span class="line">mount -t cgroup -ocpu cpu ./cgroup/cpu/
</span><span class="line">mkdir cgroup/memory
</span><span class="line">mount -t cgroup -omemory memory ./cgroup/memory/</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="section-1">实践</h3>

<p>我们来感性认识下 cgroup 吧，编写一个耗费 CPU 的程序，姑且叫暴走程序(baozou)</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line"><span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
</span><span class="line">    <span class="n">count</span> <span class="o">=</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>运行该程序，top -p 之，100% CPU使用率</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="py"><span class="line">  <span class="n">PID</span>      <span class="n">PR</span>  <span class="n">NI</span>    <span class="n">VIRT</span>    <span class="n">RES</span>    <span class="n">SHR</span> <span class="n">S</span>  <span class="o">%</span><span class="n">CPU</span> <span class="o">%</span><span class="n">MEM</span>     <span class="n">TIME</span><span class="o">+</span> <span class="n">COMMAND</span>
</span><span class="line"><span class="mi">16515</span>      <span class="mi">20</span>   <span class="mi">0</span>    <span class="mi">2336</span>    <span class="mi">728</span>    <span class="mi">544</span> <span class="n">R</span>  <span class="mf">100.0</span>  <span class="mf">0.0</span>   <span class="mi">1</span><span class="p">:</span><span class="mf">27.23</span> <span class="n">baozou</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>我想限制暴走程序 CPU 使用该如何做? 我们手动创建一个 cgroup 目录来针对它。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nb">cd</span> /sys/fs/cgroup/cpu
</span><span class="line">mkdir calm      // 名字可自定义
</span><span class="line">ls /calm        // 该目录下自动生产与 CPU 有关的文件
</span><span class="line">cgroup.clone_children  cpu.cfs_period_us  cpu.shares  notify_on_release
</span><span class="line">cgroup.procs           cpu.cfs_quota_us   cpu.stat    tasks
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>接着写入限制规则</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">// 默认是100000，20000意味着限制它的cpu为20%
</span><span class="line"><span class="nb">echo </span>20000 &gt; /sys/fs/cgroup/cpu/calm/cpu.cfs_quota_us,
</span><span class="line">
</span><span class="line">// 写入程序的 PID 16515
</span><span class="line"><span class="nb">echo </span>16515 &gt; /sys/fs/cgroup/cpu/calm/tasks
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>于是 CPU 就降到 20% 。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">  PID       PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
</span><span class="line">16515       20   0    2336    728    544 R  20.0  0.0   1:27.23 baozou
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>除了这种需要指定 PID 来限制资源的方法，也可通过指定规则来执行，更显得方便，效果和上述一致。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">sudo cgexec -g cpu:calm ./baozou
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>可以看看这个限制规则做了什么?</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>sudo cgget calm
</span><span class="line">calm:
</span><span class="line">cpu.shares: 1024
</span><span class="line">cpu.cfs_quota_us: 20000
</span><span class="line">cpu.stat: nr_periods 6943
</span><span class="line">    nr_throttled 6941
</span><span class="line">    throttled_time 563080015831
</span><span class="line">cpu.cfs_period_us: 100000
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>上述的例子中，我们手动创建了 <code>calm</code>， 其实也能通过命令来做到的</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">// 创建cgroup 文件目录
</span><span class="line">sudo cgcreate -g cpu:/calm -g memory:/calm
</span><span class="line">
</span><span class="line">// 设置限制的参数
</span><span class="line">sudo cgset -r cpu.shares<span class="o">=</span>200 calm
</span><span class="line">
</span><span class="line">// 限制了内存
</span><span class="line">sudo cgset -r memory.limit_in_bytes<span class="o">=</span>64k calm
</span><span class="line">
</span><span class="line">// 可以删除
</span><span class="line">sudo cgdelete cpu/calm memory:/calm
</span></code></pre></td></tr></table></div></figure></notextile></div>

<hr />

<p>参考链接：</p>

<ul>
  <li><a href="http://coolshell.cn/articles/17049.html">Docker基础技术: Linux CGroup</a></li>
  <li><a href="http://www.jianshu.com/p/dc3140699e79">cgroup实践</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[记一次使用 redis 协议诡异的bug]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/09/28/ji-yi-ci-redis-server-bug/"/>
    <updated>2016-09-28T08:21:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/09/28/ji-yi-ci-redis-server-bug</id>
    <content type="html"><![CDATA[<p>记录昨天定位一个诡异 bug 的过程，我耗费了不少精力，你若有兴趣，请带着一点耐心看完它。</p>

<ul>
  <li><a href="#第一节">问题背景</a></li>
  <li><a href="#第二节">重新问题 </a></li>
  <li><a href="#第三节">试着解决问题</a></li>
  <li><a href="#第四节">一点总结</a></li>
</ul>

<h3 id="第一节">问题背景</h3>

<p>我们使用 <a href="https://github.com/youmi/go-redis-server">go-redis-server</a> 开发具有 redis 协议的服务。 按照文档，我们实现了如下接口，其背后访问的是 AWS 的 Dynamodb，我们的服务也开发了监控接口，以供我们这些程序狗知道它发生了什么。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">func (handler *RedisHandler) Get(key string) (result string, err error)
</span><span class="line">func (handler *RedisHandler) Set(key string, val string) (err error)
</span><span class="line">func (handler *RedisHandler) Del(key string) (count int, err error)</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>这样，我们就能通过 redis 客户端来执行 Get，Set，Del 操作。</p>

<p>我在批量写入几千条数据时，通过监控接口，我看到服务突然卡住的样子，没有 Get，Set的统计信息了。但我能肯定的是客户端一直有数据在往服务写入，或者读写。
同时从 AWS 监控得到的反馈是 Dynamodb 使用超过预设值，我调高了读写预设值，重启服务，就恢复可用（重启大法好）。
程序试运行十多天，只发生过一次异常，之后再无重现。
这个事情没有搞清楚，就成为我一个心结。</p>

<h3 id="第二节">重现问题</h3>

<p>我们来看看代码</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
</pre></td><td class="code"><pre><code class=""><span class="line">func (handler *RedisHandler) 
</span><span class="line">Set(key string, val string) (err error) {
</span><span class="line">	...
</span><span class="line">
</span><span class="line">	m, err := JSONToMap(val)
</span><span class="line">	_, err = table.PutItem(m)
</span><span class="line">	if err != nil {
</span><span class="line">		log.Log.Errorf("PutItem failed, 
</span><span class="line">		table: %s, primary key: %s, value: %+v, 
</span><span class="line">		err: %s", 
</span><span class="line">		tableName, primaryVal, m, err.Error())
</span><span class="line">		return
</span><span class="line">	}
</span><span class="line">	return
</span><span class="line">}</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Set接口，简单的将数据写入 Dynamodb，Dynamodb 如果异常就返回错误，然后通过redis协议返回给客户端。</p>

<p>我很大程度确定那时候是因为 AWS Dynamodb 的异常导致这个错误的。除非这个巧合太牛逼了，难道 go-redis-server 接口不支持返回错误不成吗？这个猜想很快就被我们用实验否定了。</p>

<p>我想重新触发 AWS Dynamodb 返回写容量超标的错误，测试了一阵子，并不容易重现。有点沮丧，这个时候我回忆起 aws-go-sdk 的特点，如果给Dynamodb 字段 赋予空值，是会有异常返回的，
类似如下：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">ValidationException: One or more parameter values were invalid:
</span><span class="line">An AttributeValue may not contain an empty string
</span><span class="line">	status code: 400</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>空值的测试明显容易制造。我在本地也开启服务，端口是1234，用 pyredis 作为客户端做测试。
测试脚本</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
</pre></td><td class="code"><pre><code class=""><span class="line">import redis
</span><span class="line">import json
</span><span class="line">import random
</span><span class="line">r = redis.Redis(host='localhost',port=1234,db=0)
</span><span class="line">
</span><span class="line">table_name = 'test'
</span><span class="line">primary_key = 'a'
</span><span class="line">
</span><span class="line">i = 0
</span><span class="line">while True:
</span><span class="line">    if i &gt; 2:
</span><span class="line">        break
</span><span class="line">    data = {
</span><span class="line">        'a': str(random.random()),
</span><span class="line">        'b': ‘’,
</span><span class="line">    }
</span><span class="line">    key = '{0}:{1}:{2}'.format(table_name, primary_key, data[primary_key])
</span><span class="line">    value = json.dumps(data)
</span><span class="line">    r.set(key, value)
</span><span class="line">    i = i + 1</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>发现测试程序卡在终端，一动不动，strace 测试程序</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">$ sudo strace -p 22404
</span><span class="line">Process 22404 attached
</span><span class="line">recvfrom(3,</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>感觉像是在等待服务器返回，但是等不到回报的样子。</p>

<h3 id="第三节">试着解决问题</h3>

<p>难道 go-redis-server 这个框架有猫腻，我就开始了一下午的看源码之旅。不得不说源码写的真好。回头看我们出错的代码片段，我试着修改 err 信息，修改成自己定义的错误字符串。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class=""><span class="line">func (handler *RedisHandler) Set(key string, val string) (err error) {
</span><span class="line">	...
</span><span class="line">
</span><span class="line">	m, err := JSONToMap(val)
</span><span class="line">	_, err = table.PutItem(m)
</span><span class="line">	if err != nil {
</span><span class="line">		err = errors.New("I am a Custom Error")
</span><span class="line">		return
</span><span class="line">	}
</span><span class="line">	return
</span><span class="line">}</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>再次执行测试脚本，这一次。2条测试数据很快就执行结束，并无阻塞。
好像看到了一丝曙光：error 内容的不一样，导致不一样的结果。类型一样，那么我能怀疑的就是格式，或者长度了。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class=""><span class="line">AWS 错误信息的格式：
</span><span class="line">ValidationException: One or more parameter values were invalid:
</span><span class="line">An AttributeValue may not contain an empty string
</span><span class="line">	status code: 400
</span><span class="line">
</span><span class="line">我自定义错误信息的格式：
</span><span class="line">I am a Custom Error</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>我特意加长了自定义错误的长度，结果也是能顺利执行不阻塞客户端。但是我给自定义错误字符串加入了换行符，果然客户端再次测试会出现阻塞。当出现错误的时候，源码中是调用了 ErrorReply.WriteTo 这个函数，特别的。返回错误的协议格式是</p>

<blockquote>
  <p>第一个字节将是“-”,并以CR + LF 结尾</p>
</blockquote>

<p>配合源码，以下是 go-redis-server 最核心的逻辑调度代码。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
</pre></td><td class="code"><pre><code class=""><span class="line">for {
</span><span class="line">	request, err := parseRequest(conn)
</span><span class="line">	if err != nil {
</span><span class="line">		return err
</span><span class="line">	}
</span><span class="line">		request.Host = clientAddr
</span><span class="line">		request.ClientChan = clientChan
</span><span class="line">		reply, err := srv.Apply(request)
</span><span class="line">		if err != nil {
</span><span class="line">			return err
</span><span class="line">		}
</span><span class="line">		if _, err = reply.WriteTo(conn); err != nil {
</span><span class="line">			return err
</span><span class="line">		}
</span><span class="line">	}
</span><span class="line">	return nil
</span><span class="line">}
</span><span class="line">func (er *ErrorReply) WriteTo(w io.Writer) (int64, error) {
</span><span class="line">	n, err := w.Write([]byte("-" + er.code + " " + er.message + "\r\n"))
</span><span class="line">	return int64(n), err
</span><span class="line">}</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>从 <a href="http://redis.cn/topics/protocol.html">Redis协议官方文档</a>，可以确定客户端与服务器端之间传输的每个 Redis 命令或者数据都以 <code>\r\n</code> 结尾。 我们的错误信息中间杀出了 <code>\n</code>，导致协议错乱，redis 客户端不能理解协议，就阻塞了。</p>

<h3 id="第四节">一点总结</h3>

<ul>
  <li>
    <p>以后我们使用 go-redis-server 的服务时候，要记得检查返回的字符串或者错误信息有没有包含换行符，如果有，最好做一次过滤替换。</p>
  </li>
  <li>
    <p>出现这个bug,我和同事都觉得不可思议，非常神奇。在没有其他直观线索的条件下，阅读使用的库的源码，并在源码加上一些输出验证语言加以辅助，收到了效果，的确需要一些耐心。但我觉得是值得的。</p>
  </li>
  <li>
    <p>李笑来说有效阅读就是精度，这次阅读代码过程中我还有意外的收获，我发现了 reflect 的妙用，以及函数注册在框架可以那么用，读完觉得很满足的样子，值得再记录一番。</p>
  </li>
</ul>

<hr />

<p>附链接：</p>

<ul>
  <li><a href="http://redis.cn/topics/protocol.html">Redis官方协议</a></li>
  <li><a href="https://github.com/youmi/go-redis-server">go-redis-server</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[共享内存与信号量]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/09/25/gong-xiang-nei-cun-yu-xin-hao-liang/"/>
    <updated>2016-09-25T23:37:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/09/25/gong-xiang-nei-cun-yu-xin-hao-liang</id>
    <content type="html"><![CDATA[<p>今天和朋友聊天，他多次提到了共享内存，惭愧的是我没怎么用上，只是从 APUE 等神书阅读到此类名词。这个周末，我来搞懂它们。</p>

<h3 id="section">共享内存</h3>

<p>它是 Linux 最底层的通信机制，被称为最快的通信机制。多个进程共享同一个内存区域实现进程间通信。一个进程创建一个共享内存区域，并将数据存放到共享内存中，而后多个进程对其进行访问。</p>

<p>借鉴网友的例子，我做了注释和修改，一个进程写共享内存 (shmwrite.c)，一个进程读共享内存(shmread.c)。</p>

<p>共享内存并未提供同步机制，在第一个进程结束对共享内存的写操作之前，并无自动机制阻止第二个进程开始对它进行读取。上述代码中，我通过自己维护了一个变量 isWritten 来控制同步行为。</p>

<p>还好，伟大的计算机先驱们提供了信号量来帮我们解决同步的问题。</p>

<h3 id="section-1">信号量</h3>
<p>为了防止出现因多个程序同时访问一个共享资源带来的问题，Linux 使用 信号量协调进程对共享资源的访问的。
信号量只能进行两种操作等待和发送信号，即 P(sv) 和 V(sv).</p>

<ul>
  <li>P(sv)：当sv的值大于零，就减1；当它的值为零，就挂起该进程的执行。</li>
  <li>V(sv)：当有其他进程因等待sv而被挂起，就让它恢复运行，当没有进程因等待sv而挂起，就给它加1.</li>
</ul>

<p>比如：两个进程共享信号量 sv，其中一个进程执行了 P(sv) 操作，它将得到信号量，进入临界区，将 sv 减1。此时sv=0,第二个进程将被阻止进入临界区，它会被挂起以等待第一个进程离开临界区域,并执行 V(sv) 释放信号量，这时第二个进程就可以恢复执行。</p>

<h3 id="mmap--shmget">mmap 还是 shmget</h3>

<p>这两个东西某种程度上很类似。</p>

<p>内存映射，将用户空间的一段内存区域映射到内核空间,用户对这段内存区域的修改可以直接反映到内核空间，同样，内核空间对这段区域的修改也直接反映用户空间。两者之间需要大量数据传输等操作的话效率是非常高的.</p>

<p>mmap 并不是完全为了用于共享内存而设计的。它提供了不同于一般对普通文件的访问方式，进程可以像读写内存一样对普通文件的操作。而 Posix 或系统V的共享内存 IPC 则纯粹用于共享目的.</p>

<p>mmap 使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以像访问普通内存一样对文件进行访问，不必再调用 read()，write() 等操作。mmap 并不分配空间, 只是将文件映射到调用进程的地址空间里 然后你就可以用 memcpy 等操作写文件。</p>

<hr />

<p>附上代码：</p>

<ul>
  <li>共享数据结构: <a href="https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmdata.h">shmdata.h</a></li>
  <li>读共享内存：<a href="https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmread.c">shmread.c</a></li>
  <li>写共享内存：<a href="https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmwrite.c">shmwrite.c</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CuckooFilter，BloomFilter的优化]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/08/01/cuckoofilter/"/>
    <updated>2016-08-01T19:48:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/08/01/cuckoofilter</id>
    <content type="html"><![CDATA[<p>面对海量数据，我们需要一个索引数据结构，用来帮助查询，快速判断数据记录是否存在，这类数据结构叫过滤器，常用的选择是 <code>Bloom Filter</code>. 而 <code>Cuckoo Filter</code> 是它的优化变种。借此也用 Golang 实践了这个<a href="https://github.com/zheng-ji/goCuckoo">算法</a>。</p>

<p><img src="https://cloud.githubusercontent.com/assets/1414745/17084380/8c3a4896-51ee-11e6-869e-b087226cc5ce.jpg" alt="goCuckoo" /></p>

<p><code>Bloom Filter</code> 的位图模式有两个问题：</p>

<ul>
  <li>误报，它能判断元素一定不存在，但只能判断可能存在，因为存在其它元素被映射到部分相同位上，导致该位置1，那么一个不存在的元素可能会被误报成存在；</li>
  <li>漏报，如果删除了某个元素，导致该映射位被置0，那么本来存在的元素会被漏报成不存在。 </li>
</ul>

<p><code>Cuckoo Filter</code>，可以确保该元素存在的必然性，又可以在不违背此前提下删除任意元素，仅仅比 <code>Bloom Filter</code> 牺牲了微量空间效率。 它的的数据模型: </p>

<ul>
  <li>每个元素对应两个哈希算法，在哈希碰撞时会启用备用哈希算法。</li>
  <li>每一个桶是有4路的，每个槽对应一个指纹。</li>
</ul>

<p><img src="https://cloud.githubusercontent.com/assets/1414745/17103421/c97635e0-52b0-11e6-83ac-1b1fdbb5d31c.png" alt="model" /></p>

<h2 id="feature">Feature</h2>

<ul>
  <li>支持删除操作</li>
  <li>支持快速查找，支持 O(1) 查找速度</li>
  <li>高效的空间利用，四路槽的表，可以有95% 的空间利用率</li>
  <li>可替代布隆过滤器</li>
</ul>

<h2 id="installation">Installation</h2>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">go get github.com/zheng-ji/goCuckoo</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="example">Example</h2>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
</pre></td><td class="code"><pre><code class="go"><span class="line"><span class="kn">import</span> <span class="p">(</span>
</span><span class="line">	<span class="s">&quot;fmt&quot;</span>
</span><span class="line">	<span class="s">&quot;github.com/zheng-ji/goCuckoo&quot;</span>
</span><span class="line"><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="kd">func</span> <span class="nx">main</span><span class="p">()</span> <span class="p">{</span>
</span><span class="line">    <span class="c1">// speicify capacity </span>
</span><span class="line">	<span class="nx">filter</span> <span class="o">:=</span> <span class="nx">cuckoo</span><span class="p">.</span><span class="nx">NewCuckooFilter</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">	<span class="nx">filter</span><span class="p">.</span><span class="nx">Insert</span><span class="p">([]</span><span class="nb">byte</span><span class="p">(</span><span class="s">&quot;zheng-ji&quot;</span><span class="p">))</span>
</span><span class="line">	<span class="nx">filter</span><span class="p">.</span><span class="nx">Insert</span><span class="p">([]</span><span class="nb">byte</span><span class="p">(</span><span class="s">&quot;stupid&quot;</span><span class="p">))</span>
</span><span class="line">	<span class="nx">filter</span><span class="p">.</span><span class="nx">Insert</span><span class="p">([]</span><span class="nb">byte</span><span class="p">(</span><span class="s">&quot;coder&quot;</span><span class="p">))</span>
</span><span class="line">
</span><span class="line">	<span class="k">if</span> <span class="nx">filter</span><span class="p">.</span><span class="nx">Find</span><span class="p">([]</span><span class="nb">byte</span><span class="p">(</span><span class="s">&quot;stupid&quot;</span><span class="p">))</span> <span class="p">{</span>
</span><span class="line">		<span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">&quot;exist&quot;</span><span class="p">)</span>
</span><span class="line">	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span><span class="line">		<span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">&quot;Not exist&quot;</span><span class="p">)</span>
</span><span class="line">	<span class="p">}</span>
</span><span class="line">
</span><span class="line">	<span class="nx">filter</span><span class="p">.</span><span class="nx">Del</span><span class="p">([]</span><span class="nb">byte</span><span class="p">(</span><span class="s">&quot;stupid&quot;</span><span class="p">))</span>
</span><span class="line">	<span class="nx">filter</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="nx">filter</span><span class="p">.</span><span class="nx">Size</span><span class="p">())</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="section">参考</h2>

<ul>
  <li><a href="http://www.cs.cmu.edu/~binfan/papers/conext14_cuckoofilter.pdf">CMU Paper</a></li>
  <li><a href="http://www.cs.cmu.edu/~binfan/papers/conext14_cuckoofilter.pptx">CMU PPT</a></li>
  <li><a href="http://coolshell.cn/articles/17225.html">CoolShell Article</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Celery的Crontab实践]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/07/23/celeryde-crontabshi-jian/"/>
    <updated>2016-07-23T20:19:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/07/23/celeryde-crontabshi-jian</id>
    <content type="html"><![CDATA[<p>有时候我们需要处理耗时的操作，同时又要保持较快的响应速度，就需要借助异步队列的帮助。Celery 作为异步队列服务，想必是很多人和我一样的选择。用法在官方文档也详细介绍，不再赘述。</p>

<p>这次想记录的是用 Celery 来实现定时任务。这里也有一点点坑。</p>

<p>以下是 <code>main.py</code> 的内容</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span class="kn">from</span> <span class="nn">celery</span> <span class="kn">import</span> <span class="n">Celery</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">lib</span> <span class="kn">import</span> <span class="n">distribute</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">celery.schedules</span> <span class="kn">import</span> <span class="n">crontab</span>
</span><span class="line">
</span><span class="line"><span class="n">app</span> <span class="o">=</span> <span class="n">distribute</span><span class="o">.</span><span class="n">app</span>
</span><span class="line"><span class="n">app</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
</span><span class="line">    <span class="n">CELERYBEAT_SCHEDULE</span> <span class="o">=</span> <span class="p">{</span>
</span><span class="line">        <span class="s">&#39;every-minute&#39;</span><span class="p">:</span> <span class="p">{</span>
</span><span class="line">            <span class="s">&#39;task&#39;</span><span class="p">:</span> <span class="s">&#39;test_cron&#39;</span><span class="p">,</span>
</span><span class="line">            <span class="s">&#39;schedule&#39;</span><span class="p">:</span> <span class="n">crontab</span><span class="p">(</span><span class="n">minute</span><span class="o">=</span><span class="s">&quot;*&quot;</span><span class="p">),</span>
</span><span class="line">            <span class="s">&#39;args&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">13</span><span class="p">),</span>
</span><span class="line">        <span class="p">}</span>
</span><span class="line">    <span class="p">},</span>
</span><span class="line">    <span class="n">CELERY_INCLUDE</span><span class="o">=</span><span class="p">(</span><span class="s">&quot;apps.tasks&quot;</span><span class="p">,)</span>
</span><span class="line"><span class="p">)</span>
</span><span class="line"><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&#39;__main__&#39;</span><span class="p">:</span>
</span><span class="line">    <span class="n">app</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>实际工作单元,我放在 apps 目录下的 <code>tasks.py</code> 文件中</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span class="kn">from</span> <span class="nn">lib.distribute</span> <span class="kn">import</span> <span class="n">app</span>
</span><span class="line"><span class="nd">@app.task</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">&quot;test_cron&quot;</span><span class="p">)</span>
</span><span class="line"><span class="k">def</span> <span class="nf">mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span class="line">    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>上述是一个简单的 Crontab 应用，它仅需要以下命令就能执行,
其中  <code>--beat</code> 表示 crontab 的应用</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span class="n">python</span> <span class="n">main</span><span class="o">.</span><span class="n">py</span> <span class="n">worker</span> <span class="o">--</span><span class="n">beat</span> <span class="o">-</span><span class="n">l</span> <span class="n">info</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>起初我想把异步队列和定时任务放在一起,就加上了一句 CELERY_QUEUES 的配置</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span class="n">app</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
</span><span class="line">    <span class="o">//</span> <span class="err">添加的部分</span>
</span><span class="line">    <span class="n">CELERY_QUEUES</span><span class="o">=</span><span class="p">(</span>
</span><span class="line">        <span class="n">Queue</span><span class="p">(</span>
</span><span class="line">          <span class="s">&#39;test&#39;</span><span class="p">,</span> <span class="n">Exchange</span><span class="p">(</span><span class="s">&#39;test_exchange&#39;</span><span class="p">),</span>
</span><span class="line">           <span class="n">routing_key</span><span class="o">=</span><span class="s">&#39;test_queue&#39;</span>
</span><span class="line">        <span class="p">),</span>
</span><span class="line">    <span class="p">),</span>
</span><span class="line">    <span class="n">CELERYBEAT_SCHEDULE</span> <span class="o">=</span> <span class="p">{</span>
</span><span class="line">        <span class="s">&#39;every-minute&#39;</span><span class="p">:</span> <span class="p">{</span>
</span><span class="line">            <span class="s">&#39;task&#39;</span><span class="p">:</span> <span class="s">&#39;test_cron&#39;</span><span class="p">,</span>
</span><span class="line">            <span class="s">&#39;schedule&#39;</span><span class="p">:</span> <span class="n">crontab</span><span class="p">(</span><span class="n">minute</span><span class="o">=</span><span class="s">&quot;*&quot;</span><span class="p">),</span>
</span><span class="line">            <span class="s">&#39;args&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">13</span><span class="p">),</span>
</span><span class="line">        <span class="p">}</span>
</span><span class="line">    <span class="p">},</span>
</span><span class="line">    <span class="n">CELERY_INCLUDE</span><span class="o">=</span><span class="p">(</span><span class="s">&quot;apps.tasks&quot;</span><span class="p">,)</span>
</span><span class="line"><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>同样用上述命令开启worker，发现这个时候 Crontab 不能工作了，后来看到官方的文档：</p>

<blockquote>
  <p>celery beat and celery worker as separate services instead. </p>
</blockquote>

<p>也就是说 Celery 的 Beat 需要和其他异步worker 分开，单独执行。</p>

<p>相关代码<a href="https://github.com/zheng-ji/ToyCollection/tree/master/celery_proj">链接</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[环境变量的那些事]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/07/16/bash-jia-zai-shun-xu/"/>
    <updated>2016-07-16T11:35:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/07/16/bash-jia-zai-shun-xu</id>
    <content type="html"><![CDATA[<ul>
  <li><a href="#第一节">四种模式下的环境变量加载</a></li>
  <li><a href="#第二节">跨机器SSH 传递环境变量</a></li>
</ul>

<h3 id="第一节">四种模式下的环境变量加载</h3>

<p>名词解析</p>

<ol>
  <li>login shell: 指用户以非图形化界面 ssh登陆到机器上时获得的第一个 shell。 </li>
  <li>interactive: 交互式，有输入提示符，它的标准输入输出和错误输出都会显示在控制台上。</li>
</ol>

<ul>
  <li>interactive + login shell</li>
</ul>

<p>比如登陆机器后的第一个 shell 就是这种场景。它首先加载 /etc/profile，然后再依次去加载下列三个配置文件之一，一旦找到其中一个便不再接着寻找</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">~/.bash_profile
</span><span class="line">~/.bash_login
</span><span class="line">~/.profile</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>设计如此多的配置是为了兼容 bourne shell 和 C shell，尽量杜绝使用 .bash_login，如果已创建，需要创建 .bash_profile 覆盖</p>

<ul>
  <li>noninteractive + login shell</li>
</ul>

<p>bash -l script.sh 就是这种场景。<code>-l</code> 参数是将shell作为一个login shell启动，配置文件的加载与第一种完全一样。</p>

<ul>
  <li>interactive + non-login shell</li>
</ul>

<p>在一个已有shell中运行bash，此时会打开一个交互式的shell，因为不再需要登陆，所以不是login shell。启动 shell 时会去查找并加载</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">/etc/bash.bashrc
</span><span class="line">~/.bashrc </span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>non-interactive + non-login shell</li>
</ul>

<p>比如执行脚本 bash script.sh 或者 ssh user@remote command。这两种都是创建一个shell，执行完脚本之后便退出，不再需要与用户交互。它会去寻找环境变量BASH_ENV，将变量的值作为文件名进行查找，如果找到便加载它。</p>

<p>从网上看到一个清晰的图</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
</pre></td><td class="code"><pre><code class=""><span class="line">+----------------+--------+-----------+---------------+
</span><span class="line">|                | login  |interactive|non-interactive|
</span><span class="line">|                |        |non-login  |non-login      |
</span><span class="line">+----------------+--------+-----------+---------------+
</span><span class="line">|/etc/profile    |   A    |           |               |
</span><span class="line">+----------------+--------+-----------+---------------+
</span><span class="line">|/etc/bash.bashrc|        |    A      |               |
</span><span class="line">+----------------+--------+-----------+---------------+
</span><span class="line">|~/.bashrc       |        |    B      |               |
</span><span class="line">+----------------+--------+-----------+---------------+
</span><span class="line">|~/.bash_profile |   B1   |           |               |
</span><span class="line">+----------------+--------+-----------+---------------+
</span><span class="line">|~/.bash_login   |   B2   |           |               |
</span><span class="line">+----------------+--------+-----------+---------------+
</span><span class="line">|~/.profile      |   B3   |           |               |
</span><span class="line">+----------------+--------+-----------+---------------+
</span><span class="line">|BASH_ENV        |        |           |       A       |
</span><span class="line">+----------------+--------+-----------+---------------+</span></code></pre></td></tr></table></div></figure></notextile></div>
<hr />

<h3 id="第二节">跨机器传递环境变量</h3>

<p>假设要传递的变量叫做 $VARNAME</p>

<p>客户端机器的 <code>/etc/ssh_config</code> 添加 </p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">SendEnv VARNAME</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>服务端机器的 <code>/etc/sshd_config</code> 添加</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">AcceptEnv VARNAME</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>客户端机器的 $VARNAME 就可以通过 ssh 传递到服务端机器，继续使用.</p>

<hr />

<h3 id="section">参考</h3>

<p><a href="http://feihu.me/blog/2014/env-problem-when-ssh-executing-command-on-remote/">ssh连接远程主机执行脚本的环境变量问题</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[准确监控 MySQL 复制延迟]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/06/03/zhun-que-jian-ce-mysql-fu-zhi-yan-chi/"/>
    <updated>2016-06-03T23:35:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/06/03/zhun-que-jian-ce-mysql-fu-zhi-yan-chi</id>
    <content type="html"><![CDATA[<p>MySQL 建立主从复制后，在 <code>Slave_IO_Running</code>,<code>Slave_SQL_Runing</code> 都是 Yes 的前提下，通过监控 <code>Second_Behind_Master</code> 的数值来判断主从延迟时间，该值为0时是否意味着主从同步是无延迟的呢？</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="n">mysql</span><span class="o">&gt;</span> <span class="k">show</span> <span class="n">slave</span> <span class="n">status</span><span class="err">\</span><span class="k">G</span><span class="p">;</span>
</span><span class="line"><span class="o">***************************</span> <span class="mi">1</span><span class="p">.</span> <span class="k">row</span> <span class="o">***************************</span>
</span><span class="line"><span class="n">Slave_IO_State</span><span class="p">:</span> <span class="n">Waiting</span> <span class="k">for</span> <span class="n">master</span> <span class="k">to</span> <span class="n">send</span> <span class="n">event</span>
</span><span class="line"><span class="p">....</span>
</span><span class="line"><span class="n">Slave_IO_Running</span><span class="p">:</span> <span class="n">Yes</span>
</span><span class="line"><span class="n">Slave_SQL_Running</span><span class="p">:</span> <span class="n">Yes</span>
</span><span class="line"><span class="n">Seconds_Behind_Master</span><span class="p">:</span> <span class="mi">0</span>
</span><span class="line"><span class="p">...</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>很遗憾，我们并不能这样去判断，因为你看到的有可能是假象。</p>

<p>MySQL的同步是异步完成的，其中</p>

<ul>
  <li>IO thread 接收从主库的 binlog，然后在从库生成 relay log</li>
  <li>SQL thead 解析 relay log 后在从库上进行重放</li>
</ul>

<p><code>Second_Behind_Master</code>(以下简称SBM) 是 SQL thread 在执行IO thread 生成的relay log的时间差。relay log中event的时间戳是主库上的时间戳，而SQL thread的时间戳是从库上的，SBM 代表的是从库延后主库的时间差。</p>

<p>主库上执行了一个大的操作，这个操作在主库上没执行完毕的时候，从库的 SBM 会显示为0，而当主库执行完毕传到从库上开始执行的时候,SBM 就会显示很大，在网络状况不好的情况下，更是容易出现 SBM 在零和一个巨大的数值反复飘忽的现象。</p>

<h3 id="pt-heartbeat-">pt-heartbeat 帮我们准确地检测</h3>

<p>pt-heartbeat 是 percona-toolkit 中用来检测主从延迟的工具，需要在主库和从库同时配合才能完成</p>

<ul>
  <li>首先在主库创建监控的表，并定时更新</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="o">//</span><span class="err">创建</span> <span class="n">heartbeat</span> <span class="err">表</span>
</span><span class="line"><span class="n">pt</span><span class="o">-</span><span class="n">heartbeat</span> <span class="c1">--user=root --ask-pass \</span>
</span><span class="line">            <span class="c1">--host=localhost -D &lt;YourDatabase&gt; \</span>
</span><span class="line">            <span class="c1">--create-table --update </span>
</span><span class="line">
</span><span class="line"><span class="o">//</span><span class="err">每隔</span><span class="mi">60</span><span class="n">s</span><span class="p">,</span><span class="err">定时更新状态，以守护进程的方式执行</span>
</span><span class="line"><span class="n">pt</span><span class="o">-</span><span class="n">heartbeat</span> <span class="c1">--user=root --ask-pass \</span>
</span><span class="line">           <span class="c1">--host=localhost -D &lt;YourDatabase&gt;\</span>
</span><span class="line">           <span class="c1">--interval=60 --update --replace --daemonize</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>它会在指定的数据库里生产一张名为 heartbeat 的表，每隔60秒定时更新binlog 文件和位置，以及时间戳。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="o">+</span><span class="c1">----------------------------+-----------+------------------+-----------+-----------------------+---------------------+</span>
</span><span class="line"><span class="o">|</span> <span class="n">ts</span>                         <span class="o">|</span> <span class="n">server_id</span> <span class="o">|</span> <span class="n">file</span>             <span class="o">|</span> <span class="k">position</span>  <span class="o">|</span> <span class="n">relay_master_log_file</span> <span class="o">|</span> <span class="n">exec_master_log_pos</span> <span class="o">|</span>
</span><span class="line"><span class="o">+</span><span class="c1">----------------------------+-----------+------------------+-----------+-----------------------+---------------------+</span>
</span><span class="line"><span class="o">|</span> <span class="mi">2016</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">03</span><span class="n">T22</span><span class="p">:</span><span class="mi">26</span><span class="p">:</span><span class="mi">29</span><span class="p">.</span><span class="mi">000720</span> <span class="o">|</span>         <span class="mi">6</span> <span class="o">|</span> <span class="n">mysql</span><span class="o">-</span><span class="n">bin</span><span class="p">.</span><span class="mi">004</span><span class="o">|</span> <span class="mi">716</span><span class="o">|</span> <span class="n">mysql</span><span class="o">-</span><span class="n">bin</span><span class="p">.</span><span class="mi">002</span><span class="o">|</span>           <span class="mi">291330290</span> <span class="o">|</span>
</span><span class="line"><span class="o">+</span><span class="c1">----------------------------+-----------+------------------+-----------+-----------------------+---------------------+</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>接着在从库以守护进程执行定期检测,并将结果重定向到文本</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="n">pt</span><span class="o">-</span><span class="n">heartbeat</span> <span class="c1">--user=root --ask-pass \</span>
</span><span class="line">     <span class="c1">--host=localhost -D &lt;YourDatabase&gt; --interval=60 \</span>
</span><span class="line">     <span class="c1">--file=/tmp/output.txt --monitor --daemonize</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>文本的内容只有一行，每隔指定的时间就会被覆盖</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="mi">29</span><span class="p">.</span><span class="mi">00</span><span class="n">s</span> <span class="p">[</span> <span class="mi">30</span><span class="p">.</span><span class="mi">20</span><span class="n">s</span><span class="p">,</span>  <span class="mi">6</span><span class="p">.</span><span class="mi">04</span><span class="n">s</span><span class="p">,</span>  <span class="mi">2</span><span class="p">.</span><span class="mi">01</span><span class="n">s</span> <span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>29s 表示的是瞬间的延迟时间，30.20s 表示1分钟的延迟时间，6.04秒表示5分钟的延迟时间，2.01秒表示以及15分钟的延迟时间，在主从机器时间校准的前提下，这个数据才是客观准确的主从延迟。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ansible Dynamic Inventory]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/04/24/ansible-dynamic-inventory/"/>
    <updated>2016-04-24T20:53:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/04/24/ansible-dynamic-inventory</id>
    <content type="html"><![CDATA[<p>Ansible 在使用的过程中，如果机器数量比较固定，且变更不多的情况下，可在 /etc/ansible/hosts 文件里面配置固定的组合机器IP， 并给他起组的别名，执行 Ansible 脚本便可以通过别名找到相应的机器。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">[webservers]
</span><span class="line">111.222.333.444 ansible_ssh_port=888</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>假如你有很多台机器，且机器经常变更导致IP时常变换，你还想把IP逐个写入 /etc/ansible/hosts 就不现实了。你也许会问，若不把 IP 写进 /etc/ansible/hosts，那不是没法用 Ansible 指挥这些机器？
感谢 Ansible Dynamic Inventory， 如果我们能通过编程等手段获取变更机器的IP，我们还是有办法实现的。</p>

<h3 id="dynamic-inventory-">Dynamic Inventory 的原理</h3>

<ul>
  <li>通过编程的方式,也就是动态获取机器的 json 信息;</li>
  <li>Ansible 通过解析这串 json 字符串;</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">ansible -i yourprogram.py -m raw  -a 'cd /home'</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Ansible Dynamic Inventory 对程序返回的 json 的转义是这样的：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">{"devtest-asg": {"hosts": ["172.31.21.164"], "vars": {"ansible_ssh_port": 12306}}}</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>翻译一下就是  /etc/ansible/hosts 中的:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">[devtest-asg]
</span><span class="line">172.31.21.164 ansible_ssh_port=12306</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="section">一个实战的例子</h3>

<p>官方文档对 Inventory 仅作概念性描述，阅读完后仍是一头雾水，不知如何下手。 让我们用一个例子来豁然开朗吧。 我们使用 AWS 的 AutoScaling Group，以下简称 ASG，ASG 会在某种自定义的条件下会自动开启和关闭机器，这给我们在辨别IP，定位机器的时候造成困扰。因此我们需要 Ansible Dynamic Inventory</p>

<p>我们使用 AWS 的 boto 库来获取 ASG 的实例信息.以下程序(get_host.py)中要实现的方法就是列出返回机器信息的 json 串。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
<span class="line-number">39</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="c">#!/usr/bin/env python</span>
</span><span class="line"><span class="c"># -*- coding: utf-8 -*-</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">json</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">boto</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">boto.ec2</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">boto.ec2.autoscale</span>
</span><span class="line">
</span><span class="line"><span class="n">AWS_REGION</span> <span class="o">=</span> <span class="s">&#39;BBB&#39;</span>
</span><span class="line"><span class="n">AWS_ACCESS_KEY</span> <span class="o">=</span> <span class="s">&#39;xxxx&#39;</span>
</span><span class="line"><span class="n">AWS_SECRET_KEY</span> <span class="o">=</span> <span class="s">&#39;yyy&#39;</span>
</span><span class="line">
</span><span class="line"><span class="n">result</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class="line"><span class="k">def</span> <span class="nf">getData</span><span class="p">():</span>
</span><span class="line">    <span class="n">conn_as</span> <span class="o">=</span> <span class="n">boto</span><span class="o">.</span><span class="n">ec2</span><span class="o">.</span><span class="n">autoscale</span><span class="o">.</span><span class="n">connect_to_region</span><span class="p">(</span>
</span><span class="line">            <span class="s">&#39;cn-north-1&#39;</span><span class="p">,</span>
</span><span class="line">            <span class="n">aws_access_key_id</span><span class="o">=</span><span class="n">AWS_ACCESS_KEY</span><span class="p">,</span>
</span><span class="line">            <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="n">AWS_SECRET_KEY</span><span class="p">)</span>
</span><span class="line">    <span class="n">group</span> <span class="o">=</span> <span class="n">conn_as</span><span class="o">.</span><span class="n">get_all_groups</span><span class="p">(</span><span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;devtest-asg&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
</span><span class="line">    <span class="n">conn_ec2</span> <span class="o">=</span> <span class="n">boto</span><span class="o">.</span><span class="n">ec2</span><span class="o">.</span><span class="n">connect_to_region</span><span class="p">(</span>
</span><span class="line">            <span class="n">AWS_REGION</span><span class="p">,</span>
</span><span class="line">            <span class="n">aws_access_key_id</span><span class="o">=</span><span class="n">AWS_ACCESS_KEY</span><span class="p">,</span>
</span><span class="line">            <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="n">AWS_SECRET_KEY</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="n">instance_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">instance_id</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">group</span><span class="o">.</span><span class="n">instances</span><span class="p">]</span>
</span><span class="line">    <span class="n">reservations</span> <span class="o">=</span> <span class="n">conn_ec2</span><span class="o">.</span><span class="n">get_all_instances</span><span class="p">(</span><span class="n">instance_ids</span><span class="p">)</span>
</span><span class="line">    <span class="n">instances</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">reservations</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">r</span><span class="o">.</span><span class="n">instances</span><span class="p">]</span>
</span><span class="line">
</span><span class="line">    <span class="n">result</span><span class="p">[</span><span class="s">&#39;devtest-asg&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class="line">    <span class="n">result</span><span class="p">[</span><span class="s">&#39;devtest-asg&#39;</span><span class="p">][</span><span class="s">&#39;hosts&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class="line">    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">reservations</span><span class="p">:</span>
</span><span class="line">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">r</span><span class="o">.</span><span class="n">instances</span><span class="p">:</span>
</span><span class="line">            <span class="n">result</span><span class="p">[</span><span class="s">&#39;devtest-asg&#39;</span><span class="p">][</span><span class="s">&#39;hosts&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s">&#39;</span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="o">.</span><span class="n">private_ip_address</span><span class="p">)</span>
</span><span class="line">            <span class="n">result</span><span class="p">[</span><span class="s">&#39;devtest-asg&#39;</span><span class="p">][</span><span class="s">&#39;vars&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;ansible_ssh_port&#39;</span><span class="p">:</span> <span class="mi">36000</span><span class="p">}</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">getlists</span><span class="p">():</span>
</span><span class="line">    <span class="n">getData</span><span class="p">()</span>
</span><span class="line">    <span class="k">print</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">getlists</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>执行以下命令就可以愉快地使用 Ansible 了，其中 devtest-asg 是 ASG 的别名：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">ansible</span> <span class="o">-</span><span class="n">i</span> <span class="n">get_host</span><span class="o">.</span><span class="n">py</span>  <span class="n">devtest</span><span class="o">-</span><span class="n">asg</span> <span class="o">-</span><span class="n">m</span> <span class="n">raw</span> <span class="o">-</span><span class="n">a</span> <span class="s">&#39;ls /&#39;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Flume 实时收集 Nginx 日志]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/04/23/flume-shi-shi-shou-ji-nginx-ri-zhi/"/>
    <updated>2016-04-23T09:13:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/04/23/flume-shi-shi-shou-ji-nginx-ri-zhi</id>
    <content type="html"><![CDATA[<p>在分布式系统中，各个机器都有程序运行的本地日志，有时为了分析需求，不得不这些分散的日志汇总需求，相信很多人会选择 Rsync，Scp 之类，
但它们的实时性不强，而且也会带来名字冲突的问题。扩展性差强人意，一点也不优雅。</p>

<p>现实中，我们就碰到了这样的需求：实时汇总线上多台服务器的 Nginx 日志。Flume 立功了。</p>

<h1 id="flume-">Flume 简介</h1>

<p><a href="https://flume.apache.org/"><strong>F</strong>lume</a> 是一个分布式，可靠高效的日志收集系统，它允许用户自定义数据传输模型，因此可扩展性也强。也有较强的容错和恢复机制.
以下是几个重要的概念</p>

<ul>
  <li>Event：Event 是 Flume 数据传输的基本单元。flume 以事件的形式将数据从源头传送到最终的目的。</li>
  <li>Agent：Agent包含 Sources, Channels, Sinks 和其他组件，它利用这些组件将events从一个节点传输到另一个节点或最终目的。</li>
  <li>Source：Source负责接收events，并将events批量的放到一个或多个Channels。</li>
  <li>Channel：Channel位于 Source 和 Sink 之间，用于缓存进来的events，当Sink成功的将events发送到下一跳的channel或最终目的，events从Channel移除。</li>
  <li>Sink：Sink 负责将 events 传输到下一跳或最终目的，成功完成后将events从channel移除。</li>
</ul>

<p><img src="http://zheng-ji.github.com/images/2016/04/flume.jpg" /></p>

<ul>
  <li>Source 就有 Syslog Source, Kafka Source,HTTP Source, Exec Source Avro Source 等。</li>
  <li>Sink 有 Kafka Sink, Avro Sink, File Roll Sink, HDFS Sink 等。</li>
  <li>Channel 有 Memory Channel,File Channel 等</li>
</ul>

<p>它提供了一个骨架，以及多种 Source, Sink, Channel, 让你设计合适的数据模型。事实上也可以多个 Flume 联动完成，就像地铁的车厢一样。</p>

<h1 id="section">定义数据流模型</h1>

<p>回到我们开头的场景,我们要将多台服务器的 Nginx 日志进行汇总分析，</p>

<p>分成两个 flume 来实现</p>

<ul>
  <li>Flume1 数据流是 Exec Source -&gt; Memory Channel -&gt; Avro Sink,部署在业务机器上</li>
  <li>Flume2 数据流是 Avro Source -&gt; Memory Channel -&gt; FileRoll Sink</li>
</ul>

<p><img src="http://zheng-ji.github.com/images/2016/04/flume1toflume2.jpg" /></p>

<h1 id="section-1">需要的准备</h1>

<p>你需要安装</p>

<ul>
  <li>下载 <a href="https://flume.apache.org/download.html">Flume</a></li>
  <li>安装 JavaSDk,并在下载解压之后的 conf/flume-env.sh，配置</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c"># 我用的是oracle-java-8</span>
</span><span class="line"><span class="nb">export </span><span class="nv">JAVA_HOME</span><span class="o">=</span>/usr/lib/jvm/java-8-oracle/jre/
</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>思考你的数据流动模型，编写配置，如上文所说的Flume1, tail2avro.conf  ：</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">agent.sources <span class="o">=</span> s1
</span><span class="line">agent.channels <span class="o">=</span> c1
</span><span class="line">agent.sinks <span class="o">=</span> k1
</span><span class="line">
</span><span class="line">agent.sources.s1.type<span class="o">=</span><span class="nb">exec</span>
</span><span class="line">agent.sources.s1.command<span class="o">=</span>tail -F &lt;Your File Path&gt;
</span><span class="line">agent.sources.s1.channels<span class="o">=</span>c1
</span><span class="line">
</span><span class="line">agent.channels.c1.type<span class="o">=</span>memory
</span><span class="line">agent.channels.c1.capacity<span class="o">=</span>10000
</span><span class="line">agent.channels.c1.transactionCapacity<span class="o">=</span>10000
</span><span class="line">
</span><span class="line">agent.sinks.k1.type <span class="o">=</span> avro
</span><span class="line">agent.sinks.k1.hostname <span class="o">=</span> &lt;Your Target Address&gt;
</span><span class="line">agent.sinks.k1.port <span class="o">=</span> &lt;Your Target Port&gt;
</span><span class="line">agent.sinks.k1.channel<span class="o">=</span>c1
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Flume2 中的 avro2file.conf </p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">agent.sources <span class="o">=</span> s1
</span><span class="line">agent.channels <span class="o">=</span> c1
</span><span class="line">agent.sinks <span class="o">=</span> k1
</span><span class="line">
</span><span class="line">agent.sources.s1.type <span class="o">=</span> avro
</span><span class="line">agent.sources.s1.bind <span class="o">=</span> &lt;Your Address&gt;
</span><span class="line">agent.sources.s1.port <span class="o">=</span> &lt;Your Port&gt;
</span><span class="line">agent.sources.s1.channels <span class="o">=</span> c1
</span><span class="line">
</span><span class="line">agent.sinks.k1.type <span class="o">=</span> file_roll
</span><span class="line">agent.sinks.k1.sink.directory <span class="o">=</span> /data/log/ngxlog
</span><span class="line"><span class="c"># 滚动间隔</span>
</span><span class="line">agent.sinks.k1.sink.rollInterval <span class="o">=</span> 86400
</span><span class="line">agent.sinks.k1.channel <span class="o">=</span> c1
</span><span class="line">
</span><span class="line">agent.channels.c1.type <span class="o">=</span> memory
</span><span class="line"><span class="c"># 队列里 Event 的容量</span>
</span><span class="line">agent.channels.c1.capacity <span class="o">=</span> 10000
</span><span class="line">agent.channels.c1.transactionCapacity <span class="o">=</span> 10000
</span><span class="line">agent.channels.c1.keep-alive <span class="o">=</span> 60
</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>启动运行</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c"># 启动flume1</span>
</span><span class="line">bin/flume-ng agent -n agent -c conf -f conf/tail2avro.conf <span class="se">\</span>
</span><span class="line">-Dflume.root.logger<span class="o">=</span>WARN
</span><span class="line">
</span><span class="line"><span class="c"># 启动flume2</span>
</span><span class="line">in/flume-ng agent -n agent -c conf -f conf/avro2file.conf <span class="se">\</span>
</span><span class="line">-Dflume.root.logger<span class="o">=</span>INFO
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="section-2">参考</h2>

<ul>
  <li><a href="https://flume.apache.org/FlumeUserGuide.html">FlumeUserGuide</a> 官方的 FlumeUserGuide</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 该选择哪种持久化配置]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/03/10/gai-xuan-ze-na-chong-redischi-jiu-hua-pei-zhi/"/>
    <updated>2016-03-10T23:32:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/03/10/gai-xuan-ze-na-chong-redischi-jiu-hua-pei-zhi</id>
    <content type="html"><![CDATA[<p>这个标题或许会让你想起<a href="https://movie.douban.com/subject/1291843/">《黑客帝国》</a>里经典的台词，你要选择蓝色药丸，还是红色药丸？</p>

<p>Redis 是我们重度使用的一个开源软件，对它的持久化配置做一番相对深入的总结，是值得的。目前它有两种主流的持久化存储方式 SnapShot 以及 AOF 。</p>

<ul>
  <li><a href="#第一节">什么是 Snapshot</a></li>
  <li><a href="#第二节">什么是 AOF </a></li>
  <li><a href="#第三节">选择哪种药丸</a></li>
</ul>

<h3 id="第一节">什么是 Snapshot</h3>

<p>Snapshot 将内存中数据以结构化的方式序列化到 rdb 文件中，是默认的持久化方式，便于解析引擎快速解析和内存实施。快照得由间隔时间，变更次数同时符合才会触发， 该过程中并不阻塞客户端请求，copy-on-write 方式也意味着极端情况下可能会导致实际数据2倍内存的使用量。它首先将数据写入临时文件，结束后，将临时文件重名为 dump.rdb。可以使用 <code>redis-check-dump</code> 用来检测完整性</p>

<p>只有快照结束后才会将旧的文件替换成新的，因此任何时候 RDB 文件都是完整的。如果在触发 snapshot 之前，server 失效。会导致上一个时间点之后的数据未能序列化到 rdb 文件，安全性上稍弱。 </p>

<p>我们可手动执行 save 或 bgsave 命令让 redis 执行快照。两个命令的区别在于:</p>

<ul>
  <li>save 是由主进程进行快照操作，会阻塞其它请求;</li>
  <li>bgsave 会通过 fork 子进程进行快照操作;</li>
</ul>

<p>RDB 文件默认是经过压缩的二进制文件，占用的空间会小于内存中的数据，更加利于传输。设置如下，可以关闭快照功能</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">save ""</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="section">相关配置</h4>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class=""><span class="line"># snapshot触发的时机，save &lt;seconds&gt; &lt;changes&gt;， 比如600秒有2个操作
</span><span class="line">save 600 2
</span><span class="line"># 当snapshot 时出现错误无法继续时，是否阻塞客户端变更操作 
</span><span class="line">stop-writes-on-bgsave-error yes 
</span><span class="line"># 是否启用rdb文件压缩，默认为 yes cpu消耗，快速传输  
</span><span class="line">rdbcompression yes  
</span><span class="line"># rdb文件名称  
</span><span class="line">dbfilename dump.rdb  </span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第二节">什么是 AOF</h3>

<p>Append-only file，将 <code>操作 + 数据</code> 以格式化指令的方式追加到操作日志文件的尾部，在 append 操作返回后， 已经写入到文件或者即将写入，才进行实际的数据变更，日志文件保存了历史的操作过程；当 server 需要数据恢复时，可以直接回放此日志文件，即可还原所有的操作过程。 如果你期望数据更少的丢失，那么可以采用 AOF 模式。可以用 redis-check-aof 检测文件是否完整。</p>

<p>AOF 就是日志会记录变更操(例如：set/del等)，会导致AOF文件非常的庞大，意味着server失效后，数据恢复的过程将会很长；事实上，一条数据经过多次变更，将会产生多条AOF记录，其实只要保存当前的状态，历史的操作记录是可以抛弃的， 由此催生了 AOF ReWrite。</p>

<h4 id="aof-rewrite">什么是 AOF Rewrite</h4>

<p>其实是压缩 AOF 文件的过程，Redis 采取了类似 Snapshot 的方式：基于 <code>copy-on-write</code>，全量遍历内存中数据，然后逐个序列到 aof 文件中。因此 AOF Rewrite 能够正确反应当前内存数据的状态， Rewrite 过程中，新的变更操作将仍然被写入到原 AOF 文件中，同时这些新的变更操作也会被收集起来， 并不阻塞客户端请求。</p>

<h4 id="section-1">相关配置</h4>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
</pre></td><td class="code"><pre><code class=""><span class="line">##只有在yes下，aof重写/文件同步等特性才会生效  
</span><span class="line">appendonly no  
</span><span class="line">  
</span><span class="line">##指定aof文件名称  
</span><span class="line">appendfilename appendonly.aof  
</span><span class="line">  
</span><span class="line">##指定aof操作中文件同步策略，有三个合法值：always everysec no，默认为everysec  
</span><span class="line">appendfsync everysec  
</span><span class="line">
</span><span class="line">##在aof-rewrite期间，appendfsync 是否暂缓文件同步，no 表示不暂缓，yes 表示暂缓，默认为no  
</span><span class="line">no-appendfsync-on-rewrite no  
</span><span class="line">  
</span><span class="line">##aof文件rewrite触发的最小文件尺寸 只有大于此aof文件大于此尺寸是才会触发rewrite，默认64mb，建议512mb  
</span><span class="line">auto-aof-rewrite-min-size 64mb  
</span><span class="line">  
</span><span class="line">##相对于上一次rewrite，本次rewrite触发时aof文件应该增长的百分比
</span><span class="line">auto-aof-rewrite-percentage 100  </span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="appendfsync-">appendfsync 方式：</h4>

<ul>
  <li>always：每一条 aof 记录都立即同步到文件，这是最安全的方式，但是更多的磁盘操作和阻塞延迟，IO 开支较大。</li>
  <li>everysec：每秒同步一次，性能和安全也是redis推荐的方式。如果服务器故障，有可能导致最近一秒内aof记录丢失。</li>
  <li>no：redis并不直接调用文件同步，而是交给操作系统来处理，操作系统可以根据buffer填充情况等择机触发同步；性能较好，在物理服务器故障时，数据丢失量会因OS配置有关。</li>
</ul>

<h3 id="第三节">选择哪种药丸</h3>

<ul>
  <li>AOF更安全，可将数据及时同步到文件中，但需要较多的磁盘IO，AOF文件尺寸较大，文件内容恢复相对较慢， 也更完整。</li>
  <li>Snapshot，安全性较差，它是正常时期数据备份及 master-slave 数据同步的最佳手段，文件尺寸较小，恢复数度较快。</li>
</ul>

<h4 id="section-2">主从架构的环境下的选择</h4>

<ul>
  <li>通常 master 使用AOF，slave 使用 Snapshot，master 需要确保数据完整性，slave 提供只读服务.</li>
  <li>如果你的网络稳定性差， 物理环境糟糕情况下，那么 master， slave均采取 AOF，这个在 master， slave角色切换时，可以减少时间成本；</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ 实时监控 nginx qps 的拓展]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/01/07/shi-shi-jian-kong-nginx-qps-de-tuo-zhan/"/>
    <updated>2016-01-07T12:59:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/01/07/shi-shi-jian-kong-nginx-qps-de-tuo-zhan</id>
    <content type="html"><![CDATA[<p>用下班时间写了一个 ngx lua 的拓展, <a href="https://github.com/zheng-ji/ngx_lua_reqstatus">GitHub</a>。可以:</p>

<ul>
  <li>[x] 实时监控域名的 qps</li>
  <li>[x] 实时监控域名的 5xx 个数</li>
  <li>[x] 实时监控域名的 响应时长</li>
  <li>[x] 并附带 Ganglia 监控插件</li>
</ul>

<h2 id="section">使用</h2>

<ul>
  <li>配置 <code>nginx.conf</code></li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
</pre></td><td class="code"><pre><code class=""><span class="line">http {
</span><span class="line">    ...
</span><span class="line">    ...
</span><span class="line">
</span><span class="line">    lua_shared_dict statics_dict    1M; # 初始化变量
</span><span class="line">    lua_package_path "/etc/nginx/ngx_lua_reqstatus/?.lua";  #路径
</span><span class="line">    log_by_lua_file "/etc/nginx/ngx_lua_reqstatus/hook.lua"; # 添加此句
</span><span class="line">
</span><span class="line">    server {
</span><span class="line">        listen 80;
</span><span class="line">        server_name  justforfun.com; 
</span><span class="line">
</span><span class="line">        location /{
</span><span class="line">            ...
</span><span class="line">        }
</span><span class="line">    }
</span><span class="line">    # 监控服务
</span><span class="line">    server {
</span><span class="line">        listen 127.0.0.1:6080;
</span><span class="line">        location /{
</span><span class="line">            access_by_lua_file "/etc/nginx/ngx_lua_reqstatus/status.lua";
</span><span class="line">        }
</span><span class="line">    }
</span><span class="line">}</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>效果</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">curl localhost:6080/?domain=justforfun.com</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>输出</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class=""><span class="line">Server Name:    justforfun.com
</span><span class="line">Seconds SinceLast:   1.4399998188019 secs
</span><span class="line">Request Count:      1
</span><span class="line">Average Req Time:   0 secs
</span><span class="line">Requests Per Secs:  0.69444453182781
</span><span class="line">5xx num:    0</span></code></pre></td></tr></table></div></figure></notextile></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx 日志利器 GoAccess]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/12/10/fen-xi-nginxri-zhi-de-li-qi-goaccess/"/>
    <updated>2015-12-10T23:28:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/12/10/fen-xi-nginxri-zhi-de-li-qi-goaccess</id>
    <content type="html"><![CDATA[<p>我们经常需要从 Nginx 日志分析得出很多有价值的东西，分析的方法是各种 shell, awk, python, 现在 <a href="https://github.com/allinurl/goaccess">GoAccess</a> 给你另外一种选择, 值得拥有。</p>

<ul>
  <li>安装
用以下的方式安装，才能得到新版的 GoAccess, 功能更健全</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class=""><span class="line">$ echo "deb http://deb.goaccess.io $(lsb_release -cs) main"|sudo tee -a /etc/apt/sources.list
</span><span class="line">$ wget -O - http://deb.goaccess.io/gnugpg.key | sudo apt-key add -
</span><span class="line">$ sudo apt-get update
</span><span class="line">$ sudo apt-get install goaccess</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>推荐配置</li>
</ul>

<p>安装完成之后，会生成一份 <code>/etc/goaccess.conf</code> 稍作编辑，这就是默认的配置，免去了后续每次都要定义格式</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">time-format %T   # 只有这种方式才能解决 0.0us 的显示问题
</span><span class="line">date-format %d/%b/%Y
</span><span class="line">log-format %h %^[%d:%t %^] "%r" %s %b "%R" "%u" %T</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>使用</li>
</ul>

<p>输出报表，报表中，我们可以看到最常访问的 IP, 接口，以及每个接口使用带宽，平均响应时长，状态码等，对业务分析有较好的便利性</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class=""><span class="line">终端显示
</span><span class="line">goaccess -f access.log 
</span><span class="line"> 
</span><span class="line">输出报表，报表中，我们可以看到top ip, 接口，以及接口使用带宽，平均响应时长，状态码等
</span><span class="line">goaccess -f access.log &gt; report.html
</span><span class="line"> 
</span><span class="line">具体某段时间的输出
</span><span class="line">sed -n '/5\/Dec\/2015/,/10\/Dec\/2010/ p' access.log | goaccess -a
</span><span class="line"> 
</span><span class="line">处理已经压缩的日志
</span><span class="line">zcat access.log.*.gz | goaccess</span></code></pre></td></tr></table></div></figure></notextile></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gre 隧道与 Keepalived]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/12/05/gre-tuning-and-keepalived/"/>
    <updated>2015-12-05T10:29:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/12/05/gre-tuning-and-keepalived</id>
    <content type="html"><![CDATA[<p>这一篇文章是做了不少功课的。</p>

<ul>
  <li><a href="#第一节">什么是 Gre 隧道</a></li>
  <li><a href="#第二节">什么是 Vrrp </a></li>
  <li><a href="#第三节">KeepAlived 是什么</a></li>
  <li><a href="#第四节">用Keepalived 怎么玩</a></li>
  <li><a href="#第五节">附录</a></li>
</ul>

<h3 id="第一节">什么是 Gre 隧道 </h3>

<p>GRE 隧道是一种 IP-2-IP 的隧道，是通用路由封装协议，可以对某些网路层协议的数据报进行封装，使这些被封装的数据报能够在 IPv4/IPv6 网络中传输。Tunnel 是一个虚拟的点对点的连接，提供了一条通路使封装的数据报文能够在这个通路上传输，并且在一个Tunnel 的两端分别对数据报进行封装及解封装。Linux 上创建 GRE 隧道，需要 ip_gre 内核模块，它是Pv4 隧道的驱动程序。</p>

<p>假设我有2台服务器，想做这两台之间创建 GRE 隧道</p>

<ul>
  <li>$server_A_ip 表示服务器A的IP</li>
  <li>$server_B_ip 服务器B 的内网IP</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class=""><span class="line"># 在 A 机器上执行
</span><span class="line"># 创建 GRE 协议的 虚拟网络设备, 指定本地和对端 IP
</span><span class="line">sudo ip link add gretap1 type gretap local $server_a_ip remote $server_b_ip 
</span><span class="line">sudo ip link set dev gretap1 up  # 启动该设备
</span><span class="line">sudo ip addr add dev gretap1 10.1.1.2/24 # 给该设备一个虚拟网络地址
</span><span class="line">
</span><span class="line"># 在 B 机器上执行
</span><span class="line"># 创建 GRE 协议的 虚拟网络设备, 指定本地和对端 IP
</span><span class="line">sudo ip link add gretap1 type gretap local $server_b_ip remote $server_a_ip 
</span><span class="line">sudo ip link set dev gretap1 up  # 启动该设备
</span><span class="line">sudo ip addr add dev gretap1 10.1.1.3/24 # 给该设备一个虚拟网络地址</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>如果想停止或者删除上述网卡</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">ip link set gretap1 down
</span><span class="line">ip tunnel del gretap1</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>至此点到点得隧道建立。</p>

<h3 id="第二节">什么是 vrrp 协议 </h3>

<p>VRRP(Virtual Router Redundancy Protocol), 即虚拟路由冗余协议。是实现路由器高可用的容错协议。</p>

<p>即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个 master 和多个 backup， 但在外界看来就像一台一样，构成虚拟路由器，拥有一个虚拟IP（vip），占有这个IP 的 master 实际负责 ARP 相应和转发 IP 数据包， 组中的其它路由器作为备份的角色处于待命状态。 master 会发组播消息，当 backup 在超时时间内收不到 vrrp 包时就认为 master 宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master，保证路由器的高可用。</p>

<h3 id="第三节"> Keepalived 是什么 </h3>

<p>Keepalived 是一个基于 VRRP 协议来实现的服务高可用方案，可以利用其来避免IP单点故障。</p>

<ul>
  <li>一个经典的案例</li>
</ul>

<p>一个WEB服务至少会有2台服务器运行 Keepalived，一台为主服务器，一台为备份服务器, 但是对外表现为一个虚拟IP，主服务器会发送特定的消息给备份服务器，当备份服务器收不到这个消息的时候，即主服务器宕机的时候，备份服务器就会接管虚拟IP，继续提供服务，从而保证了高可用性。</p>

<h3 id="第四节">怎么玩 Keepalived</h3>

<ul>
  <li>安装</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo apt-get install keepalived</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>之前提到的，我们在 A, B 两台服务器建立起了 GRE 隧道了。 现在我们有一个虚拟的内网IP， 姑且叫做 $virtual_third_ip
接着在 A 服务器上</p>

<ul>
  <li>配置</li>
</ul>

<p>编辑服务器 A, B 的 <code>/etc/keepalived/keepalived.conf</code></p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
</pre></td><td class="code"><pre><code class=""><span class="line">
</span><span class="line">global_defs {
</span><span class="line">    router_id LVS_DEVEL
</span><span class="line">}
</span><span class="line">
</span><span class="line">vrrp_instance VI_1 {
</span><span class="line">    state MASTER
</span><span class="line">    interface gretap1 # 绑在建立起来的隧道上
</span><span class="line">    virtual_router_id 51
</span><span class="line">    # 优先级别,越高的设备会被弄成主设备, A,B 服务器要有所差别，其他都一样
</span><span class="line">    priority 100          advert_int 1      # 广播时间间隔
</span><span class="line">    authentication {  #  验证相关
</span><span class="line">        auth_type PASS
</span><span class="line">        auth_pass 1111
</span><span class="line">    }
</span><span class="line">    virtual_ipaddress {
</span><span class="line">        $virtual_third_ip dev eth0
</span><span class="line">    }
</span><span class="line">}</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>我们将服务器  A 作为 Master, 服务器 B 当做 Backup, 当服务器 A 需要停机的时候，$virtual_third_ip 就会漂移到服务器 B 上面。 我们两台机器都有相同配置的 Nginx 服务，就可以保障机器出现故障的时候，Nginx 服务丝毫不受影响。</p>

<h3 id="第五节"> 附录 </h3>

<ul>
  <li><a href="http://linux.vbird.org/linux_server/0140networkcommand.php">鸟哥的网络知识</a></li>
  <li><a href="http://www.tldp.org/HOWTO/Adv-Routing-HOWTO/lartc.tunnel.gre.html">GRE tuneling</a></li>
  <li><a href="http://baike.baidu.com/link?url=N1-VGuzQC0PJ2bCnOzYn-XRTlN8eFGCvIJQlTI6KDL5Fx3EQxoRGTrxazb11jfZQqlfeA6q2Ka0VKRVEc0Kdu3GEyhqe1W_Ae2h0Tqu5NacIjOSaSnUVeOe-9QV5dB8q0Wv_uq8-vqdnQICt39UZFK">VRRP</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[给 Tengine 加上 lua 拓展]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/10/29/gei-tengine-jia-shang-lua-tuo-zhan/"/>
    <updated>2015-10-29T22:45:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/10/29/gei-tengine-jia-shang-lua-tuo-zhan</id>
    <content type="html"><![CDATA[<p>Tengine 能动态加载第三方模块，成为我们青睐的选择，我们可以编译动态链接文件，而不需要重新安装 Nginx, 这对在线增强 webservice 很有帮助. 
感谢 agentzh, <a href="https://github.com/openresty/lua-nginx-module">lua-nginx-module</a>, 可以让我们使用 lua 增强nginx的功能, 不言而喻，我们必须现有 Lua 的环境，才能运行 ngx_lua;</p>

<h2 id="nginxlua">编译 nginx_lua</h2>

<p>官方推荐使用LuaJit,虽然也可以使用Lua，但是即时编译(Just-In-Time Compiler)混合了动态编译和静态编译，一句一句编译源代码，但是会将翻译过的代码缓存起来以降低性能损耗。</p>

<ul>
  <li>下载安装</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class=""><span class="line">wget http://luajit.org/download/LuaJIT-2.0.4.tar.gz
</span><span class="line">tar zxvf LuaJIT-2.0.4.tar.gz
</span><span class="line">cd LuaJIT-2.0.4
</span><span class="line">make
</span><span class="line">make install</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>设置环境变量</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">export LUAJIT_LIB=/usr/local/lib
</span><span class="line">export LUAJIT_INC=/usr/local/include/luajit-2.0</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>然后编译ngx-lua-module.so</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">/usr/local/share/dso_tool/ --path=/Path/To/Lua-Nginx-module</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>设置动态库</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">&gt; echo "/usr/local/lib" &gt; /etc/ld.so.conf.d/usr_local_lib.conf
</span><span class="line">&gt; ldconfig</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="tengine-">在 Tengine 中启用</h3>

<p><code>nginx.conf</code> 中先加载动态库</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">dso {
</span><span class="line">    load ngx_load_module;
</span><span class="line">}</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>在 nginx.conf 中添加</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">lua_code_cache on/off;</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>来开启是否将代码缓存，所以每次变更 “*.lua” 文件时，必须重启 nginx 才可生效.</p>

<h3 id="ngxluawaf">使用 ngx_lua_waf</h3>

<p>有了基础环境，我们要开始发挥 ngx lua 的优点了, 我用他安装了 waf (web application firework)
<a href="https://github.com/loveshell/ngx_lua_waf">ngx_lua_waf</a>，这是一个通过 ngx_lua 编写的 web 应用防火墙, 在使用过程中也发现了 ngx_lua_waf 一个bug，给他提了一个<a href="https://github.com/loveshell/ngx_lua_waf/pull/70">Pull Request</a>, 码农生涯第一个 PR.</p>

<hr />

<p>注：
静态编译的程序在执行前全部被翻译为机器码，而动态直译执行的则是一句一句边运行边翻译。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[记录使用 Flask 的点滴]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/10/06/ji-lu-shi-yong-flaskde-dian-di/"/>
    <updated>2015-10-06T13:21:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/10/06/ji-lu-shi-yong-flaskde-dian-di</id>
    <content type="html"><![CDATA[<p>喜欢 Flask 经典的 RestFul 设计风格，以及它与 Gevent 的优雅结合，可以帮助我们轻松构建异步非阻塞应用，烂笔头记下一些较好的实践。</p>

<ul>
  <li><a href="#第一节">消息反馈</a></li>
  <li><a href="#第二节">Flask 上下文</a></li>
  <li><a href="#第三节">注册 JinJia 模板过滤器</a></li>
  <li><a href="#第四节">itsdangerous 生成过期时间 Json 签名</a></li>
  <li><a href="#第五节">一种较好的项目组织方式</a></li>
  <li><a href="#第六节">BluePrint 的好</a></li>
  <li><a href="#第七节">Json 返回</a></li>
  <li><a href="#第八节">自定义出错页面</a></li>
  <li><a href="#第九节">WTF 跨站脚本防御</a></li>
</ul>

<h3 id="第一节">消息反馈</h3>

<p>Flask 提供了一个非常简单的方法来使用闪现系统向用户反馈信息。
闪现系统使得在一个请求结束的时候记录一个信息，然后在且仅仅在下一个请求中访问这个数据。这通常配合一个布局模板实现</p>

<p><a href="http://docs.jinkan.org/docs/flask/patterns/flashing.html">文档链接</a></p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class=""><span class="line"># 视图函数需要调用
</span><span class="line">flash('your response message for user')
</span><span class="line">
</span><span class="line"># 前端页面调用
</span><span class="line">for message in get_flashed_messages()
</span><span class="line">就可以输出反馈信息</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第二节">Flask 上下文</h3>

<p>有两种上下文：程序上下文，请求上下文</p>

<ul>
  <li>current_app： 程序级别上下文，当前激活程序的实例。</li>
  <li>g: 请求级别的上下文</li>
  <li>request: 是请求级别的上下文，封装了客户端发出的 Http 请求中的内容</li>
  <li>session: 用户会话，用于存储请求之间需要记住的键值对</li>
</ul>

<h3 id="第三节">注册 JinJia 模板过滤</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class=""><span class="line">def reverse_filter(s):
</span><span class="line">    return s[::-1]
</span><span class="line">
</span><span class="line">app.jinja_env.filters['reverse'] = reverse_filter</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第四节">itsdangerous 生成过期时间 Json 签名</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class=""><span class="line">serialaizer = Serializer(SECRET_KEY, expires_in=EXPIRES)
</span><span class="line">info = {'id':'xxx'}
</span><span class="line">session = serialaizer.dumps(info)
</span><span class="line">
</span><span class="line"># 判断 session 时间
</span><span class="line">info = None
</span><span class="line">try:
</span><span class="line">    info = serialaizer.loads(session)
</span><span class="line">except Exception:
</span><span class="line">    return jsonify(ERR_SESS_TIMEOUT)</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>用途：生成一个有时间限制的签名，用于API 访问的验证码，如果过期，提醒用户重新登录</p>

<h3 id="第五节">一种较好的项目组织方式</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
</pre></td><td class="code"><pre><code class=""><span class="line">▾ app/
</span><span class="line">    ▾ controlers/
</span><span class="line">        ▾ admin/                    #管理后台的蓝图控制器
</span><span class="line">            ▾ forms/                #表单限制文件
</span><span class="line">                __init__.py　　　　　
</span><span class="line">                xx.py　　　         # blueprint 文件
</span><span class="line">            __init__.py
</span><span class="line">            administrator.py
</span><span class="line">        ▾ api/                      # API 控制器
</span><span class="line">            __init__.py
</span><span class="line">        ▾ site/                     # 站点控制器
</span><span class="line">            __init__.py             # blueprint 文件
</span><span class="line">            xx.py
</span><span class="line">        __init__.py
</span><span class="line">        error.py
</span><span class="line">    ▸ models/         # SQLAlchemy 的各类模型
</span><span class="line">    ▸ static/         # 需要的静态资源，css, js, imgs
</span><span class="line">    ▾ templates/　　　# 前端页面，跟 controller 分类一一对应
</span><span class="line">        ▸ admin/
</span><span class="line">        ▸ error/
</span><span class="line">        ▸ site/
</span><span class="line">    ▸ utilities/　　　　#  功能函数
</span><span class="line">      __init__.py       #　初始化app需要的各种插件，比如 redis, db, 注册蓝图
</span><span class="line">run.py                  #　相当于 main 函数,创建 app, 执行app.run() 函数
</span><span class="line">settings.py             #　配置文件</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第六节">BluePrint 的好 </h3>

<p>每个 Blueprint 就像独立的 Application, 可以管理自己的模板, 路由, 反向路由url_for, 甚至是静态文件，最后统一挂载到 Application 下。从头到尾都是 RestFul。</p>

<p>在创建 app (app/<strong>init</strong>.py) 的时候调用如下:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">from app.controllers.site.console import console 
</span><span class="line">app.register_blueprint(console, url_prefix='/console')</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>视图文件 (app/controllers/site/console.py):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">console = BLueprint('console', __name__)</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第七节">Json 返回</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">from flask import jsonify
</span><span class="line">return jsonify({'code': 0})</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第八节">自定义出错页面</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class=""><span class="line">@app.errorhandler(404)
</span><span class="line">def not_found(error):
</span><span class="line">    return render_template('404.html'), 404
</span><span class="line">
</span><span class="line">@app.errorhandler(500)
</span><span class="line">def crash(error):
</span><span class="line">    return render_template('5xx.html'), 500</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第九节">WTF 跨站脚本防御</h3>

<p>Flask-WTF 能保护表单免受跨站请求伪造的攻击,恶意网站把请求发送到被攻击者已经登录的其他玩战会引发 CSRF 攻击</p>

<ul>
  <li>app config 文件中，开启 CSRF 开关并配置密钥</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">CSRF_ENABLED = True
</span><span class="line">SECRET_KEY = 'you-will-never-guess'</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>表单的定义</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class=""><span class="line">from flask.ext.wtf import Form, TextField, BooleanField
</span><span class="line">from flask.ext.wtf import Required
</span><span class="line">class LoginForm(Form):
</span><span class="line">    openid = TextField('openid', validators = [Required()])
</span><span class="line">    remember_me = BooleanField('remember_me', default = False)</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>页面渲染</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class=""><span class="line">&lt;form action="" method="post" name="login"&gt;
</span><span class="line">    form.hidden_tag()
</span><span class="line">    &lt;p&gt; Please enter your OpenID:form.openid(size=80)&lt;br&gt;&lt;/p&gt;
</span><span class="line">    &lt;p&gt;form.remember_me &lt;/p&gt;
</span><span class="line">    &lt;p&gt;&lt;input type="submit" value="Sign In"&gt;&lt;/p&gt;
</span><span class="line">&lt;/form&gt;</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>控制器函数</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class=""><span class="line">@app.route('/login', methods = ['GET', 'POST'])
</span><span class="line">def login():
</span><span class="line">    form = LoginForm()
</span><span class="line">    if form.validate_on_submit():
</span><span class="line">        flash('Login requested for OpenID="' + form.openid.data))
</span><span class="line">        return redirect('/index')
</span><span class="line">    return render_template('login.html', title = 'Sign In',form = form)</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>我们在配置中开启了CSRF(跨站伪造请求)功能，模板参数 form.hidden_tag() 会被替换成一个具有防止CSRF功能的隐藏表单字段。 在开启了CSRF功能后，所有模板的表单中都需要添加这个模板参数</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python 使用 LDAP]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/10/01/python-shi-yong-ldap/"/>
    <updated>2015-10-01T09:49:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/10/01/python-shi-yong-ldap</id>
    <content type="html"><![CDATA[<h2 id="section">写在开头</h2>

<p>过去的两个多星期，几位小伙伴同心协力完成一个自研的，类似<a href="http://pushover.net">pushover</a>的产品。感谢 Leader 的信任，让我在负责开发的同时也兼顾了一把项目经理。谢谢 IOS, Android 客户端的兄弟，设计师的支持，还有一位实习生，开心看到他的点滴成长。</p>

<p>提下背景，我们之前使用 <code>pushover</code> 来做报警推送，但是它对天朝用户不友好，Android 用户需要翻墙才能使用，有时候不稳定，体现为会收不到信息。pushove 需要付费。我们的受众不仅有程序汪，还有运营产品汪，他们需要一款更容易上手的推送软件，至少不需要番羽墙。于是自己开发一个很有必要。</p>

<p>为最大程度降低用户使用门槛，同时保证用户信息的安全，我们用了 LDAP 账户登陆，严格控制权限，以及 HTTPS 协议开发。下面提一提 LDAP 这个东西。</p>

<h2 id="ldap-">LDAP 是什么</h2>

<p><a href="https://zh.wikipedia.org/wiki/%E8%BD%BB%E5%9E%8B%E7%9B%AE%E5%BD%95%E8%AE%BF%E9%97%AE%E5%8D%8F%E8%AE%AE">LDAP维基百科</a></p>

<p>简单地讲，它是以目录树的方式存放账户信息。</p>

<p>这次项目中，我们不希望用户重新注册账户，而是采用原有的用户体系，这样对单点登录以及权限控制的好处不严而喻, LDAP 协议呼之欲出。</p>

<h2 id="virtualenv--python-ldap">virtualenv 下安装 python-ldap</h2>

<p>我们采用 Python 开发，这就需要 python-ldap 的帮助了, 记下安装笔记的好处是下次不用在此纠结太长时间。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">apt-get install libsasl2-dev python-dev libldap2-dev libssl-dev
</span><span class="line">pip install python-ldap</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="section-1">身份验证</h2>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class=""><span class="line"># LDAP 服务的域名和端口
</span><span class="line">SERVER_NAME = 'xxxx'
</span><span class="line">SERVER_PORT = xxx
</span><span class="line">try:
</span><span class="line">    conn = ldap.open(SERVER_NAME, SERVER_PORT)  
</span><span class="line">    conn.protocol_version = ldap.VERSION3 #设置ldap协议版本 
</span><span class="line">    username = "user=xxx,dc=company,dc=com" #身份信息
</span><span class="line">    password = "xxx" #访问密码
</span><span class="line">    conn.simple_bind_s(username,password) # 开始绑定，验证成功的话不会抛出异常
</span><span class="line">except ldap.LDAPError, e: #捕获出错信息
</span><span class="line">    print e</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="section-2">一点感悟</h2>

<p>鄙人觉得，技术领导要带领项目成长, 除了有责任把控项目风险，推进项目进度。
还必须要花很多的心血在驾驭技术上,  身先士卒去调研可行性, 以及做技术攻关，
而非命令式地分配任务，让同事干活, 只问责结果。
否则很容易导致凝聚力不足,团队技术氛围不足，这样的团队易消极，也易滋生失败的项目。
然而在天朝, 很多人存在一个潜意识:写好代码是为了以后不写代码，这种阶级思想让我反感。</p>

<p>以前看过一个新闻, 硅谷在面试技术 VP ，仍然要求其在各位工程师面前手写代码，以此作为面试的重要环节, 不得不点赞。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sysdig 值得拥有]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/09/10/sysdig-zhi-de-yong-you/"/>
    <updated>2015-09-10T23:10:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/09/10/sysdig-zhi-de-yong-you</id>
    <content type="html"><![CDATA[<p>定位服务器问题时,  我们需要各式各样的武器, 诸如 iftop, ifstat, netstat, tcpdump, iostat。dstat 等, 因此工具箱需要装满很多工具, 在面对问题的时候才能显得不费吹灰之力, 迅速定位问题并解决, 保障服务稳定运行。Sysdig 的横空出世, 对我们而言, 就是一把瑞士军刀, 灵活小巧, 武艺多端.</p>

<ul>
  <li><a href="#第一节">安装</a></li>
  <li><a href="#第二节">常用操作</a></li>
  <li><a href="#第三节">高效的实战</a></li>
</ul>

<h3 id="第一节">安装</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class=""><span class="line">curl -s https://s3.amazonaws.com/download.draios.com/DRAIOS-GPG-KEY.public | apt-key add -
</span><span class="line">curl -s -o /etc/apt/sources.list.d/draios.list http://download.draios.com/stable/deb/draios.list
</span><span class="line">apt-get update
</span><span class="line">apt-get -y install sysdig</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第二节">常用操作</h3>

<p>sysdig 有很多 chisel, chisel 意为 铲子, 可以理解为定位某类问题的工具, sysdig 采用 Lua 编写的。</p>

<ul>
  <li>查看 chisel 列表</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sysdig -cl  </span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看具体某个 chisel 的提示</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sysdig -i spy_logs</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>使用某个 chisel</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sysdig -c spy_logs</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>过滤器可以帮助我们从各种输出信息中, 筛选出我们需要的, 比如 
<code>proc.name=foo</code> , 
如果你记住不了太多过滤器也无妨,  我们可以借助如下命令查看过滤器</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sysdig -l</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>记录定位信息到文本, 以及从文本读取信息</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sysdig -w tracefile.cap
</span><span class="line">sysdig -r tracefile.dump proc.name=sshd</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第三节">高效的实战</h3>

<ul>
  <li>服务器上经常需要查看哪个服务带宽占用使用较高, 特别是被 DDOS 的时候。</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo sysdig -c topprocs_net</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看某个IP的通讯数据,并以ASCII 码输出</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo sysdig -s2000 -A -c echo_fds fd.cip=127.0.0.1</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看非请求 redis-server 的其他请求进程和句柄</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo sysdig -p"%proc.name %fd.name" "evt.type=accept and proc.name!=redis-server"</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看访问该服务器的所有 GET 请求数据</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo sysdig -s 2000 -A -c echo_fds fd.port=80 and evt.buffer contains GET</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看访问该服务器的 SQL 语句</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo sysdig -s 2000 -A -c echo_fds evt.buffer contains SELECT</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看磁盘读写最高的进程</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sysdig -c topprocs_file</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看延迟最大的系统调用</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sysdig -c topscalls_time</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看具体文件的操作细节</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sysdig -A -c echo_fds "fd.filename=syslog"</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看 IO 延迟大于 1ms 的文件</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo sysdig -c fileslower 1</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>监视某个文件是否被操作, 从安全出发想象空间很大哦</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo sysdig evt.type=open and fd.name contains /etc</span></code></pre></td></tr></table></div></figure></notextile></div>

<hr />

<p><a href="http://www.sysdig.org/wiki/">Sysdig 官网</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ansible 使用经验]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/09/05/ansiblede-shi-yong-jing-yan/"/>
    <updated>2015-09-05T18:09:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/09/05/ansiblede-shi-yong-jing-yan</id>
    <content type="html"><![CDATA[<p>当你只有一两台服务器的情况下，可以直接登上服务器，手敲命令完成软件部署，代码发布等工作。但假如你有10台，100台的时候，这种方式不仅浪费大量时间，而且给人为犯错带来了可能。于是我们选择 Ansible 来做自动化批量操作。</p>

<p>之前有记录一些 Ansible 入门的使用,请看<a href="http://wiki.zheng-ji.info/Sys/ansible.html">这里</a>, 这半年的积累, 总结一些实用的经验, 记录了一把。</p>

<ul>
  <li><a href="#第一节">配置 ansible.cfg 文件</a></li>
  <li><a href="#第二节">使用 ansible role 来区分业务</a></li>
  <li><a href="#第三节">files 目录的路径定位</a></li>
  <li><a href="#第四节">使用 tags 区分不同操作</a></li>
  <li><a href="#第五节">规划 ansible roles 的 tasks 文件</a></li>
  <li><a href="#第六节">ansible-play-book 一些常用的选项</a></li>
</ul>

<h3 id="第一节">更好地配置文件</h3>

<p>我们会如下配置 /etc/ansible/host, 特意指明用户与 端口</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">[web-cluster]
</span><span class="line">&lt;node-1-IP&gt; ansible_ssh_port=&lt;Your Port&gt; ansible_ssh_user=zj
</span><span class="line">&lt;node-2-IP&gt; ansible_ssh_port=&lt;Your Port&gt; ansible_ssh_user=zj</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>在 /etc/ansible/ansible.cfg 文件里
我们特意提及了 ansible-role 的配置，未来我们会使用这个东西</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">roles_path    = /home/zj/my-ansible/roles</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第二节">使用 ansible role 来区分业务</h3>

<p>打开 ansible 部署脚本的文件夹, 目录树如下</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class=""><span class="line">cd /home/zj/my-ansible/
</span><span class="line">haproxy
</span><span class="line">     - entry.yaml
</span><span class="line">roles
</span><span class="line">     - haproxy
</span><span class="line">        - files
</span><span class="line">        - handlers
</span><span class="line">        - vars
</span><span class="line">        - tasks</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>我用一个管理 haproxy 的例子来讲解这种方式。
在 roles 目录下创建 haproxy, 如上所示，需要有四个目录;</p>

<ul>
  <li>files 目录下放置需要被传输到远端的文件;</li>
  <li>vars  目录下有一个 main.yml 文件,可以定义一些通用的配置变量，可以在 ansbile 脚本中使用;</li>
  <li>handlers 目录下有一个 main.yml, 可以定义一些通用的操作，比如重启服务等;</li>
  <li>tasks 目录下是我们编写 main.yml 脚本，执行业务逻辑的地方;</li>
</ul>

<blockquote>
  <p>那么 ansible role 的入口在哪呢？</p>
</blockquote>

<p>在 ~/my-ansible/haproxy/entry.yml 中，指定了roles的角色，如此一来， 
ansible-playbook 就会去 /home/zj/my-ansible/roles/haproxy 准备执行 tasks/main.yml </p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">- hosts: web-cluster
</span><span class="line">  roles:
</span><span class="line">    - haproxy</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第三节">files 目录的路径定位</h3>

<p>摘取 ~/my-ansible/roles/haproxy/tasks/main.yml</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">- name: copy haproxy conf
</span><span class="line">  copy: src=haproxy.cfg dest=/etc/haproxy/haproxy.cfg owner=root group=root
</span><span class="line">  sudo: yes</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>这里的 src=haproxy.cfg 意味着 ~/my-ansible/roles/haproxy/files/haproxy.cfg</p>

<h3 id="第四节">使用 tags 区分不同操作</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class=""><span class="line">- name: install ppa
</span><span class="line">  shell: add-apt-repository -y ppa:vbernat/haproxy-1.5
</span><span class="line">  sudo: yes
</span><span class="line">  tags:
</span><span class="line">    - install-haproxy</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>以下命令，是使用 tags 参数区分操作的例子</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">cd ~/my-ansible/haproxy
</span><span class="line">ansible-playbook entry.yml -v -K --tags "install-haproxy"</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第五节">规划 ansible roles 的 tasks 目录</h3>

<p>tasks 目录有一个主执行文件 main.yml, 因为业务操作步骤太多，导致 main.yml 文件很长，那么可读性就下降了。为此，我们使用了 include 语法。</p>

<p>cat ~/my-ansible/roles/haproxy/tasks/main.yml</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">- include: 'install-haproxy.yml'</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>include 上述文件，这样 main.yml 就显得简洁，我们可以将相关的操作写在对应的 yml 文件里</p>

<p>cat ~/my-ansible/roles/haproxy/tasks/install-haproxy.yml</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class=""><span class="line">- name: copy haproxy conf
</span><span class="line">  copy: src=haproxy.cfg dest=/etc/haproxy/haproxy.cfg owner=root group=root
</span><span class="line">  sudo: yes
</span><span class="line">  tags:
</span><span class="line">     - install-haproxy</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>tags 最好也与该 yml 文件名一致，清晰分明</p>

<h3 id="第六节">ansible-play-book 一些常用的选项</h3>

<ul>
  <li>-K 需要 sudo 权限去客户机执行命令，会提示你输入密码</li>
  <li>-v 可以输出冗余的执行过程</li>
  <li>–check 可以测试脚本执行情况，但实际并未在远程机器执行</li>
  <li>–tags 提示 ansible-play-book 调用哪些 tags 命令</li>
</ul>

<p>使用过ansible roles 之后，最大的体会是操作调理化，甚至编程化，合理的利用 handler, vars, 能更加优雅抽象。</p>

<hr />

<p>上述的例子在 Github 有代码, 结合本文阅读可能更容易上手
<a href="https://github.com/zheng-ji/ToyCollection/tree/master/my-ansible">Link</a> </p>

]]></content>
  </entry>
  
</feed>
