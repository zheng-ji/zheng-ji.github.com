<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[织网]]></title>
  <link href="http://zheng-ji.github.com/atom.xml" rel="self"/>
  <link href="http://zheng-ji.github.com/"/>
  <updated>2016-07-23T20:27:34+08:00</updated>
  <id>http://zheng-ji.github.com/</id>
  <author>
    <name><![CDATA[zheng-ji]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Celery的Crontab实践]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/07/23/celeryde-crontabshi-jian/"/>
    <updated>2016-07-23T20:19:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/07/23/celeryde-crontabshi-jian</id>
    <content type="html"><![CDATA[<p>有时候我们需要处理耗时的操作，同时又要保持较快的响应速度，就需要借助异步队列的帮助。Celery 作为异步队列服务，想必是很多人和我一样的选择。用法在官方文档也详细介绍，不再赘述。</p>

<p>这次想记录的是用 Celery 来实现定时任务。这里也有一点点坑。</p>

<p>main.py 的内容</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span class="kn">from</span> <span class="nn">celery</span> <span class="kn">import</span> <span class="n">Celery</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">lib</span> <span class="kn">import</span> <span class="n">distribute</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">celery.schedules</span> <span class="kn">import</span> <span class="n">crontab</span>
</span><span class="line">
</span><span class="line"><span class="n">app</span> <span class="o">=</span> <span class="n">distribute</span><span class="o">.</span><span class="n">app</span>
</span><span class="line"><span class="n">app</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
</span><span class="line">    <span class="n">CELERYBEAT_SCHEDULE</span> <span class="o">=</span> <span class="p">{</span>
</span><span class="line">        <span class="s">&#39;every-minute&#39;</span><span class="p">:</span> <span class="p">{</span>
</span><span class="line">            <span class="s">&#39;task&#39;</span><span class="p">:</span> <span class="s">&#39;test_cron&#39;</span><span class="p">,</span>
</span><span class="line">            <span class="s">&#39;schedule&#39;</span><span class="p">:</span> <span class="n">crontab</span><span class="p">(</span><span class="n">minute</span><span class="o">=</span><span class="s">&quot;*&quot;</span><span class="p">),</span>
</span><span class="line">            <span class="s">&#39;args&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">13</span><span class="p">),</span>
</span><span class="line">        <span class="p">}</span>
</span><span class="line">    <span class="p">},</span>
</span><span class="line">    <span class="n">CELERY_INCLUDE</span><span class="o">=</span><span class="p">(</span><span class="s">&quot;apps.tasks&quot;</span><span class="p">,)</span>
</span><span class="line"><span class="p">)</span>
</span><span class="line"><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&#39;__main__&#39;</span><span class="p">:</span>
</span><span class="line">    <span class="n">app</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>实际工作单元,我放在 apps 目录下的 <code>tasks.py</code> 文件中</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span class="kn">from</span> <span class="nn">lib.distribute</span> <span class="kn">import</span> <span class="n">app</span>
</span><span class="line"><span class="nd">@app.task</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">&quot;test_cron&quot;</span><span class="p">)</span>
</span><span class="line"><span class="k">def</span> <span class="nf">mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span class="line">    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>上述是一个简单的 Crontab 应用，它仅需要以下命令就能执行,
其中  <code>--beat</code> 表示 crontab 的应用</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span class="n">python</span> <span class="n">main</span><span class="o">.</span><span class="n">py</span> <span class="n">worker</span> <span class="o">--</span><span class="n">beat</span> <span class="o">-</span><span class="n">l</span> <span class="n">info</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>起初我想把异步队列和定时任务放在一起,就加上了一句 CELERY_QUEUES 的配置</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span class="n">app</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
</span><span class="line">    <span class="o">//</span> <span class="err">添加的部分</span>
</span><span class="line">    <span class="n">CELERY_QUEUES</span><span class="o">=</span><span class="p">(</span>
</span><span class="line">        <span class="n">Queue</span><span class="p">(</span>
</span><span class="line">          <span class="s">&#39;test&#39;</span><span class="p">,</span> <span class="n">Exchange</span><span class="p">(</span><span class="s">&#39;test_exchange&#39;</span><span class="p">),</span>
</span><span class="line">           <span class="n">routing_key</span><span class="o">=</span><span class="s">&#39;test_queue&#39;</span>
</span><span class="line">        <span class="p">),</span>
</span><span class="line">    <span class="p">),</span>
</span><span class="line">    <span class="n">CELERYBEAT_SCHEDULE</span> <span class="o">=</span> <span class="p">{</span>
</span><span class="line">        <span class="s">&#39;every-minute&#39;</span><span class="p">:</span> <span class="p">{</span>
</span><span class="line">            <span class="s">&#39;task&#39;</span><span class="p">:</span> <span class="s">&#39;test_cron&#39;</span><span class="p">,</span>
</span><span class="line">            <span class="s">&#39;schedule&#39;</span><span class="p">:</span> <span class="n">crontab</span><span class="p">(</span><span class="n">minute</span><span class="o">=</span><span class="s">&quot;*&quot;</span><span class="p">),</span>
</span><span class="line">            <span class="s">&#39;args&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">13</span><span class="p">),</span>
</span><span class="line">        <span class="p">}</span>
</span><span class="line">    <span class="p">},</span>
</span><span class="line">    <span class="n">CELERY_INCLUDE</span><span class="o">=</span><span class="p">(</span><span class="s">&quot;apps.tasks&quot;</span><span class="p">,)</span>
</span><span class="line"><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>同样用上述命令开启worker，发现这个时候 Crontab 不能工作了，后来看到官方的文档：</p>

<blockquote>
  <p>celery beat and celery worker as separate services instead. </p>
</blockquote>

<p>也就是说 Celery 的 Beat 需要和其他异步worker 分开，单独执行。</p>

<p>相关代码<a href="https://github.com/zheng-ji/ToyCollection/tree/master/celery_proj">链接</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[环境变量的那些事]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/07/16/bash-jia-zai-shun-xu/"/>
    <updated>2016-07-16T11:35:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/07/16/bash-jia-zai-shun-xu</id>
    <content type="html"><![CDATA[<ul>
  <li><a href="#第一节">四种模式下的环境变量加载</a></li>
  <li><a href="#第二节">跨机器SSH 传递环境变量</a></li>
</ul>

<h3 id="第一节">四种模式下的环境变量加载</h3>

<p>名词解析</p>

<ol>
  <li>login shell: 指用户以非图形化界面 ssh登陆到机器上时获得的第一个 shell。 </li>
  <li>interactive: 交互式，有输入提示符，它的标准输入输出和错误输出都会显示在控制台上。</li>
</ol>

<ul>
  <li>interactive + login shell</li>
</ul>

<p>比如登陆机器后的第一个 shell 就是这种场景。它首先加载 /etc/profile，然后再依次去加载下列三个配置文件之一，一旦找到其中一个便不再接着寻找</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">~/.bash_profile
</span><span class="line">~/.bash_login
</span><span class="line">~/.profile</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>设计如此多的配置是为了兼容 bourne shell 和 C shell，尽量杜绝使用 .bash_login，如果已创建，需要创建 .bash_profile 覆盖</p>

<ul>
  <li>noninteractive + login shell</li>
</ul>

<p>bash -l script.sh 就是这种场景。<code>-l</code> 参数是将shell作为一个login shell启动，配置文件的加载与第一种完全一样。</p>

<ul>
  <li>interactive + non-login shell</li>
</ul>

<p>在一个已有shell中运行bash，此时会打开一个交互式的shell，因为不再需要登陆，所以不是login shell。启动 shell 时会去查找并加载</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">/etc/bash.bashrc
</span><span class="line">~/.bashrc </span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>non-interactive + non-login shell</li>
</ul>

<p>比如执行脚本 bash script.sh 或者 ssh user@remote command。这两种都是创建一个shell，执行完脚本之后便退出，不再需要与用户交互。它会去寻找环境变量BASH_ENV，将变量的值作为文件名进行查找，如果找到便加载它。</p>

<p>从网上看到一个清晰的图</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
</pre></td><td class="code"><pre><code class=""><span class="line">+----------------+--------+-----------+---------------+
</span><span class="line">|                | login  |interactive|non-interactive|
</span><span class="line">|                |        |non-login  |non-login      |
</span><span class="line">+----------------+--------+-----------+---------------+
</span><span class="line">|/etc/profile    |   A    |           |               |
</span><span class="line">+----------------+--------+-----------+---------------+
</span><span class="line">|/etc/bash.bashrc|        |    A      |               |
</span><span class="line">+----------------+--------+-----------+---------------+
</span><span class="line">|~/.bashrc       |        |    B      |               |
</span><span class="line">+----------------+--------+-----------+---------------+
</span><span class="line">|~/.bash_profile |   B1   |           |               |
</span><span class="line">+----------------+--------+-----------+---------------+
</span><span class="line">|~/.bash_login   |   B2   |           |               |
</span><span class="line">+----------------+--------+-----------+---------------+
</span><span class="line">|~/.profile      |   B3   |           |               |
</span><span class="line">+----------------+--------+-----------+---------------+
</span><span class="line">|BASH_ENV        |        |           |       A       |
</span><span class="line">+----------------+--------+-----------+---------------+</span></code></pre></td></tr></table></div></figure></notextile></div>
<hr />

<h3 id="第二节">跨机器传递环境变量</h3>

<p>假设要传递的变量叫做 $VARNAME</p>

<p>客户端机器的 <code>/etc/ssh_config</code> 添加 </p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">SendEnv VARNAME</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>服务端机器的 <code>/etc/sshd_config</code> 添加</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">AcceptEnv VARNAME</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>客户端机器的 $VARNAME 就可以通过 ssh 传递到服务端机器，继续使用.</p>

<hr />

<h3 id="section">参考</h3>

<p><a href="http://feihu.me/blog/2014/env-problem-when-ssh-executing-command-on-remote/">ssh连接远程主机执行脚本的环境变量问题</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[准确监控 MySQL 复制延迟]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/06/03/zhun-que-jian-ce-mysql-fu-zhi-yan-chi/"/>
    <updated>2016-06-03T23:35:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/06/03/zhun-que-jian-ce-mysql-fu-zhi-yan-chi</id>
    <content type="html"><![CDATA[<p>MySQL 建立主从复制后，在 <code>Slave_IO_Running</code>,<code>Slave_SQL_Runing</code> 都是 Yes 的前提下，通过监控 <code>Second_Behind_Master</code> 的数值来判断主从延迟时间，该值为0时是否意味着主从同步是无延迟的呢？</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="n">mysql</span><span class="o">&gt;</span> <span class="k">show</span> <span class="n">slave</span> <span class="n">status</span><span class="err">\</span><span class="k">G</span><span class="p">;</span>
</span><span class="line"><span class="o">***************************</span> <span class="mi">1</span><span class="p">.</span> <span class="k">row</span> <span class="o">***************************</span>
</span><span class="line"><span class="n">Slave_IO_State</span><span class="p">:</span> <span class="n">Waiting</span> <span class="k">for</span> <span class="n">master</span> <span class="k">to</span> <span class="n">send</span> <span class="n">event</span>
</span><span class="line"><span class="p">....</span>
</span><span class="line"><span class="n">Slave_IO_Running</span><span class="p">:</span> <span class="n">Yes</span>
</span><span class="line"><span class="n">Slave_SQL_Running</span><span class="p">:</span> <span class="n">Yes</span>
</span><span class="line"><span class="n">Seconds_Behind_Master</span><span class="p">:</span> <span class="mi">0</span>
</span><span class="line"><span class="p">...</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>很遗憾，我们并不能这样去判断，因为你看到的有可能是假象。</p>

<p>MySQL的同步是异步完成的，其中</p>

<ul>
  <li>IO thread 接收从主库的 binlog，然后在从库生成 relay log</li>
  <li>SQL thead 解析 relay log 后在从库上进行重放</li>
</ul>

<p><code>Second_Behind_Master</code>(以下简称SBM) 是 SQL thread 在执行IO thread 生成的relay log的时间差。relay log中event的时间戳是主库上的时间戳，而SQL thread的时间戳是从库上的，SBM 代表的是从库延后主库的时间差。</p>

<p>主库上执行了一个大的操作，这个操作在主库上没执行完毕的时候，从库的 SBM 会显示为0，而当主库执行完毕传到从库上开始执行的时候,SBM 就会显示很大，在网络状况不好的情况下，更是容易出现 SBM 在零和一个巨大的数值反复飘忽的现象。</p>

<h3 id="pt-heartbeat-">pt-heartbeat 帮我们准确地检测</h3>

<p>pt-heartbeat 是 percona-toolkit 中用来检测主从延迟的工具，需要在主库和从库同时配合才能完成</p>

<ul>
  <li>首先在主库创建监控的表，并定时更新</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="o">//</span><span class="err">创建</span> <span class="n">heartbeat</span> <span class="err">表</span>
</span><span class="line"><span class="n">pt</span><span class="o">-</span><span class="n">heartbeat</span> <span class="c1">--user=root --ask-pass \</span>
</span><span class="line">            <span class="c1">--host=localhost -D &lt;YourDatabase&gt; \</span>
</span><span class="line">            <span class="c1">--create-table --update </span>
</span><span class="line">
</span><span class="line"><span class="o">//</span><span class="err">每隔</span><span class="mi">60</span><span class="n">s</span><span class="p">,</span><span class="err">定时更新状态，以守护进程的方式执行</span>
</span><span class="line"><span class="n">pt</span><span class="o">-</span><span class="n">heartbeat</span> <span class="c1">--user=root --ask-pass \</span>
</span><span class="line">           <span class="c1">--host=localhost -D &lt;YourDatabase&gt;\</span>
</span><span class="line">           <span class="c1">--interval=60 --update --replace --daemonize</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>它会在指定的数据库里生产一张名为 heartbeat 的表，每隔60秒定时更新binlog 文件和位置，以及时间戳。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="o">+</span><span class="c1">----------------------------+-----------+------------------+-----------+-----------------------+---------------------+</span>
</span><span class="line"><span class="o">|</span> <span class="n">ts</span>                         <span class="o">|</span> <span class="n">server_id</span> <span class="o">|</span> <span class="n">file</span>             <span class="o">|</span> <span class="k">position</span>  <span class="o">|</span> <span class="n">relay_master_log_file</span> <span class="o">|</span> <span class="n">exec_master_log_pos</span> <span class="o">|</span>
</span><span class="line"><span class="o">+</span><span class="c1">----------------------------+-----------+------------------+-----------+-----------------------+---------------------+</span>
</span><span class="line"><span class="o">|</span> <span class="mi">2016</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">03</span><span class="n">T22</span><span class="p">:</span><span class="mi">26</span><span class="p">:</span><span class="mi">29</span><span class="p">.</span><span class="mi">000720</span> <span class="o">|</span>         <span class="mi">6</span> <span class="o">|</span> <span class="n">mysql</span><span class="o">-</span><span class="n">bin</span><span class="p">.</span><span class="mi">004</span><span class="o">|</span> <span class="mi">716</span><span class="o">|</span> <span class="n">mysql</span><span class="o">-</span><span class="n">bin</span><span class="p">.</span><span class="mi">002</span><span class="o">|</span>           <span class="mi">291330290</span> <span class="o">|</span>
</span><span class="line"><span class="o">+</span><span class="c1">----------------------------+-----------+------------------+-----------+-----------------------+---------------------+</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>接着在从库以守护进程执行定期检测,并将结果重定向到文本</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="n">pt</span><span class="o">-</span><span class="n">heartbeat</span> <span class="c1">--user=root --ask-pass \</span>
</span><span class="line">     <span class="c1">--host=localhost -D &lt;YourDatabase&gt; --interval=60 \</span>
</span><span class="line">     <span class="c1">--file=/tmp/output.txt --monitor --daemonize</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>文本的内容只有一行，每隔指定的时间就会被覆盖</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="mi">29</span><span class="p">.</span><span class="mi">00</span><span class="n">s</span> <span class="p">[</span> <span class="mi">30</span><span class="p">.</span><span class="mi">20</span><span class="n">s</span><span class="p">,</span>  <span class="mi">6</span><span class="p">.</span><span class="mi">04</span><span class="n">s</span><span class="p">,</span>  <span class="mi">2</span><span class="p">.</span><span class="mi">01</span><span class="n">s</span> <span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>29s 表示的是瞬间的延迟时间，30.20s 表示1分钟的延迟时间，6.04秒表示5分钟的延迟时间，2.01秒表示以及15分钟的延迟时间，在主从机器时间校准的前提下，这个数据才是客观准确的主从延迟。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ansible Dynamic Inventory]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/04/24/ansible-dynamic-inventory/"/>
    <updated>2016-04-24T20:53:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/04/24/ansible-dynamic-inventory</id>
    <content type="html"><![CDATA[<p>Ansible 在使用的过程中，如果机器数量比较固定，且变更不多的情况下，可在 /etc/ansible/hosts 文件里面配置固定的组合机器IP， 并给他起组的别名，执行 Ansible 脚本便可以通过别名找到相应的机器。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">[webservers]
</span><span class="line">111.222.333.444 ansible_ssh_port=888</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>假如你有很多台机器，且机器经常变更导致IP时常变换，你还想把IP逐个写入 /etc/ansible/hosts 就不现实了。你也许会问，若不把 IP 写进 /etc/ansible/hosts，那不是没法用 Ansible 指挥这些机器？
感谢 Ansible Dynamic Inventory， 如果我们能通过编程等手段获取变更机器的IP，我们还是有办法实现的。</p>

<h3 id="dynamic-inventory-">Dynamic Inventory 的原理</h3>

<ul>
  <li>通过编程的方式,也就是动态获取机器的 json 信息;</li>
  <li>Ansible 通过解析这串 json 字符串;</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">ansible -i yourprogram.py -m raw  -a 'cd /home'</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Ansible Dynamic Inventory 对程序返回的 json 的转义是这样的：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">{"devtest-asg": {"hosts": ["172.31.21.164"], "vars": {"ansible_ssh_port": 12306}}}</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>翻译一下就是  /etc/ansible/hosts 中的:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">[devtest-asg]
</span><span class="line">172.31.21.164 ansible_ssh_port=12306</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="section">一个实战的例子</h3>

<p>官方文档对 Inventory 仅作概念性描述，阅读完后仍是一头雾水，不知如何下手。 让我们用一个例子来豁然开朗吧。 我们使用 AWS 的 AutoScaling Group，以下简称 ASG，ASG 会在某种自定义的条件下会自动开启和关闭机器，这给我们在辨别IP，定位机器的时候造成困扰。因此我们需要 Ansible Dynamic Inventory</p>

<p>我们使用 AWS 的 boto 库来获取 ASG 的实例信息.以下程序(get_host.py)中要实现的方法就是列出返回机器信息的 json 串。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
<span class="line-number">39</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="c">#!/usr/bin/env python</span>
</span><span class="line"><span class="c"># -*- coding: utf-8 -*-</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">json</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">boto</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">boto.ec2</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">boto.ec2.autoscale</span>
</span><span class="line">
</span><span class="line"><span class="n">AWS_REGION</span> <span class="o">=</span> <span class="s">&#39;BBB&#39;</span>
</span><span class="line"><span class="n">AWS_ACCESS_KEY</span> <span class="o">=</span> <span class="s">&#39;xxxx&#39;</span>
</span><span class="line"><span class="n">AWS_SECRET_KEY</span> <span class="o">=</span> <span class="s">&#39;yyy&#39;</span>
</span><span class="line">
</span><span class="line"><span class="n">result</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class="line"><span class="k">def</span> <span class="nf">getData</span><span class="p">():</span>
</span><span class="line">    <span class="n">conn_as</span> <span class="o">=</span> <span class="n">boto</span><span class="o">.</span><span class="n">ec2</span><span class="o">.</span><span class="n">autoscale</span><span class="o">.</span><span class="n">connect_to_region</span><span class="p">(</span>
</span><span class="line">            <span class="s">&#39;cn-north-1&#39;</span><span class="p">,</span>
</span><span class="line">            <span class="n">aws_access_key_id</span><span class="o">=</span><span class="n">AWS_ACCESS_KEY</span><span class="p">,</span>
</span><span class="line">            <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="n">AWS_SECRET_KEY</span><span class="p">)</span>
</span><span class="line">    <span class="n">group</span> <span class="o">=</span> <span class="n">conn_as</span><span class="o">.</span><span class="n">get_all_groups</span><span class="p">(</span><span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;devtest-asg&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
</span><span class="line">    <span class="n">conn_ec2</span> <span class="o">=</span> <span class="n">boto</span><span class="o">.</span><span class="n">ec2</span><span class="o">.</span><span class="n">connect_to_region</span><span class="p">(</span>
</span><span class="line">            <span class="n">AWS_REGION</span><span class="p">,</span>
</span><span class="line">            <span class="n">aws_access_key_id</span><span class="o">=</span><span class="n">AWS_ACCESS_KEY</span><span class="p">,</span>
</span><span class="line">            <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="n">AWS_SECRET_KEY</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="n">instance_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">instance_id</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">group</span><span class="o">.</span><span class="n">instances</span><span class="p">]</span>
</span><span class="line">    <span class="n">reservations</span> <span class="o">=</span> <span class="n">conn_ec2</span><span class="o">.</span><span class="n">get_all_instances</span><span class="p">(</span><span class="n">instance_ids</span><span class="p">)</span>
</span><span class="line">    <span class="n">instances</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">reservations</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">r</span><span class="o">.</span><span class="n">instances</span><span class="p">]</span>
</span><span class="line">
</span><span class="line">    <span class="n">result</span><span class="p">[</span><span class="s">&#39;devtest-asg&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class="line">    <span class="n">result</span><span class="p">[</span><span class="s">&#39;devtest-asg&#39;</span><span class="p">][</span><span class="s">&#39;hosts&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class="line">    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">reservations</span><span class="p">:</span>
</span><span class="line">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">r</span><span class="o">.</span><span class="n">instances</span><span class="p">:</span>
</span><span class="line">            <span class="n">result</span><span class="p">[</span><span class="s">&#39;devtest-asg&#39;</span><span class="p">][</span><span class="s">&#39;hosts&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s">&#39;</span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="o">.</span><span class="n">private_ip_address</span><span class="p">)</span>
</span><span class="line">            <span class="n">result</span><span class="p">[</span><span class="s">&#39;devtest-asg&#39;</span><span class="p">][</span><span class="s">&#39;vars&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;ansible_ssh_port&#39;</span><span class="p">:</span> <span class="mi">36000</span><span class="p">}</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">getlists</span><span class="p">():</span>
</span><span class="line">    <span class="n">getData</span><span class="p">()</span>
</span><span class="line">    <span class="k">print</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">getlists</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>执行以下命令就可以愉快地使用 Ansible 了，其中 devtest-asg 是 ASG 的别名：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">ansible</span> <span class="o">-</span><span class="n">i</span> <span class="n">get_host</span><span class="o">.</span><span class="n">py</span>  <span class="n">devtest</span><span class="o">-</span><span class="n">asg</span> <span class="o">-</span><span class="n">m</span> <span class="n">raw</span> <span class="o">-</span><span class="n">a</span> <span class="s">&#39;ls /&#39;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Flume 实时收集 Nginx 日志]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/04/23/flume-shi-shi-shou-ji-nginx-ri-zhi/"/>
    <updated>2016-04-23T09:13:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/04/23/flume-shi-shi-shou-ji-nginx-ri-zhi</id>
    <content type="html"><![CDATA[<p>在分布式系统中，各个机器都有程序运行的本地日志，有时为了分析需求，不得不这些分散的日志汇总需求，相信很多人会选择 Rsync，Scp 之类，
但它们的实时性不强，而且也会带来名字冲突的问题。扩展性差强人意，一点也不优雅。</p>

<p>现实中，我们就碰到了这样的需求：实时汇总线上多台服务器的 Nginx 日志。Flume 立功了。</p>

<h1 id="flume-">Flume 简介</h1>

<p><a href="https://flume.apache.org/"><strong>F</strong>lume</a> 是一个分布式，可靠高效的日志收集系统，它允许用户自定义数据传输模型，因此可扩展性也强。也有较强的容错和恢复机制.
以下是几个重要的概念</p>

<ul>
  <li>Event：Event 是 Flume 数据传输的基本单元。flume 以事件的形式将数据从源头传送到最终的目的。</li>
  <li>Agent：Agent包含 Sources, Channels, Sinks 和其他组件，它利用这些组件将events从一个节点传输到另一个节点或最终目的。</li>
  <li>Source：Source负责接收events，并将events批量的放到一个或多个Channels。</li>
  <li>Channel：Channel位于 Source 和 Sink 之间，用于缓存进来的events，当Sink成功的将events发送到下一跳的channel或最终目的，events从Channel移除。</li>
  <li>Sink：Sink 负责将 events 传输到下一跳或最终目的，成功完成后将events从channel移除。</li>
</ul>

<p><img src="http://zheng-ji.github.com/images/2016/04/flume.jpg" /></p>

<ul>
  <li>Source 就有 Syslog Source, Kafka Source,HTTP Source, Exec Source Avro Source 等。</li>
  <li>Sink 有 Kafka Sink, Avro Sink, File Roll Sink, HDFS Sink 等。</li>
  <li>Channel 有 Memory Channel,File Channel 等</li>
</ul>

<p>它提供了一个骨架，以及多种 Source, Sink, Channel, 让你设计合适的数据模型。事实上也可以多个 Flume 联动完成，就像地铁的车厢一样。</p>

<h1 id="section">定义数据流模型</h1>

<p>回到我们开头的场景,我们要将多台服务器的 Nginx 日志进行汇总分析，</p>

<p>分成两个 flume 来实现</p>

<ul>
  <li>Flume1 数据流是 Exec Source -&gt; Memory Channel -&gt; Avro Sink,部署在业务机器上</li>
  <li>Flume2 数据流是 Avro Source -&gt; Memory Channel -&gt; FileRoll Sink</li>
</ul>

<p><img src="http://zheng-ji.github.com/images/2016/04/flume1toflume2.jpg" /></p>

<h1 id="section-1">需要的准备</h1>

<p>你需要安装</p>

<ul>
  <li>下载 <a href="https://flume.apache.org/download.html">Flume</a></li>
  <li>安装 JavaSDk,并在下载解压之后的 conf/flume-env.sh，配置</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c"># 我用的是oracle-java-8</span>
</span><span class="line"><span class="nb">export </span><span class="nv">JAVA_HOME</span><span class="o">=</span>/usr/lib/jvm/java-8-oracle/jre/
</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>思考你的数据流动模型，编写配置，如上文所说的Flume1, tail2avro.conf  ：</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">agent.sources <span class="o">=</span> s1
</span><span class="line">agent.channels <span class="o">=</span> c1
</span><span class="line">agent.sinks <span class="o">=</span> k1
</span><span class="line">
</span><span class="line">agent.sources.s1.type<span class="o">=</span><span class="nb">exec</span>
</span><span class="line">agent.sources.s1.command<span class="o">=</span>tail -F &lt;Your File Path&gt;
</span><span class="line">agent.sources.s1.channels<span class="o">=</span>c1
</span><span class="line">
</span><span class="line">agent.channels.c1.type<span class="o">=</span>memory
</span><span class="line">agent.channels.c1.capacity<span class="o">=</span>10000
</span><span class="line">agent.channels.c1.transactionCapacity<span class="o">=</span>10000
</span><span class="line">
</span><span class="line">agent.sinks.k1.type <span class="o">=</span> avro
</span><span class="line">agent.sinks.k1.hostname <span class="o">=</span> &lt;Your Target Address&gt;
</span><span class="line">agent.sinks.k1.port <span class="o">=</span> &lt;Your Target Port&gt;
</span><span class="line">agent.sinks.k1.channel<span class="o">=</span>c1
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Flume2 中的 avro2file.conf </p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">agent.sources <span class="o">=</span> s1
</span><span class="line">agent.channels <span class="o">=</span> c1
</span><span class="line">agent.sinks <span class="o">=</span> k1
</span><span class="line">
</span><span class="line">agent.sources.s1.type <span class="o">=</span> avro
</span><span class="line">agent.sources.s1.bind <span class="o">=</span> &lt;Your Address&gt;
</span><span class="line">agent.sources.s1.port <span class="o">=</span> &lt;Your Port&gt;
</span><span class="line">agent.sources.s1.channels <span class="o">=</span> c1
</span><span class="line">
</span><span class="line">agent.sinks.k1.type <span class="o">=</span> file_roll
</span><span class="line">agent.sinks.k1.sink.directory <span class="o">=</span> /data/log/ngxlog
</span><span class="line"><span class="c"># 滚动间隔</span>
</span><span class="line">agent.sinks.k1.sink.rollInterval <span class="o">=</span> 86400
</span><span class="line">agent.sinks.k1.channel <span class="o">=</span> c1
</span><span class="line">
</span><span class="line">agent.channels.c1.type <span class="o">=</span> memory
</span><span class="line"><span class="c"># 队列里 Event 的容量</span>
</span><span class="line">agent.channels.c1.capacity <span class="o">=</span> 10000
</span><span class="line">agent.channels.c1.transactionCapacity <span class="o">=</span> 10000
</span><span class="line">agent.channels.c1.keep-alive <span class="o">=</span> 60
</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>启动运行</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c"># 启动flume1</span>
</span><span class="line">bin/flume-ng agent -n agent -c conf -f conf/tail2avro.conf <span class="se">\</span>
</span><span class="line">-Dflume.root.logger<span class="o">=</span>WARN
</span><span class="line">
</span><span class="line"><span class="c"># 启动flume2</span>
</span><span class="line">in/flume-ng agent -n agent -c conf -f conf/avro2file.conf <span class="se">\</span>
</span><span class="line">-Dflume.root.logger<span class="o">=</span>INFO
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="section-2">参考</h2>

<ul>
  <li><a href="https://flume.apache.org/FlumeUserGuide.html">FlumeUserGuide</a> 官方的 FlumeUserGuide</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 该选择哪种持久化配置]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/03/10/gai-xuan-ze-na-chong-redischi-jiu-hua-pei-zhi/"/>
    <updated>2016-03-10T23:32:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/03/10/gai-xuan-ze-na-chong-redischi-jiu-hua-pei-zhi</id>
    <content type="html"><![CDATA[<p>这个标题或许会让你想起<a href="https://movie.douban.com/subject/1291843/">《黑客帝国》</a>里经典的台词，你要选择蓝色药丸，还是红色药丸？</p>

<p>Redis 是我们重度使用的一个开源软件，对它的持久化配置做一番相对深入的总结，是值得的。目前它有两种主流的持久化存储方式 SnapShot 以及 AOF 。</p>

<ul>
  <li><a href="#第一节">什么是 Snapshot</a></li>
  <li><a href="#第二节">什么是 AOF </a></li>
  <li><a href="#第三节">选择哪种药丸</a></li>
</ul>

<h3 id="第一节">什么是 Snapshot</h3>

<p>Snapshot 将内存中数据以结构化的方式序列化到 rdb 文件中，是默认的持久化方式，便于解析引擎快速解析和内存实施。快照得由间隔时间，变更次数同时符合才会触发， 该过程中并不阻塞客户端请求，copy-on-write 方式也意味着极端情况下可能会导致实际数据2倍内存的使用量。它首先将数据写入临时文件，结束后，将临时文件重名为 dump.rdb。可以使用 <code>redis-check-dump</code> 用来检测完整性</p>

<p>只有快照结束后才会将旧的文件替换成新的，因此任何时候 RDB 文件都是完整的。如果在触发 snapshot 之前，server 失效。会导致上一个时间点之后的数据未能序列化到 rdb 文件，安全性上稍弱。 </p>

<p>我们可手动执行 save 或 bgsave 命令让 redis 执行快照。两个命令的区别在于:</p>

<ul>
  <li>save 是由主进程进行快照操作，会阻塞其它请求;</li>
  <li>bgsave 会通过 fork 子进程进行快照操作;</li>
</ul>

<p>RDB 文件默认是经过压缩的二进制文件，占用的空间会小于内存中的数据，更加利于传输。设置如下，可以关闭快照功能</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">save ""</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="section">相关配置</h4>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class=""><span class="line"># snapshot触发的时机，save &lt;seconds&gt; &lt;changes&gt;， 比如600秒有2个操作
</span><span class="line">save 600 2
</span><span class="line"># 当snapshot 时出现错误无法继续时，是否阻塞客户端变更操作 
</span><span class="line">stop-writes-on-bgsave-error yes 
</span><span class="line"># 是否启用rdb文件压缩，默认为 yes cpu消耗，快速传输  
</span><span class="line">rdbcompression yes  
</span><span class="line"># rdb文件名称  
</span><span class="line">dbfilename dump.rdb  </span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第二节">什么是 AOF</h3>

<p>Append-only file，将 <code>操作 + 数据</code> 以格式化指令的方式追加到操作日志文件的尾部，在 append 操作返回后， 已经写入到文件或者即将写入，才进行实际的数据变更，日志文件保存了历史的操作过程；当 server 需要数据恢复时，可以直接回放此日志文件，即可还原所有的操作过程。 如果你期望数据更少的丢失，那么可以采用 AOF 模式。可以用 redis-check-aof 检测文件是否完整。</p>

<p>AOF 就是日志会记录变更操(例如：set/del等)，会导致AOF文件非常的庞大，意味着server失效后，数据恢复的过程将会很长；事实上，一条数据经过多次变更，将会产生多条AOF记录，其实只要保存当前的状态，历史的操作记录是可以抛弃的， 由此催生了 AOF ReWrite。</p>

<h4 id="aof-rewrite">什么是 AOF Rewrite</h4>

<p>其实是压缩 AOF 文件的过程，Redis 采取了类似 Snapshot 的方式：基于 <code>copy-on-write</code>，全量遍历内存中数据，然后逐个序列到 aof 文件中。因此 AOF Rewrite 能够正确反应当前内存数据的状态， Rewrite 过程中，新的变更操作将仍然被写入到原 AOF 文件中，同时这些新的变更操作也会被收集起来， 并不阻塞客户端请求。</p>

<h4 id="section-1">相关配置</h4>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
</pre></td><td class="code"><pre><code class=""><span class="line">##只有在yes下，aof重写/文件同步等特性才会生效  
</span><span class="line">appendonly no  
</span><span class="line">  
</span><span class="line">##指定aof文件名称  
</span><span class="line">appendfilename appendonly.aof  
</span><span class="line">  
</span><span class="line">##指定aof操作中文件同步策略，有三个合法值：always everysec no，默认为everysec  
</span><span class="line">appendfsync everysec  
</span><span class="line">
</span><span class="line">##在aof-rewrite期间，appendfsync 是否暂缓文件同步，no 表示不暂缓，yes 表示暂缓，默认为no  
</span><span class="line">no-appendfsync-on-rewrite no  
</span><span class="line">  
</span><span class="line">##aof文件rewrite触发的最小文件尺寸 只有大于此aof文件大于此尺寸是才会触发rewrite，默认64mb，建议512mb  
</span><span class="line">auto-aof-rewrite-min-size 64mb  
</span><span class="line">  
</span><span class="line">##相对于上一次rewrite，本次rewrite触发时aof文件应该增长的百分比
</span><span class="line">auto-aof-rewrite-percentage 100  </span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="appendfsync-">appendfsync 方式：</h4>

<ul>
  <li>always：每一条 aof 记录都立即同步到文件，这是最安全的方式，但是更多的磁盘操作和阻塞延迟，IO 开支较大。</li>
  <li>everysec：每秒同步一次，性能和安全也是redis推荐的方式。如果服务器故障，有可能导致最近一秒内aof记录丢失。</li>
  <li>no：redis并不直接调用文件同步，而是交给操作系统来处理，操作系统可以根据buffer填充情况等择机触发同步；性能较好，在物理服务器故障时，数据丢失量会因OS配置有关。</li>
</ul>

<h3 id="第三节">选择哪种药丸</h3>

<ul>
  <li>AOF更安全，可将数据及时同步到文件中，但需要较多的磁盘IO，AOF文件尺寸较大，文件内容恢复相对较慢， 也更完整。</li>
  <li>Snapshot，安全性较差，它是正常时期数据备份及 master-slave 数据同步的最佳手段，文件尺寸较小，恢复数度较快。</li>
</ul>

<h4 id="section-2">主从架构的环境下的选择</h4>

<ul>
  <li>通常 master 使用AOF，slave 使用 Snapshot，master 需要确保数据完整性，slave 提供只读服务.</li>
  <li>如果你的网络稳定性差， 物理环境糟糕情况下，那么 master， slave均采取 AOF，这个在 master， slave角色切换时，可以减少时间成本；</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ 实时监控 nginx qps 的拓展]]></title>
    <link href="http://zheng-ji.github.com/blog/2016/01/07/shi-shi-jian-kong-nginx-qps-de-tuo-zhan/"/>
    <updated>2016-01-07T12:59:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2016/01/07/shi-shi-jian-kong-nginx-qps-de-tuo-zhan</id>
    <content type="html"><![CDATA[<p>用下班时间写了一个 ngx lua 的拓展, <a href="https://github.com/zheng-ji/ngx_lua_reqstatus">GitHub</a>。可以:</p>

<ul>
  <li>[x] 实时监控域名的 qps</li>
  <li>[x] 实时监控域名的 5xx 个数</li>
  <li>[x] 实时监控域名的 响应时长</li>
  <li>[x] 并附带 Ganglia 监控插件</li>
</ul>

<h2 id="section">使用</h2>

<ul>
  <li>配置 <code>nginx.conf</code></li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
</pre></td><td class="code"><pre><code class=""><span class="line">http {
</span><span class="line">    ...
</span><span class="line">    ...
</span><span class="line">
</span><span class="line">    lua_shared_dict statics_dict    1M; # 初始化变量
</span><span class="line">    lua_package_path "/etc/nginx/ngx_lua_reqstatus/?.lua";  #路径
</span><span class="line">    log_by_lua_file "/etc/nginx/ngx_lua_reqstatus/hook.lua"; # 添加此句
</span><span class="line">
</span><span class="line">    server {
</span><span class="line">        listen 80;
</span><span class="line">        server_name  justforfun.com; 
</span><span class="line">
</span><span class="line">        location /{
</span><span class="line">            ...
</span><span class="line">        }
</span><span class="line">    }
</span><span class="line">    # 监控服务
</span><span class="line">    server {
</span><span class="line">        listen 127.0.0.1:6080;
</span><span class="line">        location /{
</span><span class="line">            access_by_lua_file "/etc/nginx/ngx_lua_reqstatus/status.lua";
</span><span class="line">        }
</span><span class="line">    }
</span><span class="line">}</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>效果</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">curl localhost:6080/?domain=justforfun.com</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>输出</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class=""><span class="line">Server Name:    justforfun.com
</span><span class="line">Seconds SinceLast:   1.4399998188019 secs
</span><span class="line">Request Count:      1
</span><span class="line">Average Req Time:   0 secs
</span><span class="line">Requests Per Secs:  0.69444453182781
</span><span class="line">5xx num:    0</span></code></pre></td></tr></table></div></figure></notextile></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx 日志利器 GoAccess]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/12/10/fen-xi-nginxri-zhi-de-li-qi-goaccess/"/>
    <updated>2015-12-10T23:28:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/12/10/fen-xi-nginxri-zhi-de-li-qi-goaccess</id>
    <content type="html"><![CDATA[<p>我们经常需要从 Nginx 日志分析得出很多有价值的东西，分析的方法是各种 shell, awk, python, 现在 <a href="https://github.com/allinurl/goaccess">GoAccess</a> 给你另外一种选择, 值得拥有。</p>

<ul>
  <li>安装
用以下的方式安装，才能得到新版的 GoAccess, 功能更健全</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class=""><span class="line">$ echo "deb http://deb.goaccess.io $(lsb_release -cs) main"|sudo tee -a /etc/apt/sources.list
</span><span class="line">$ wget -O - http://deb.goaccess.io/gnugpg.key | sudo apt-key add -
</span><span class="line">$ sudo apt-get update
</span><span class="line">$ sudo apt-get install goaccess</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>推荐配置</li>
</ul>

<p>安装完成之后，会生成一份 <code>/etc/goaccess.conf</code> 稍作编辑，这就是默认的配置，免去了后续每次都要定义格式</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">time-format %T   # 只有这种方式才能解决 0.0us 的显示问题
</span><span class="line">date-format %d/%b/%Y
</span><span class="line">log-format %h %^[%d:%t %^] "%r" %s %b "%R" "%u" %T</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>使用</li>
</ul>

<p>输出报表，报表中，我们可以看到最常访问的 IP, 接口，以及每个接口使用带宽，平均响应时长，状态码等，对业务分析有较好的便利性</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class=""><span class="line">终端显示
</span><span class="line">goaccess -f access.log 
</span><span class="line"> 
</span><span class="line">输出报表，报表中，我们可以看到top ip, 接口，以及接口使用带宽，平均响应时长，状态码等
</span><span class="line">goaccess -f access.log &gt; report.html
</span><span class="line"> 
</span><span class="line">具体某段时间的输出
</span><span class="line">sed -n '/5\/Dec\/2015/,/10\/Dec\/2010/ p' access.log | goaccess -a
</span><span class="line"> 
</span><span class="line">处理已经压缩的日志
</span><span class="line">zcat access.log.*.gz | goaccess</span></code></pre></td></tr></table></div></figure></notextile></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gre 隧道与 Keepalived]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/12/05/gre-tuning-and-keepalived/"/>
    <updated>2015-12-05T10:29:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/12/05/gre-tuning-and-keepalived</id>
    <content type="html"><![CDATA[<p>这一篇文章是做了不少功课的。</p>

<ul>
  <li><a href="#第一节">什么是 Gre 隧道</a></li>
  <li><a href="#第二节">什么是 Vrrp </a></li>
  <li><a href="#第三节">KeepAlived 是什么</a></li>
  <li><a href="#第四节">用Keepalived 怎么玩</a></li>
  <li><a href="#第五节">附录</a></li>
</ul>

<h3 id="第一节">什么是 Gre 隧道 </h3>

<p>GRE 隧道是一种 IP-2-IP 的隧道，是通用路由封装协议，可以对某些网路层协议的数据报进行封装，使这些被封装的数据报能够在 IPv4/IPv6 网络中传输。Tunnel 是一个虚拟的点对点的连接，提供了一条通路使封装的数据报文能够在这个通路上传输，并且在一个Tunnel 的两端分别对数据报进行封装及解封装。Linux 上创建 GRE 隧道，需要 ip_gre 内核模块，它是Pv4 隧道的驱动程序。</p>

<p>假设我有2台服务器，想做这两台之间创建 GRE 隧道</p>

<ul>
  <li>$server_A_ip 表示服务器A的IP</li>
  <li>$server_B_ip 服务器B 的内网IP</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class=""><span class="line"># 在 A 机器上执行
</span><span class="line"># 创建 GRE 协议的 虚拟网络设备, 指定本地和对端 IP
</span><span class="line">sudo ip link add gretap1 type gretap local $server_a_ip remote $server_b_ip 
</span><span class="line">sudo ip link set dev gretap1 up  # 启动该设备
</span><span class="line">sudo ip addr add dev gretap1 10.1.1.2/24 # 给该设备一个虚拟网络地址
</span><span class="line">
</span><span class="line"># 在 B 机器上执行
</span><span class="line"># 创建 GRE 协议的 虚拟网络设备, 指定本地和对端 IP
</span><span class="line">sudo ip link add gretap1 type gretap local $server_b_ip remote $server_a_ip 
</span><span class="line">sudo ip link set dev gretap1 up  # 启动该设备
</span><span class="line">sudo ip addr add dev gretap1 10.1.1.3/24 # 给该设备一个虚拟网络地址</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>如果想停止或者删除上述网卡</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">ip link set gretap1 down
</span><span class="line">ip tunnel del gretap1</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>至此点到点得隧道建立。</p>

<h3 id="第二节">什么是 vrrp 协议 </h3>

<p>VRRP(Virtual Router Redundancy Protocol), 即虚拟路由冗余协议。是实现路由器高可用的容错协议。</p>

<p>即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个 master 和多个 backup， 但在外界看来就像一台一样，构成虚拟路由器，拥有一个虚拟IP（vip），占有这个IP 的 master 实际负责 ARP 相应和转发 IP 数据包， 组中的其它路由器作为备份的角色处于待命状态。 master 会发组播消息，当 backup 在超时时间内收不到 vrrp 包时就认为 master 宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master，保证路由器的高可用。</p>

<h3 id="第三节"> Keepalived 是什么 </h3>

<p>Keepalived 是一个基于 VRRP 协议来实现的服务高可用方案，可以利用其来避免IP单点故障。</p>

<ul>
  <li>一个经典的案例</li>
</ul>

<p>一个WEB服务至少会有2台服务器运行 Keepalived，一台为主服务器，一台为备份服务器, 但是对外表现为一个虚拟IP，主服务器会发送特定的消息给备份服务器，当备份服务器收不到这个消息的时候，即主服务器宕机的时候，备份服务器就会接管虚拟IP，继续提供服务，从而保证了高可用性。</p>

<h3 id="第四节">怎么玩 Keepalived</h3>

<ul>
  <li>安装</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo apt-get install keepalived</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>之前提到的，我们在 A, B 两台服务器建立起了 GRE 隧道了。 现在我们有一个虚拟的内网IP， 姑且叫做 $virtual_third_ip
接着在 A 服务器上</p>

<ul>
  <li>配置</li>
</ul>

<p>编辑服务器 A, B 的 <code>/etc/keepalived/keepalived.conf</code></p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
</pre></td><td class="code"><pre><code class=""><span class="line">
</span><span class="line">global_defs {
</span><span class="line">    router_id LVS_DEVEL
</span><span class="line">}
</span><span class="line">
</span><span class="line">vrrp_instance VI_1 {
</span><span class="line">    state MASTER
</span><span class="line">    interface gretap1 # 绑在建立起来的隧道上
</span><span class="line">    virtual_router_id 51
</span><span class="line">    # 优先级别,越高的设备会被弄成主设备, A,B 服务器要有所差别，其他都一样
</span><span class="line">    priority 100          advert_int 1      # 广播时间间隔
</span><span class="line">    authentication {  #  验证相关
</span><span class="line">        auth_type PASS
</span><span class="line">        auth_pass 1111
</span><span class="line">    }
</span><span class="line">    virtual_ipaddress {
</span><span class="line">        $virtual_third_ip dev eth0
</span><span class="line">    }
</span><span class="line">}</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>我们将服务器  A 作为 Master, 服务器 B 当做 Backup, 当服务器 A 需要停机的时候，$virtual_third_ip 就会漂移到服务器 B 上面。 我们两台机器都有相同配置的 Nginx 服务，就可以保障机器出现故障的时候，Nginx 服务丝毫不受影响。</p>

<h3 id="第五节"> 附录 </h3>

<ul>
  <li><a href="http://linux.vbird.org/linux_server/0140networkcommand.php">鸟哥的网络知识</a></li>
  <li><a href="http://www.tldp.org/HOWTO/Adv-Routing-HOWTO/lartc.tunnel.gre.html">GRE tuneling</a></li>
  <li><a href="http://baike.baidu.com/link?url=N1-VGuzQC0PJ2bCnOzYn-XRTlN8eFGCvIJQlTI6KDL5Fx3EQxoRGTrxazb11jfZQqlfeA6q2Ka0VKRVEc0Kdu3GEyhqe1W_Ae2h0Tqu5NacIjOSaSnUVeOe-9QV5dB8q0Wv_uq8-vqdnQICt39UZFK">VRRP</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[给 Tengine 加上 lua 拓展]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/10/29/gei-tengine-jia-shang-lua-tuo-zhan/"/>
    <updated>2015-10-29T22:45:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/10/29/gei-tengine-jia-shang-lua-tuo-zhan</id>
    <content type="html"><![CDATA[<p>Tengine 能动态加载第三方模块，成为我们青睐的选择，我们可以编译动态链接文件，而不需要重新安装 Nginx, 这对在线增强 webservice 很有帮助. 
感谢 agentzh, <a href="https://github.com/openresty/lua-nginx-module">lua-nginx-module</a>, 可以让我们使用 lua 增强nginx的功能, 不言而喻，我们必须现有 Lua 的环境，才能运行 ngx_lua;</p>

<h2 id="nginxlua">编译 nginx_lua</h2>

<p>官方推荐使用LuaJit,虽然也可以使用Lua，但是即时编译(Just-In-Time Compiler)混合了动态编译和静态编译，一句一句编译源代码，但是会将翻译过的代码缓存起来以降低性能损耗。</p>

<ul>
  <li>下载安装</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class=""><span class="line">wget http://luajit.org/download/LuaJIT-2.0.4.tar.gz
</span><span class="line">tar zxvf LuaJIT-2.0.4.tar.gz
</span><span class="line">cd LuaJIT-2.0.4
</span><span class="line">make
</span><span class="line">make install</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>设置环境变量</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">export LUAJIT_LIB=/usr/local/lib
</span><span class="line">export LUAJIT_INC=/usr/local/include/luajit-2.0</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>然后编译ngx-lua-module.so</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">/usr/local/share/dso_tool/ --path=/Path/To/Lua-Nginx-module</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>设置动态库</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">&gt; echo "/usr/local/lib" &gt; /etc/ld.so.conf.d/usr_local_lib.conf
</span><span class="line">&gt; ldconfig</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="tengine-">在 Tengine 中启用</h3>

<p><code>nginx.conf</code> 中先加载动态库</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">dso {
</span><span class="line">    load ngx_load_module;
</span><span class="line">}</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>在 nginx.conf 中添加</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">lua_code_cache on/off;</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>来开启是否将代码缓存，所以每次变更 “*.lua” 文件时，必须重启 nginx 才可生效.</p>

<h3 id="ngxluawaf">使用 ngx_lua_waf</h3>

<p>有了基础环境，我们要开始发挥 ngx lua 的优点了, 我用他安装了 waf (web application firework)
<a href="https://github.com/loveshell/ngx_lua_waf">ngx_lua_waf</a>，这是一个通过 ngx_lua 编写的 web 应用防火墙, 在使用过程中也发现了 ngx_lua_waf 一个bug，给他提了一个<a href="https://github.com/loveshell/ngx_lua_waf/pull/70">Pull Request</a>, 码农生涯第一个 PR.</p>

<hr />

<p>注：
静态编译的程序在执行前全部被翻译为机器码，而动态直译执行的则是一句一句边运行边翻译。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[记录使用 Flask 的点滴]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/10/06/ji-lu-shi-yong-flaskde-dian-di/"/>
    <updated>2015-10-06T13:21:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/10/06/ji-lu-shi-yong-flaskde-dian-di</id>
    <content type="html"><![CDATA[<p>喜欢 Flask 经典的 RestFul 设计风格，以及它与 Gevent 的优雅结合，可以帮助我们轻松构建异步非阻塞应用，烂笔头记下一些较好的实践。</p>

<ul>
  <li><a href="#第一节">消息反馈</a></li>
  <li><a href="#第二节">Flask 上下文</a></li>
  <li><a href="#第三节">注册 JinJia 模板过滤器</a></li>
  <li><a href="#第四节">itsdangerous 生成过期时间 Json 签名</a></li>
  <li><a href="#第五节">一种较好的项目组织方式</a></li>
  <li><a href="#第六节">BluePrint 的好</a></li>
  <li><a href="#第七节">Json 返回</a></li>
  <li><a href="#第八节">自定义出错页面</a></li>
  <li><a href="#第九节">WTF 跨站脚本防御</a></li>
</ul>

<h3 id="第一节">消息反馈</h3>

<p>Flask 提供了一个非常简单的方法来使用闪现系统向用户反馈信息。
闪现系统使得在一个请求结束的时候记录一个信息，然后在且仅仅在下一个请求中访问这个数据。这通常配合一个布局模板实现</p>

<p><a href="http://docs.jinkan.org/docs/flask/patterns/flashing.html">文档链接</a></p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class=""><span class="line"># 视图函数需要调用
</span><span class="line">flash('your response message for user')
</span><span class="line">
</span><span class="line"># 前端页面调用
</span><span class="line">for message in get_flashed_messages()
</span><span class="line">就可以输出反馈信息</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第二节">Flask 上下文</h3>

<p>有两种上下文：程序上下文，请求上下文</p>

<ul>
  <li>current_app： 程序级别上下文，当前激活程序的实例。</li>
  <li>g: 请求级别的上下文</li>
  <li>request: 是请求级别的上下文，封装了客户端发出的 Http 请求中的内容</li>
  <li>session: 用户会话，用于存储请求之间需要记住的键值对</li>
</ul>

<h3 id="第三节">注册 JinJia 模板过滤</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class=""><span class="line">def reverse_filter(s):
</span><span class="line">    return s[::-1]
</span><span class="line">
</span><span class="line">app.jinja_env.filters['reverse'] = reverse_filter</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第四节">itsdangerous 生成过期时间 Json 签名</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class=""><span class="line">serialaizer = Serializer(SECRET_KEY, expires_in=EXPIRES)
</span><span class="line">info = {'id':'xxx'}
</span><span class="line">session = serialaizer.dumps(info)
</span><span class="line">
</span><span class="line"># 判断 session 时间
</span><span class="line">info = None
</span><span class="line">try:
</span><span class="line">    info = serialaizer.loads(session)
</span><span class="line">except Exception:
</span><span class="line">    return jsonify(ERR_SESS_TIMEOUT)</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>用途：生成一个有时间限制的签名，用于API 访问的验证码，如果过期，提醒用户重新登录</p>

<h3 id="第五节">一种较好的项目组织方式</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
</pre></td><td class="code"><pre><code class=""><span class="line">▾ app/
</span><span class="line">    ▾ controlers/
</span><span class="line">        ▾ admin/                    #管理后台的蓝图控制器
</span><span class="line">            ▾ forms/                #表单限制文件
</span><span class="line">                __init__.py　　　　　
</span><span class="line">                xx.py　　　         # blueprint 文件
</span><span class="line">            __init__.py
</span><span class="line">            administrator.py
</span><span class="line">        ▾ api/                      # API 控制器
</span><span class="line">            __init__.py
</span><span class="line">        ▾ site/                     # 站点控制器
</span><span class="line">            __init__.py             # blueprint 文件
</span><span class="line">            xx.py
</span><span class="line">        __init__.py
</span><span class="line">        error.py
</span><span class="line">    ▸ models/         # SQLAlchemy 的各类模型
</span><span class="line">    ▸ static/         # 需要的静态资源，css, js, imgs
</span><span class="line">    ▾ templates/　　　# 前端页面，跟 controller 分类一一对应
</span><span class="line">        ▸ admin/
</span><span class="line">        ▸ error/
</span><span class="line">        ▸ site/
</span><span class="line">    ▸ utilities/　　　　#  功能函数
</span><span class="line">      __init__.py       #　初始化app需要的各种插件，比如 redis, db, 注册蓝图
</span><span class="line">run.py                  #　相当于 main 函数,创建 app, 执行app.run() 函数
</span><span class="line">settings.py             #　配置文件</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第六节">BluePrint 的好 </h3>

<p>每个 Blueprint 就像独立的 Application, 可以管理自己的模板, 路由, 反向路由url_for, 甚至是静态文件，最后统一挂载到 Application 下。从头到尾都是 RestFul。</p>

<p>在创建 app (app/<strong>init</strong>.py) 的时候调用如下:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">from app.controllers.site.console import console 
</span><span class="line">app.register_blueprint(console, url_prefix='/console')</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>视图文件 (app/controllers/site/console.py):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">console = BLueprint('console', __name__)</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第七节">Json 返回</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">from flask import jsonify
</span><span class="line">return jsonify({'code': 0})</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第八节">自定义出错页面</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class=""><span class="line">@app.errorhandler(404)
</span><span class="line">def not_found(error):
</span><span class="line">    return render_template('404.html'), 404
</span><span class="line">
</span><span class="line">@app.errorhandler(500)
</span><span class="line">def crash(error):
</span><span class="line">    return render_template('5xx.html'), 500</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第九节">WTF 跨站脚本防御</h3>

<p>Flask-WTF 能保护表单免受跨站请求伪造的攻击,恶意网站把请求发送到被攻击者已经登录的其他玩战会引发 CSRF 攻击</p>

<ul>
  <li>app config 文件中，开启 CSRF 开关并配置密钥</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">CSRF_ENABLED = True
</span><span class="line">SECRET_KEY = 'you-will-never-guess'</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>表单的定义</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class=""><span class="line">from flask.ext.wtf import Form, TextField, BooleanField
</span><span class="line">from flask.ext.wtf import Required
</span><span class="line">class LoginForm(Form):
</span><span class="line">    openid = TextField('openid', validators = [Required()])
</span><span class="line">    remember_me = BooleanField('remember_me', default = False)</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>页面渲染</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class=""><span class="line">&lt;form action="" method="post" name="login"&gt;
</span><span class="line">    form.hidden_tag()
</span><span class="line">    &lt;p&gt; Please enter your OpenID:form.openid(size=80)&lt;br&gt;&lt;/p&gt;
</span><span class="line">    &lt;p&gt;form.remember_me &lt;/p&gt;
</span><span class="line">    &lt;p&gt;&lt;input type="submit" value="Sign In"&gt;&lt;/p&gt;
</span><span class="line">&lt;/form&gt;</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>控制器函数</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class=""><span class="line">@app.route('/login', methods = ['GET', 'POST'])
</span><span class="line">def login():
</span><span class="line">    form = LoginForm()
</span><span class="line">    if form.validate_on_submit():
</span><span class="line">        flash('Login requested for OpenID="' + form.openid.data))
</span><span class="line">        return redirect('/index')
</span><span class="line">    return render_template('login.html', title = 'Sign In',form = form)</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>我们在配置中开启了CSRF(跨站伪造请求)功能，模板参数 form.hidden_tag() 会被替换成一个具有防止CSRF功能的隐藏表单字段。 在开启了CSRF功能后，所有模板的表单中都需要添加这个模板参数</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python 使用 LDAP]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/10/01/python-shi-yong-ldap/"/>
    <updated>2015-10-01T09:49:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/10/01/python-shi-yong-ldap</id>
    <content type="html"><![CDATA[<h2 id="section">写在开头</h2>

<p>过去的两个多星期，几位小伙伴同心协力完成一个自研的，类似<a href="http://pushover.net">pushover</a>的产品。感谢 Leader 的信任，让我在负责开发的同时也兼顾了一把项目经理。谢谢 IOS, Android 客户端的兄弟，设计师的支持，还有一位实习生，开心看到他的点滴成长。</p>

<p>提下背景，我们之前使用 <code>pushover</code> 来做报警推送，但是它对天朝用户不友好，Android 用户需要翻墙才能使用，有时候不稳定，体现为会收不到信息。pushove 需要付费。我们的受众不仅有程序汪，还有运营产品汪，他们需要一款更容易上手的推送软件，至少不需要番羽墙。于是自己开发一个很有必要。</p>

<p>为最大程度降低用户使用门槛，同时保证用户信息的安全，我们用了 LDAP 账户登陆，严格控制权限，以及 HTTPS 协议开发。下面提一提 LDAP 这个东西。</p>

<h2 id="ldap-">LDAP 是什么</h2>

<p><a href="https://zh.wikipedia.org/wiki/%E8%BD%BB%E5%9E%8B%E7%9B%AE%E5%BD%95%E8%AE%BF%E9%97%AE%E5%8D%8F%E8%AE%AE">LDAP维基百科</a></p>

<p>简单地讲，它是以目录树的方式存放账户信息。</p>

<p>这次项目中，我们不希望用户重新注册账户，而是采用原有的用户体系，这样对单点登录以及权限控制的好处不严而喻, LDAP 协议呼之欲出。</p>

<h2 id="virtualenv--python-ldap">virtualenv 下安装 python-ldap</h2>

<p>我们采用 Python 开发，这就需要 python-ldap 的帮助了, 记下安装笔记的好处是下次不用在此纠结太长时间。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">apt-get install libsasl2-dev python-dev libldap2-dev libssl-dev
</span><span class="line">pip install python-ldap</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="section-1">身份验证</h2>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class=""><span class="line"># LDAP 服务的域名和端口
</span><span class="line">SERVER_NAME = 'xxxx'
</span><span class="line">SERVER_PORT = xxx
</span><span class="line">try:
</span><span class="line">    conn = ldap.open(SERVER_NAME, SERVER_PORT)  
</span><span class="line">    conn.protocol_version = ldap.VERSION3 #设置ldap协议版本 
</span><span class="line">    username = "user=xxx,dc=company,dc=com" #身份信息
</span><span class="line">    password = "xxx" #访问密码
</span><span class="line">    conn.simple_bind_s(username,password) # 开始绑定，验证成功的话不会抛出异常
</span><span class="line">except ldap.LDAPError, e: #捕获出错信息
</span><span class="line">    print e</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="section-2">一点感悟</h2>

<p>鄙人觉得，技术领导要带领项目成长, 除了有责任把控项目风险，推进项目进度。
还必须要花很多的心血在驾驭技术上,  身先士卒去调研可行性, 以及做技术攻关，
而非命令式地分配任务，让同事干活, 只问责结果。
否则很容易导致凝聚力不足,团队技术氛围不足，这样的团队易消极，也易滋生失败的项目。
然而在天朝, 很多人存在一个潜意识:写好代码是为了以后不写代码，这种阶级思想让我反感。</p>

<p>以前看过一个新闻, 硅谷在面试技术 VP ，仍然要求其在各位工程师面前手写代码，以此作为面试的重要环节, 不得不点赞。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sysdig 值得拥有]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/09/10/sysdig-zhi-de-yong-you/"/>
    <updated>2015-09-10T23:10:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/09/10/sysdig-zhi-de-yong-you</id>
    <content type="html"><![CDATA[<p>定位服务器问题时,  我们需要各式各样的武器, 诸如 iftop, ifstat, netstat, tcpdump, iostat。dstat 等, 因此工具箱需要装满很多工具, 在面对问题的时候才能显得不费吹灰之力, 迅速定位问题并解决, 保障服务稳定运行。Sysdig 的横空出世, 对我们而言, 就是一把瑞士军刀, 灵活小巧, 武艺多端.</p>

<ul>
  <li><a href="#第一节">安装</a></li>
  <li><a href="#第二节">常用操作</a></li>
  <li><a href="#第三节">高效的实战</a></li>
</ul>

<h3 id="第一节">安装</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class=""><span class="line">curl -s https://s3.amazonaws.com/download.draios.com/DRAIOS-GPG-KEY.public | apt-key add -
</span><span class="line">curl -s -o /etc/apt/sources.list.d/draios.list http://download.draios.com/stable/deb/draios.list
</span><span class="line">apt-get update
</span><span class="line">apt-get -y install sysdig</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第二节">常用操作</h3>

<p>sysdig 有很多 chisel, chisel 意为 铲子, 可以理解为定位某类问题的工具, sysdig 采用 Lua 编写的。</p>

<ul>
  <li>查看 chisel 列表</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sysdig -cl  </span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看具体某个 chisel 的提示</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sysdig -i spy_logs</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>使用某个 chisel</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sysdig -c spy_logs</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>过滤器可以帮助我们从各种输出信息中, 筛选出我们需要的, 比如 
<code>proc.name=foo</code> , 
如果你记住不了太多过滤器也无妨,  我们可以借助如下命令查看过滤器</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sysdig -l</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>记录定位信息到文本, 以及从文本读取信息</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sysdig -w tracefile.cap
</span><span class="line">sysdig -r tracefile.dump proc.name=sshd</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第三节">高效的实战</h3>

<ul>
  <li>服务器上经常需要查看哪个服务带宽占用使用较高, 特别是被 DDOS 的时候。</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo sysdig -c topprocs_net</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看某个IP的通讯数据,并以ASCII 码输出</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo sysdig -s2000 -A -c echo_fds fd.cip=127.0.0.1</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看非请求 redis-server 的其他请求进程和句柄</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo sysdig -p"%proc.name %fd.name" "evt.type=accept and proc.name!=redis-server"</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看访问该服务器的所有 GET 请求数据</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo sysdig -s 2000 -A -c echo_fds fd.port=80 and evt.buffer contains GET</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看访问该服务器的 SQL 语句</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo sysdig -s 2000 -A -c echo_fds evt.buffer contains SELECT</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看磁盘读写最高的进程</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sysdig -c topprocs_file</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看延迟最大的系统调用</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sysdig -c topscalls_time</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看具体文件的操作细节</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sysdig -A -c echo_fds "fd.filename=syslog"</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>查看 IO 延迟大于 1ms 的文件</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo sysdig -c fileslower 1</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>监视某个文件是否被操作, 从安全出发想象空间很大哦</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo sysdig evt.type=open and fd.name contains /etc</span></code></pre></td></tr></table></div></figure></notextile></div>

<hr />

<p><a href="http://www.sysdig.org/wiki/">Sysdig 官网</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ansible 使用经验]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/09/05/ansiblede-shi-yong-jing-yan/"/>
    <updated>2015-09-05T18:09:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/09/05/ansiblede-shi-yong-jing-yan</id>
    <content type="html"><![CDATA[<p>当你只有一两台服务器的情况下，可以直接登上服务器，手敲命令完成软件部署，代码发布等工作。但假如你有10台，100台的时候，这种方式不仅浪费大量时间，而且给人为犯错带来了可能。于是我们选择 Ansible 来做自动化批量操作。</p>

<p>之前有记录一些 Ansible 入门的使用,请看<a href="http://wiki.zheng-ji.info/Sys/ansible.html">这里</a>, 这半年的积累, 总结一些实用的经验, 记录了一把。</p>

<ul>
  <li><a href="#第一节">配置 ansible.cfg 文件</a></li>
  <li><a href="#第二节">使用 ansible role 来区分业务</a></li>
  <li><a href="#第三节">files 目录的路径定位</a></li>
  <li><a href="#第四节">使用 tags 区分不同操作</a></li>
  <li><a href="#第五节">规划 ansible roles 的 tasks 文件</a></li>
  <li><a href="#第六节">ansible-play-book 一些常用的选项</a></li>
</ul>

<h3 id="第一节">更好地配置文件</h3>

<p>我们会如下配置 /etc/ansible/host, 特意指明用户与 端口</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">[web-cluster]
</span><span class="line">&lt;node-1-IP&gt; ansible_ssh_port=&lt;Your Port&gt; ansible_ssh_user=zj
</span><span class="line">&lt;node-2-IP&gt; ansible_ssh_port=&lt;Your Port&gt; ansible_ssh_user=zj</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>在 /etc/ansible/ansible.cfg 文件里
我们特意提及了 ansible-role 的配置，未来我们会使用这个东西</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">roles_path    = /home/zj/my-ansible/roles</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第二节">使用 ansible role 来区分业务</h3>

<p>打开 ansible 部署脚本的文件夹, 目录树如下</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class=""><span class="line">cd /home/zj/my-ansible/
</span><span class="line">haproxy
</span><span class="line">     - entry.yaml
</span><span class="line">roles
</span><span class="line">     - haproxy
</span><span class="line">        - files
</span><span class="line">        - handlers
</span><span class="line">        - vars
</span><span class="line">        - tasks</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>我用一个管理 haproxy 的例子来讲解这种方式。
在 roles 目录下创建 haproxy, 如上所示，需要有四个目录;</p>

<ul>
  <li>files 目录下放置需要被传输到远端的文件;</li>
  <li>vars  目录下有一个 main.yml 文件,可以定义一些通用的配置变量，可以在 ansbile 脚本中使用;</li>
  <li>handlers 目录下有一个 main.yml, 可以定义一些通用的操作，比如重启服务等;</li>
  <li>tasks 目录下是我们编写 main.yml 脚本，执行业务逻辑的地方;</li>
</ul>

<blockquote>
  <p>那么 ansible role 的入口在哪呢？</p>
</blockquote>

<p>在 ~/my-ansible/haproxy/entry.yml 中，指定了roles的角色，如此一来， 
ansible-playbook 就会去 /home/zj/my-ansible/roles/haproxy 准备执行 tasks/main.yml </p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">- hosts: web-cluster
</span><span class="line">  roles:
</span><span class="line">    - haproxy</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第三节">files 目录的路径定位</h3>

<p>摘取 ~/my-ansible/roles/haproxy/tasks/main.yml</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">- name: copy haproxy conf
</span><span class="line">  copy: src=haproxy.cfg dest=/etc/haproxy/haproxy.cfg owner=root group=root
</span><span class="line">  sudo: yes</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>这里的 src=haproxy.cfg 意味着 ~/my-ansible/roles/haproxy/files/haproxy.cfg</p>

<h3 id="第四节">使用 tags 区分不同操作</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class=""><span class="line">- name: install ppa
</span><span class="line">  shell: add-apt-repository -y ppa:vbernat/haproxy-1.5
</span><span class="line">  sudo: yes
</span><span class="line">  tags:
</span><span class="line">    - install-haproxy</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>以下命令，是使用 tags 参数区分操作的例子</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">cd ~/my-ansible/haproxy
</span><span class="line">ansible-playbook entry.yml -v -K --tags "install-haproxy"</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第五节">规划 ansible roles 的 tasks 目录</h3>

<p>tasks 目录有一个主执行文件 main.yml, 因为业务操作步骤太多，导致 main.yml 文件很长，那么可读性就下降了。为此，我们使用了 include 语法。</p>

<p>cat ~/my-ansible/roles/haproxy/tasks/main.yml</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">- include: 'install-haproxy.yml'</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>include 上述文件，这样 main.yml 就显得简洁，我们可以将相关的操作写在对应的 yml 文件里</p>

<p>cat ~/my-ansible/roles/haproxy/tasks/install-haproxy.yml</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class=""><span class="line">- name: copy haproxy conf
</span><span class="line">  copy: src=haproxy.cfg dest=/etc/haproxy/haproxy.cfg owner=root group=root
</span><span class="line">  sudo: yes
</span><span class="line">  tags:
</span><span class="line">     - install-haproxy</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>tags 最好也与该 yml 文件名一致，清晰分明</p>

<h3 id="第六节">ansible-play-book 一些常用的选项</h3>

<ul>
  <li>-K 需要 sudo 权限去客户机执行命令，会提示你输入密码</li>
  <li>-v 可以输出冗余的执行过程</li>
  <li>–check 可以测试脚本执行情况，但实际并未在远程机器执行</li>
  <li>–tags 提示 ansible-play-book 调用哪些 tags 命令</li>
</ul>

<p>使用过ansible roles 之后，最大的体会是操作调理化，甚至编程化，合理的利用 handler, vars, 能更加优雅抽象。</p>

<hr />

<p>上述的例子在 Github 有代码, 结合本文阅读可能更容易上手
<a href="https://github.com/zheng-ji/ToyCollection/tree/master/my-ansible">Link</a> </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Supervisor 监听器]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/08/21/supervisorjian-ting-qi/"/>
    <updated>2015-08-21T16:36:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/08/21/supervisorjian-ting-qi</id>
    <content type="html"><![CDATA[<p>我们服务多是用 supervisor 启动的， 但监控多数是用 <code>monit</code>, 如果我们能通过监测 supervisor 事件变化来做监控，就可以写一套通用的监控程序。</p>

<p>庆幸的是，supervisor 的 <code>eventListener</code> 支持我的设想。</p>

<p>这个监控程序需要用 supervisor 启动，类型不再是<code>program</code>, 而是<code>eventlistener</code>，这里有几个比较耗时的地方需要记录下。</p>

<ul>
  <li>supervisor 有独特的通信协议,需要遵循，否则通讯不会被触发</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class=""><span class="line">def write_stdout(self, s):
</span><span class="line">    sys.stdout.write(s)
</span><span class="line">    sys.stdout.flush()
</span><span class="line">
</span><span class="line">write_stdout('READY\n') //类似开始握手
</span><span class="line">write_stdout('RESULT 2\nOK') //结束通讯</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>需要从标准输入端读取事件,而且他是个阻塞的事件模型</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class=""><span class="line">while 1:
</span><span class="line">    self.write_stdout('READY\n')
</span><span class="line">    line = sys.stdin.readline()
</span><span class="line">    do_some_thing()
</span><span class="line">    self.write_stdout('RESULT 2\nOK')</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>supervisor 配置文件需要订阅事件</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class=""><span class="line">[eventlistener:alarm]
</span><span class="line">user=zj
</span><span class="line">command=/usr/bin/python /home/ymserver/bin/alarm/main.py
</span><span class="line">events=PROCESS_STATE_EXITED,PROCESS_STATE_STOPPED,PROCESS_STATE_FATAL
</span><span class="line">
</span><span class="line"># 记录控制台输出的日志位置
</span><span class="line">stderr_logfile=/home/zj/log/supervisor/alarm.err.log
</span><span class="line">stdout_logfile=/home/zj/log/supervisor/alarm.output.log</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>弄好 supervisor 配置，以及部署好代码之后，需要重启 supervisor 才会真正的订阅事件。
从此 supervisor 管理的程序一旦有 <code>FATAL</code>,<code>EXIT</code> 等状态就会触发程序，程序中就会触发自定义的报警。</p>

<hr />

<p><a href="https://github.com/zheng-ji/ToyCollection/tree/master/supervisor-listener">代码</a></p>

<p>Happy Hack!</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Twemproxy 一个 Redis 代理]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/08/16/twemproxy/"/>
    <updated>2015-08-16T12:11:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/08/16/twemproxy</id>
    <content type="html"><![CDATA[<dl>
  <dt>为解决线上 Redis 服务直连出现链接数爆棚而做的调研， 对 Twitter 开源的 twemproxy 做一些记录。 我们之所以放弃官方的 RedisCLuster 是因为不太满意其性能</dt>
  <dd>
    <p><a href="#第一节">初窥原理</a>
* <a href="#第二节">安装与配置</a>
* <a href="#第三节">不支持的操作</a>
* <a href="#第四节">压力测试</a>
* <a href="#第五节">摘自极光博客的评论</a></p>
  </dd>
</dl>

<h3 id="第一节">初窥原理</h3>

<ul>
  <li>Twitter 出品的轻量级 Redis，memcached 代理，使用它可以减少缓存服务器的连接数，并且利用它来作分片。</li>
  <li>作是说最差情况下，性能损耗不会多于20%。背后是用了pipeline，redis是支持使用pipeline批处理的。</li>
  <li>twemproxy 与每个 redis 服务器都会建立一个连接，每个连接实现了两个 FIFO 的队列， 通过这两个队列实现对 redis 的 pipeline 访问，将多个客户端的访问合并到一个连接，这样既减少了redis服务器的连接数，又提高了访问性能。</li>
</ul>

<h3 id="第二节">安装与配置</h3>

<ul>
  <li>安装</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class=""><span class="line">apt-get install automake
</span><span class="line">apt-get install libtool
</span><span class="line">git clone git://github.com/twitter/twemproxy.git
</span><span class="line">cd twemproxy
</span><span class="line">autoreconf -fvi
</span><span class="line">./configure
</span><span class="line">make
</span><span class="line">sudo make install</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>默认的可执行文件在 /usr/local/sbin/nutcracker</p>

<ul>
  <li>配置文件 /etc/nutcracker/nutcracker.yml</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class=""><span class="line">alpha:
</span><span class="line">    listen: 127.0.0.1:8877
</span><span class="line">    hash: fnv1a_64
</span><span class="line">    distribution: ketama
</span><span class="line">    auto_eject_hosts: true
</span><span class="line">    redis: true
</span><span class="line">    server_retry_timeout: 30000
</span><span class="line">    server_failure_limit: 3
</span><span class="line">    servers:
</span><span class="line">        - 127.0.0.1:6379:1 master0  #后端的redis-server
</span><span class="line">        - 127.0.0.1:6380:1 master1</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>当 redis 做缓存的使用的时候应该启用 auto_eject_hosts， 如果某个节点失败的时候将该节点删除，虽然丧失了数据的一致性，但作为缓存使用，保证了这个集群的高可用性。当redis做存储的使用时为了保持数据的一致性，应该禁用 auto_eject_hosts,也就是当某个节点失败之后并不删除该节点。</p>

<h3 id="第三节">不支持的操作</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class=""><span class="line">keys command: keys,migrate,move object,randomkey,rename,renamenx,
</span><span class="line">sort strings command: bitop,mset,msetnx
</span><span class="line">list command: blpop,brpop,brpoplpush
</span><span class="line">scripting command: script exists,script flush,script kill,script load
</span><span class="line">pub/sub command:(全部不支持)psubscribe,publish,punsubscribe,subscribe,unsubscribe</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第四节">压测</h3>

<p>感谢 redis 提供的 redis-benchmark 工具，用它来做压测挺好的。</p>

<ul>
  <li>n 表示多少个连接</li>
  <li>r 表示多少个 key,</li>
  <li>t 代表命令</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
</pre></td><td class="code"><pre><code class=""><span class="line">zj@zheng-ji.info:~$ redis-benchmark -p 6700 -t smembers,hexists,get,hget,lrange,ltrim,zcard,setex,sadd -n 1000000 -r 100000000
</span><span class="line">
</span><span class="line">====== GET ======
</span><span class="line">1000000 requests completed in 12.95 seconds
</span><span class="line">50 parallel clients
</span><span class="line">3 bytes payload
</span><span class="line">keep alive: 1
</span><span class="line">
</span><span class="line">99.19% &lt;= 1 milliseconds
</span><span class="line">99.93% &lt;= 2 milliseconds
</span><span class="line">100.00% &lt;= 2 milliseconds
</span><span class="line">77220.08 requests per second
</span><span class="line">
</span><span class="line">====== SADD ======
</span><span class="line">1000000 requests completed in 10.74 seconds
</span><span class="line">50 parallel clients
</span><span class="line">3 bytes payload
</span><span class="line">keep alive: 1
</span><span class="line">
</span><span class="line">99.88% &lt;= 1 milliseconds
</span><span class="line">99.95% &lt;= 2 milliseconds
</span><span class="line">99.97% &lt;= 3 milliseconds
</span><span class="line">99.99% &lt;= 4 milliseconds
</span><span class="line">100.00% &lt;= 4 milliseconds
</span><span class="line">93144.56 requests per second</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>如作者所言, 性能几乎可以跟直连redis比拟，背后的数据也很均匀,使用twemproxy 观察连接数, 一直都保持在个位数左右。</p>

<h3 id="第五节">摘自极光博客的评论</h3>

<ul>
  <li>前端使用 Twemproxy 做代理，后端的 Redis 数据能基本上根据 key 来进行比较均衡的分布。</li>
  <li>后端一台 Redis 挂掉后，Twemproxy 能够自动摘除。恢复后，Twemproxy 能够自动识别、恢复并重新加入到 Redis 组中重新使用。</li>
  <li>Redis 挂掉后，后端数据是否丢失依据 Redis 本身的策略配置，与 Twemproxy 基本无关。</li>
  <li>如果要新增加一台 Redis，Twemproxy 需要重启才能生效；并且数据不会自动重新 Reblance，需要人工单独写脚本来实现。</li>
  <li>如同时部署多个 Twemproxy，配置文件一致（测试配置为distribution：ketama,modula），则可以从任意一个读取，都可以正确读取 key对应的值。</li>
  <li>多台 Twemproxy 配置一样，客户端分别连接多台 Twemproxy可以在一定条件下提高性能。根据 Server 数量，提高比例在 110-150%之间。</li>
  <li>如原来已经有 2 个节点 Redis，后续有增加 2 个 Redis，则数据分布计算与原来的 Redis 分布无关，现有数据如果需要分布均匀的话，需要人工单独处理。</li>
  <li>如果 Twemproxy 的后端节点数量发生变化，Twemproxy 相同算法的前提下，原来的数据必须重新处理分布，否则会存在找不到key值的情况。</li>
</ul>

<hr />

<p>参考链接</p>

<p><a href="http://blog.jpush.cn/redis-twemproxy-benchmark/">极光推送的博客</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[黑客马拉松]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/08/10/hackthon/"/>
    <updated>2015-08-10T22:24:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/08/10/hackthon</id>
    <content type="html"><![CDATA[<p>周末参加了公司组织的黑客马拉松比赛, </p>

<p>通宵达旦完成了作品是个值得纪念的经历, 我们的产品叫做：<a href="http://pact.im">正义的朋友</a> </p>

<ul>
  <li>我们想要实现的功能是让人在紧急关头用最快速的方式联系到可以帮助你的人，于是我们通过锁屏应用来实现; </li>
  <li>用户在锁屏状态，画一个v手势，会把自己的地理位置发送给设置好的联系人，并持续每十秒发送一次周围的声音给联系人；</li>
  <li>用户在锁屏状态，画一个w手势，会发出专业的求救声</li>
</ul>

<p>这次比赛的感觉, 与当年<code>叫神马</code>团队的似曾相识, 队友非常给力, 大家都很拼, 我喜欢这种感觉, 事实上，在比赛之前，为了工作上的项目我已经几乎透支了, 队友也是一样。 但周六上午我们还是快速进入状态, 被逼的潜力果然不容小觑.  晒一张我们队伍合照.</p>

<p><img src="http://zheng-ji.github.com/images/2015/08/teammate.png" /></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[记录错误登陆的 btmp 文件]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/07/24/ji-lu-cuo-wu-deng-lu-de-btmpwen-jian/"/>
    <updated>2015-07-24T23:06:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/07/24/ji-lu-cuo-wu-deng-lu-de-btmpwen-jian</id>
    <content type="html"><![CDATA[<p>今天查看了服务器时，发现 <code>/var/log/btmp</code> 日志文件较大。</p>

<p>此文件是记录错误登录的日志， 文件较大意味着有人使用密码字典登录ssh服务，
这个文件是需要用 <code>lastb</code> 命令才可读的。</p>

<p>查看尝试恶意登陆的前十个IP</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sudo lastb | awk '{ print $3}' | awk '{++S[$NF]} END {for(a in S) print a, S[a]}' | sort -rk2 |head</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>如果有有必要封阻IP的话，可以执行：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">iptables -A INPUT -i eth0 -s *.*.*.0/24 -j DROP</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[my.cnf 配置依据]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/07/12/my-dot-cnfpei-zhi-yi-ju/"/>
    <updated>2015-07-12T08:35:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/07/12/my-dot-cnfpei-zhi-yi-ju</id>
    <content type="html"><![CDATA[<p>阅读完<a href="http://book.douban.com/subject/6873681/">构建高性能服务器</a> 一书，书中对 <code>MySQL</code> 配置做了讲解，我用烂笔头记录一番，明白它们这么配置的真正意义，形成系统的认知。</p>

<ul>
  <li><a href="#第一节">通用配置</a></li>
  <li><a href="#第二节">innodb_pool_buffer 合理配置</a></li>
  <li><a href="#第三节">文件打开数的合理设置</a></li>
  <li><a href="#第四节">打开表优化设置</a></li>
  <li><a href="#第五节">临时表的设置</a></li>
  <li><a href="#第六节">查看索引命中率</a></li>
</ul>

<h3 id="第一节">通用配置</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">skip-name-resolve:</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>禁止 MySQL 对外连接 DNS 解析 ,这一选项可以消除 MySQL 进行DNS解析时间，开启该选项，所有远程主机连接授权都要使用 IP。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">back_log=512</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>指出在 MySQL 暂停响应之前，有多少个请求被存在堆栈中。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">key_buffer_size</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>指定用于索引的缓冲区大小，增加它可得到更好的索引处理能力，对于内存 4G 左右，可设置为 256MB。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">max_allowed_packet=4M</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>设定在一次网络传输中的最大值。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">thread_stack=256k</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>设置每个线程的堆栈大小，可满足普通操作。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">table_cache=614k</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>高速缓冲区的大小，当mysql访问一个表示，缓冲区还有空间，那么这个表就会被放入缓冲区，一般看峰值时间状态值，open_tables与open_cache，用于判断是否需要增加table_cache，如果open_Table接近table_cache就要增加了。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">sort_buffer_size=6M</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>设定查询排序所用的缓冲区大小，是对每个链接而言，如果有100个连接，那么分配的总缓存是100*6=600M。
read_buffer_size,join_buffer_size 都是对单个链接而言。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">thread_cache_size=64</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>设置缓存中的链接线程的最大数量,4GB内存以上的我们会给64或者更大。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">query_cache_size=64M</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>如果该值比较小反而会影响效率，可以考虑不用。如果太大，缓存区中碎片会很多。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">tmp_table_size</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>设置内存临时表的最大值，如果超过改制，就会将临时表写入磁盘，范围是1kB-4GB。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">max_connection</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>如果超过该值，会出现<code>too many connections</code>。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">max_connect_errors</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>设置每个主机中连接请求异常中断最大次数，如果超过，MySQL禁止host连接请求，直到MySQL重启。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">wait_timeout = 120</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>一个请求的最大链接时间。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">thread_concurrency=8</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>该参数为服务器逻辑CPU * 2。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">skip-networking</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>该选项可以关闭连接方式，如果需要远程连接，不要开启。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">innodb_flush_log_at_trx_commit = 1</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>设置为0就是等到 innodb_log_buffer_size 队列满了之后再统一存储，默认是1，是最安全的设置。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">innodb_thread_concurrency = 8</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>服务器几个CPU就设置多少。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">read_rnd_buffer_Size = 16M</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>设置随机读的使用的缓冲区。</p>

<h3 id="第二节">innodb_buffer_pool 的合理设置</h3>

<p>不要武断的把innodb_buffer pool 配置为内存的50-80% 应具体而定。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class=""><span class="line">show status like 'innodb_buffer_pool_%'
</span><span class="line">
</span><span class="line">关注的有
</span><span class="line">innodb_buffer_pool_pages_data;
</span><span class="line">innodb_buffer_pool_page_total;
</span><span class="line">innodb_buffer_pool_read_request;
</span><span class="line">innodb_buffer_pool_reads;</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后看</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">读命中率 (innodb_buffer_pool_read_request - innodb_buffer_pool_reads) / innodb_buffer_pool_read_request;
</span><span class="line">写命中率 innodb_buffer_pool_pages_data /innodb_buffer_pool_page_total;</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>如果读写命中率都能在95%以上就很好了。</p>

<h3 id="第三节">文件打开数的合理设置依据</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">show global status like 'open_files'
</span><span class="line">show variables like 'open_file_limit';</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>比较合适的设置是 Open_files / open_files_limit * 100% &lt;= 75;</p>

<h3 id="第四节">打开表优化设置依据</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">show global status like 'open%tables';
</span><span class="line">show variable like 'table_cache';</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>比较合适</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">open_tables / opende_tables * 100 &gt; 85%;
</span><span class="line">open_Tables / table_Cache* 100% &lt; 95%；</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第五节">临时表的设置依据</h3>

<p>每次执行语句，关于已经被创造了的临时表的数量，可以这么设置:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">show gloabl status like 'created_tmp5';
</span><span class="line">Created_tmp_disk_table / Created_tmp_tables * 100% &lt;= 25 %</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="第六节">查看索引命中率</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">show global status like 'key_read%';</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>key_cache_miss_rate = key_Read / key_read_request * 100% 小于 1% 是很好的，
意味着1000个请求有一个直接读硬盘。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[轻巧实时统计用户数]]></title>
    <link href="http://zheng-ji.github.com/blog/2015/06/11/qing-qiao-shi-shi-tong-ji-yong-hu-shu/"/>
    <updated>2015-06-11T23:14:00+08:00</updated>
    <id>http://zheng-ji.github.com/blog/2015/06/11/qing-qiao-shi-shi-tong-ji-yong-hu-shu</id>
    <content type="html"><![CDATA[<h2 id="section">背景</h2>

<p>最近在优化一个短地址的统计服务，之前是使用 Cookie 来做统计每天的UV，而且这个需求是近乎实时的，
业务方需要每5分钟就能看到最新统计结果。但有些情况我们是取不到Cookie的，比如服务器对服务器的狂刷访问，那么UV就计算不准确，
是时候要改造方案了。</p>

<p>后来我用 IP+UserAgent 来识别用户，从而统计 UV。好了，接下来你会怎么做这个实时统计呢？</p>

<h2 id="section-1">两个方案的选择</h2>

<ul>
  <li>Plan A：</li>
</ul>

<p>将每天的 <code>IP+UA</code> 存进 Redis 的 Set 集合里，它会自动去重，然后计算该集合里元素的个数得到结果，此方案似乎不错，
但真的好吗？假如每天大概有200W个UV，1个用户标识<code>IP+UA</code>需要大概150个字节，那么大约要耗费300MB的内存。</p>

<p>觉得内存太宝贵，应该有更好的方法，想起了位运算， 于是就有了</p>

<ul>
  <li>Plan B:</li>
</ul>

<p>将 <code>IP+UA</code> 组合成的字符串哈希成一个数值，然后借助 Redis 的 BitSet 数据结构求出<code>UV</code>。以下是伪代码</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class=""><span class="line">conn = redis()
</span><span class="line">index = hash(UA+IP)
</span><span class="line">key = "xxx_2015-05-10"
</span><span class="line">conn.do('SETBIT', key, index, 1) # 将该hash值对应的位赋值为1
</span><span class="line">
</span><span class="line">realtime_uv = conn.do('BITCOUNT', key) # 得到实时的uv</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>根据业务的情况，我的hash桶开了200W个位，大概需要消耗2M的内存，的确节约不少空间，位运算的效率也很快。
于是欣然选择 Plan B</p>

<h2 id="section-2">一些链接</h2>

<ul>
  <li><a href="https://redis.readthedocs.org/en/2.4/set.html">Redis Set</a></li>
  <li><a href="http://redis.io/commands/SETBIT">Redis BitSet</a></li>
  <li><a href="http://blog.nosqlfan.com/html/3501.html">NoSQLFan 一个文章</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
